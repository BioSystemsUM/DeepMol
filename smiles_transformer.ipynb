{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smiles_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Gx6C47FhgCHA",
        "H8xfVjtAgOOu",
        "jEHffPvzpUp-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iDcj6TIgbzI"
      },
      "source": [
        "# Creation of molecular embeddings for classifying compounds using Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx6C47FhgCHA"
      },
      "source": [
        "## Obtaining Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KALcmt7p0Ax"
      },
      "source": [
        "Get the latest version of the dataset from the repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jFRrBSPmpjCQ",
        "outputId": "0fc00b44-854d-4d73-80ae-e00ebd645ca8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "\n",
        "url = 'https://github.com/GLambard/Molecules_Dataset_Collection/raw/master/originals/HIV.csv'\n",
        "\n",
        "data = requests.get(url).content\n",
        "df = pd.read_csv(io.StringIO(data.decode('utf-8')), index_col = 0)\n",
        "df.reset_index(inplace=True)\n",
        "df"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smiles</th>\n",
              "      <th>activity</th>\n",
              "      <th>HIV_active</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O=S(=O)(O)CCS(=O)(=O)O</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41122</th>\n",
              "      <td>CCC1CCC2c3c([nH]c4ccc(C)cc34)C3C(=O)N(N(C)C)C(...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41123</th>\n",
              "      <td>Cc1ccc2[nH]c3c(c2c1)C1CCC(C(C)(C)C)CC1C1C(=O)N...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41124</th>\n",
              "      <td>Cc1ccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)C...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41125</th>\n",
              "      <td>Cc1cccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41126</th>\n",
              "      <td>CCCCCC=C(c1cc(Cl)c(OC)c(-c2nc(C)no2)c1)c1cc(Cl...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41127 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  smiles activity  HIV_active\n",
              "0      CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...       CI           0\n",
              "1      C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...       CI           0\n",
              "2                       CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21       CI           0\n",
              "3        Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1       CI           0\n",
              "4                                 O=S(=O)(O)CCS(=O)(=O)O       CI           0\n",
              "...                                                  ...      ...         ...\n",
              "41122  CCC1CCC2c3c([nH]c4ccc(C)cc34)C3C(=O)N(N(C)C)C(...       CI           0\n",
              "41123  Cc1ccc2[nH]c3c(c2c1)C1CCC(C(C)(C)C)CC1C1C(=O)N...       CI           0\n",
              "41124  Cc1ccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)C...       CI           0\n",
              "41125  Cc1cccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)...       CI           0\n",
              "41126  CCCCCC=C(c1cc(Cl)c(OC)c(-c2nc(C)no2)c1)c1cc(Cl...       CI           0\n",
              "\n",
              "[41127 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8xfVjtAgOOu"
      },
      "source": [
        "## Pre-Processing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTbjNjsZrfT9"
      },
      "source": [
        "Create a vocabulary of tokens based on the SMILES specifications\n",
        "\n",
        "http://opensmiles.org/opensmiles.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRuKPbvQhrAs"
      },
      "source": [
        "elements = 'H,He,Li,Be,B,C,N,O,F,Ne,Na,Mg,Al,Si,P,S,Cl,Ar,K,Ca,Sc,Ti,V,Cr,Mn,Fe,Co,Ni,Cu,Zn,Ga,Ge,As,Se,Br,Kr,Rb,Sr,Y,Zr,Nb,Mo,Tc,Ru,Rh,Pd,Ag,Cd,In,Sn,Sb,Te,I,Xe,Cs,Ba,La,Ce,Pr,Nd,Pm,Sm,Eu,Gd,Tb,Dy,Ho,Er,Tm,Yb,Lu,Hf,Ta,W,Re,Os,Ir,Pt,Au,Hg,Tl,Pb,Bi,Po,At,Rn,Fr,Ra,Ac,Th,Pa,U,Np,Pu,Am,Cm,Bk,Cf,Es,Fm,Md,No,Lr,Rf,Db,Sg,Bh,Hs,Mt,Ds,Rg,Cn,Uut,Fl,Uup,Lv,Uus,Uuo'\n",
        "aromatic_atoms = 'b,c,n,o,p,s,as,se,te'\n",
        "symbols = '[,],(,),=,+,-,#,:,@,.,%'\n",
        "isotopes = '0,1,2,3,4,5,6,7,8,9'\n",
        "\n",
        "elements = str(elements).split(',')\n",
        "aromatic_atoms = str(aromatic_atoms).split(',')\n",
        "symbols = str(symbols).split(',')\n",
        "isotopes = str(isotopes).split(',')\n",
        "\n",
        "smiles_vocabulary = elements + aromatic_atoms + symbols + isotopes"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iEuhSs0rno9"
      },
      "source": [
        "Method to process a SMILES by spliting it into an array of tokens that are part of the SMILES vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1TWKgxjNExR"
      },
      "source": [
        "def process_smiles(smiles, vocabulary):\n",
        "  tokens = []\n",
        "  i = 0;\n",
        "  found = False;\n",
        "  while i < len(smiles):\n",
        "    if len(smiles[i:]) >= 3:\n",
        "      if smiles[i:i+3] in vocabulary:\n",
        "        tokens.append(smiles[i:i+3])\n",
        "        i += 3\n",
        "        found = True\n",
        "    if len(smiles[i:]) >= 2 and not found:\n",
        "      if smiles[i:i+2] in vocabulary:\n",
        "        tokens.append(smiles[i:i+2])\n",
        "        i += 2\n",
        "        found = True\n",
        "    if len(smiles[i:]) >= 1 and not found:\n",
        "      if smiles[i] in vocabulary:\n",
        "        tokens.append(smiles[i])\n",
        "        i += 1\n",
        "        found = True\n",
        "    if not found:\n",
        "      print('Error in value', smiles[i])\n",
        "      print(smiles)\n",
        "      break\n",
        "    found = False\n",
        "  return tokens"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cktfXtsQXIy"
      },
      "source": [
        "Method to process an array of SMILES into a list of processed SMILES and respective lengths (number of tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYOkDDrCMFVG"
      },
      "source": [
        "def process_smiles_array(smiles_array):\n",
        "  processed_list = list()\n",
        "  lengths = list()\n",
        "  for i in range(len(smiles_array)):\n",
        "      processed_smiles = process_smiles(smiles_array[i], smiles_vocabulary)\n",
        "      processed_list.append(' '.join(processed_smiles))\n",
        "      lengths.append(len(processed_smiles))\n",
        "  return processed_list, lengths"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMlCOV7idlhO"
      },
      "source": [
        "Process all SMILES in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zep3WMMROu9e"
      },
      "source": [
        "processed_smiles, smiles_lengths = process_smiles_array(df['smiles'].values)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9zXjaETdpsZ"
      },
      "source": [
        "Insert processed SMILES and respective lengths into the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lw6OXkW8PQqh",
        "outputId": "abdb23d8-283d-4080-b2c1-180d9b3f99bb"
      },
      "source": [
        "df['processed_smiles'] = processed_smiles\n",
        "df['smiles_length'] = smiles_lengths\n",
        "df"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smiles</th>\n",
              "      <th>activity</th>\n",
              "      <th>HIV_active</th>\n",
              "      <th>processed_smiles</th>\n",
              "      <th>smiles_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C C C 1 = [ O + ] [ Cu - 3 ] 2 ( [ O + ] = C (...</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C ( = C c 1 c c c c c 1 ) C 1 = [ O + ] [ Cu -...</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C C ( = O ) N 1 c 2 c c c c c 2 Sc 2 c 1 c c c...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>N c 1 c c c ( C = C c 2 c c c ( N ) c c 2 S ( ...</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O=S(=O)(O)CCS(=O)(=O)O</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>O = S ( = O ) ( O ) C C S ( = O ) ( = O ) O</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41122</th>\n",
              "      <td>CCC1CCC2c3c([nH]c4ccc(C)cc34)C3C(=O)N(N(C)C)C(...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C C C 1 C C C 2 c 3 c ( [ n H ] c 4 c c c ( C ...</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41123</th>\n",
              "      <td>Cc1ccc2[nH]c3c(c2c1)C1CCC(C(C)(C)C)CC1C1C(=O)N...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C c 1 c c c 2 [ n H ] c 3 c ( c 2 c 1 ) C 1 C ...</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41124</th>\n",
              "      <td>Cc1ccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)C...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C c 1 c c c ( N 2 C ( = O ) C 3 c 4 [ n H ] c ...</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41125</th>\n",
              "      <td>Cc1cccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C c 1 c c c c ( N 2 C ( = O ) C 3 c 4 [ n H ] ...</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41126</th>\n",
              "      <td>CCCCCC=C(c1cc(Cl)c(OC)c(-c2nc(C)no2)c1)c1cc(Cl...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C C C C C C = C ( c 1 c c ( Cl ) c ( O C ) c (...</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41127 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  smiles  ... smiles_length\n",
              "0      CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...  ...            51\n",
              "1      C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...  ...            83\n",
              "2                       CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21  ...            31\n",
              "3        Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1  ...            47\n",
              "4                                 O=S(=O)(O)CCS(=O)(=O)O  ...            22\n",
              "...                                                  ...  ...           ...\n",
              "41122  CCC1CCC2c3c([nH]c4ccc(C)cc34)C3C(=O)N(N(C)C)C(...  ...            55\n",
              "41123  Cc1ccc2[nH]c3c(c2c1)C1CCC(C(C)(C)C)CC1C1C(=O)N...  ...            71\n",
              "41124  Cc1ccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)C...  ...            60\n",
              "41125  Cc1cccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)...  ...            60\n",
              "41126  CCCCCC=C(c1cc(Cl)c(OC)c(-c2nc(C)no2)c1)c1cc(Cl...  ...            66\n",
              "\n",
              "[41127 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSZ4FYa9W8NR"
      },
      "source": [
        "Plot a histogram with the distribution of the lengths of the SMILES in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pnzLW9gJRzLj",
        "outputId": "80a7d817-d722-493c-cf5b-b992775d799a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(smiles_lengths, bins=100)\n",
        "plt.ylabel('Number of SMILES')\n",
        "plt.xlabel('Length of SMILES')\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBcIlhUBj3zV"
      },
      "source": [
        "Check the percentage of the instances from the dataset where the length of the SMILES is too small/big"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKBinb_7kpfI",
        "outputId": "c980c47d-e2e0-4822-fa84-35da03521a2b"
      },
      "source": [
        "length_range = (15, 125)\n",
        "\n",
        "filtered = filter(lambda x: length_range[0] <= x <= length_range[1], smiles_lengths)\n",
        "percentage = len(list(filtered)) / len(processed_smiles)\n",
        "print('Percentage of instances with SMILES\\' length between %s and %s: %s' % (length_range[0], length_range[1], percentage))\n",
        "\n",
        "sequence_length = length_range[1]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of instances with SMILES' length between 15 and 125: 0.9813018211880273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV4L9JilCK4e"
      },
      "source": [
        "Remove instances from the dataset where the length of the SMILES is too small/big"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JTSV4eLXCM8V",
        "outputId": "db4134cf-2530-443e-dfd7-09d349446c6f"
      },
      "source": [
        "df = df[(df['smiles_length'] >= length_range[0]) & (df['smiles_length'] <= length_range[1])]\n",
        "df = df.drop('smiles_length', axis='columns')\n",
        "df"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smiles</th>\n",
              "      <th>activity</th>\n",
              "      <th>HIV_active</th>\n",
              "      <th>processed_smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C C C 1 = [ O + ] [ Cu - 3 ] 2 ( [ O + ] = C (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C ( = C c 1 c c c c c 1 ) C 1 = [ O + ] [ Cu -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C C ( = O ) N 1 c 2 c c c c c 2 Sc 2 c 1 c c c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>N c 1 c c c ( C = C c 2 c c c ( N ) c c 2 S ( ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O=S(=O)(O)CCS(=O)(=O)O</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>O = S ( = O ) ( O ) C C S ( = O ) ( = O ) O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41122</th>\n",
              "      <td>CCC1CCC2c3c([nH]c4ccc(C)cc34)C3C(=O)N(N(C)C)C(...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C C C 1 C C C 2 c 3 c ( [ n H ] c 4 c c c ( C ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41123</th>\n",
              "      <td>Cc1ccc2[nH]c3c(c2c1)C1CCC(C(C)(C)C)CC1C1C(=O)N...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C c 1 c c c 2 [ n H ] c 3 c ( c 2 c 1 ) C 1 C ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41124</th>\n",
              "      <td>Cc1ccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)C...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C c 1 c c c ( N 2 C ( = O ) C 3 c 4 [ n H ] c ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41125</th>\n",
              "      <td>Cc1cccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C c 1 c c c c ( N 2 C ( = O ) C 3 c 4 [ n H ] ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41126</th>\n",
              "      <td>CCCCCC=C(c1cc(Cl)c(OC)c(-c2nc(C)no2)c1)c1cc(Cl...</td>\n",
              "      <td>CI</td>\n",
              "      <td>0</td>\n",
              "      <td>C C C C C C = C ( c 1 c c ( Cl ) c ( O C ) c (...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40358 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  smiles  ...                                   processed_smiles\n",
              "0      CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...  ...  C C C 1 = [ O + ] [ Cu - 3 ] 2 ( [ O + ] = C (...\n",
              "1      C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...  ...  C ( = C c 1 c c c c c 1 ) C 1 = [ O + ] [ Cu -...\n",
              "2                       CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21  ...  C C ( = O ) N 1 c 2 c c c c c 2 Sc 2 c 1 c c c...\n",
              "3        Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1  ...  N c 1 c c c ( C = C c 2 c c c ( N ) c c 2 S ( ...\n",
              "4                                 O=S(=O)(O)CCS(=O)(=O)O  ...        O = S ( = O ) ( O ) C C S ( = O ) ( = O ) O\n",
              "...                                                  ...  ...                                                ...\n",
              "41122  CCC1CCC2c3c([nH]c4ccc(C)cc34)C3C(=O)N(N(C)C)C(...  ...  C C C 1 C C C 2 c 3 c ( [ n H ] c 4 c c c ( C ...\n",
              "41123  Cc1ccc2[nH]c3c(c2c1)C1CCC(C(C)(C)C)CC1C1C(=O)N...  ...  C c 1 c c c 2 [ n H ] c 3 c ( c 2 c 1 ) C 1 C ...\n",
              "41124  Cc1ccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)C...  ...  C c 1 c c c ( N 2 C ( = O ) C 3 c 4 [ n H ] c ...\n",
              "41125  Cc1cccc(N2C(=O)C3c4[nH]c5ccccc5c4C4CCC(C(C)(C)...  ...  C c 1 c c c c ( N 2 C ( = O ) C 3 c 4 [ n H ] ...\n",
              "41126  CCCCCC=C(c1cc(Cl)c(OC)c(-c2nc(C)no2)c1)c1cc(Cl...  ...  C C C C C C = C ( c 1 c c ( Cl ) c ( O C ) c (...\n",
              "\n",
              "[40358 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2q8y9mlCJRm"
      },
      "source": [
        "##  Transformer model to extract embeddings and use them as input to another classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6M_xnKWpnOn"
      },
      "source": [
        "Install necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp8HBXwqCNQC",
        "outputId": "ffaa1da6-10a3-4b9c-f310-0e50249c0e2a"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_VBm96dxaQO"
      },
      "source": [
        "Check if an GPU is being used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr7icVnyCN7I",
        "outputId": "ad793d50-bf9a-4b73-92b7-c63d50c678ed"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wBZpsKmxf_x"
      },
      "source": [
        "Initialize model and tokenizer\n",
        "\n",
        "> The model selected is the BERT cased model since the tokens in the SMILES vocabulary are cased dependent, for example, the token for the chemical element Carbon 'C' must be differentiated from the token for the aromatic element 'c'.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYOMwU12CQOy",
        "outputId": "fbd1b377-d55b-47c8-8819-8090566dbac4"
      },
      "source": [
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "model = TFAutoModel.from_pretrained('bert-base-cased')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGNraIVaxr0X"
      },
      "source": [
        "Method to handle tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jmw5CqXCS4P"
      },
      "source": [
        "def tokenize(sequence):\n",
        "    return tokenizer.encode_plus(sequence,                    # sequence to tokenize\n",
        "                                 max_length=sequence_length,  # maximum length for the sequence\n",
        "                                 truncation=True,             # truncate any sequence longer than the maximum length\n",
        "                                 padding='max_length',        # allow any sequence shorter than the maximum length to be padded\n",
        "                                 add_special_tokens=True,     # allow special tokens (important for BERT)\n",
        "                                 return_attention_mask=True,  # output attention_mask needed\n",
        "                                 return_token_type_ids=False, # output token_type_ids not needed \n",
        "                                 return_tensors='tf')         # return TensorFlow tensors\n",
        "    return tokens"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP9JQA3F79Nv"
      },
      "source": [
        "Demonstration of BERT's tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA0emsLM54J6",
        "outputId": "ef309957-9cfa-4352-845f-cecb3c449ede"
      },
      "source": [
        "processed_smiles = df['processed_smiles'].values\n",
        "\n",
        "smiles = processed_smiles[0]\n",
        "\n",
        "input_ids = tokenize(smiles)\n",
        "ids = input_ids['input_ids'][0].numpy()\n",
        "\n",
        "print('Sequence of tokens:\\n')\n",
        "print(smiles)\n",
        "print('\\n')\n",
        "\n",
        "print('List of BERT\\'s vocabulary indeces:\\n')\n",
        "print(ids)\n",
        "print('\\n')\n",
        "\n",
        "print('Decoding of the indeces:\\n')\n",
        "print(tokenizer.decode(ids))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence of tokens:\n",
            "\n",
            "C C C 1 = [ O + ] [ Cu - 3 ] 2 ( [ O + ] = C ( C C ) C 1 ) [ O + ] = C ( C C ) C C ( C C ) = [ O + ] 2\n",
            "\n",
            "\n",
            "List of BERT's vocabulary indeces:\n",
            "\n",
            "[ 101  140  140  140  122  134  164  152  116  166  164  140 1358  118\n",
            "  124  166  123  113  164  152  116  166  134  140  113  140  140  114\n",
            "  140  122  114  164  152  116  166  134  140  113  140  140  114  140\n",
            "  140  113  140  140  114  134  164  152  116  166  123  102    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "\n",
            "\n",
            "Decoding of the indeces:\n",
            "\n",
            "[CLS] C C C 1 = [ O + ] [ Cu - 3 ] 2 ( [ O + ] = C ( C C ) C 1 ) [ O + ] = C ( C C ) C C ( C C ) = [ O + ] 2 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12NTJLurTaAb"
      },
      "source": [
        "Method to generate an embedding for a sequence as a single vector\n",
        "\n",
        "> The model BERT has 12 hidden states, each being the output of its 12 layers (transformer blocks).\n",
        "\n",
        "> Each token is represented by a vector with 768 features. This means that each sequence of tokens is represented by an array with the dimensions (length of the sequence, 768). \n",
        "\n",
        "> The strategy to generate an embedding from a sequence of tokens is to average, for each token, the values its vector. This means that each sequence of tokens is represented by a one-dimensional vector with 768 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN02lZ-TSTl1"
      },
      "source": [
        "def get_embedding(sequence):\n",
        "  input_ids = tokenize(sequence)              # sequence tokenization\n",
        "  outputs = model(input_ids)                  # run the sequence through BERT\n",
        "  last_hidden_state = outputs[0]              # get the last hidden state\n",
        "  vectors = last_hidden_state[0]              # get the token vectors from the last hidden state\n",
        "  embedding = tf.reduce_mean(vectors, axis=0) # calculate the average for all token vectors\n",
        "  return embedding.numpy()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9k_k2et5FRl"
      },
      "source": [
        "Generate embeddings for all the SMILES in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFU_qccTTpP_",
        "outputId": "a5dc84fa-7d63-41aa-fce6-09974b3c0336"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "embeddings = []\n",
        "\n",
        "#for smiles in tqdm(processed_smiles):\n",
        "for smiles in tqdm(processed_smiles[0:9]):\n",
        "  embedding = get_embedding(smiles)\n",
        "  embeddings.append(embedding)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 11%|█         | 1/9 [00:00<00:00,  9.07it/s]\u001b[A\n",
            " 22%|██▏       | 2/9 [00:00<00:00,  9.11it/s]\u001b[A\n",
            " 33%|███▎      | 3/9 [00:00<00:00,  8.76it/s]\u001b[A\n",
            " 44%|████▍     | 4/9 [00:00<00:00,  8.59it/s]\u001b[A\n",
            " 56%|█████▌    | 5/9 [00:00<00:00,  8.52it/s]\u001b[A\n",
            " 67%|██████▋   | 6/9 [00:00<00:00,  8.59it/s]\u001b[A\n",
            " 78%|███████▊  | 7/9 [00:00<00:00,  8.56it/s]\u001b[A\n",
            " 89%|████████▉ | 8/9 [00:00<00:00,  8.30it/s]\u001b[A\n",
            "100%|██████████| 9/9 [00:01<00:00,  8.43it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEHffPvzpUp-"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShBNX0YMpYLv"
      },
      "source": [
        "https://towardsdatascience.com/tensorflow-and-transformers-df6fceaf57cc\n",
        "\n",
        "https://www.kaggle.com/sameerpixelbot/bert-embeddings-with-tensorflow-2-0-example\n",
        "\n",
        "https://betterprogramming.pub/build-a-natural-language-classifier-with-bert-and-tensorflow-4770d4442d41\n",
        "\n",
        "https://medium.com/@dhartidhami/understanding-bert-word-embeddings-7dc4d2ea54ca\n",
        "\n",
        "https://www.sbert.net/examples/applications/computing-embeddings/README.html\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/\n"
      ]
    }
  ]
}