{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b389ab",
   "metadata": {},
   "source": [
    "# 3D descriptors experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a144b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [14:14:05] Warning: molecule is tagged as 3D, but all Z coords are zero\n"
     ]
    }
   ],
   "source": [
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "frame = PandasTools.LoadSDF('sweet.sdf',smilesName='SMILES',molColName='Molecule',includeFingerprints=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b687056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def checkAtomsCoordinates(m):\n",
    "    '''\n",
    "        Function to check if a molecule contains zero coordinates in all atoms. \n",
    "        Then this molecule must be eliminated.\n",
    "        Returns True if molecules is OK and False if molecule contains zero coordinates.\n",
    "        Example:\n",
    "            # Load  test set to a frame\n",
    "            sdf = 'miniset.sdf'\n",
    "            df = pt.LoadSDF(sdf, molColName='mol3DProt')\n",
    "            ## Checking if molecule contains only ZERO coordinates,\n",
    "           ##  then remove that molecules from dataset\n",
    "            df['check_coordinates'] = [checkAtomsCoordinates(x) for x in df.mol3DProt]\n",
    "            df_eliminated_mols = dfl[df.check_coordinates == False]\n",
    "            df = df[df.check_coordinates == True]\n",
    "            df.drop(columns=['check_coordinates'], inplace=True)\n",
    "            print('final minitest set:', df.shape[0])\n",
    "            print('minitest eliminated:', df_eliminated_mols.shape[0])\n",
    "    '''\n",
    "    conf = m.GetConformer()\n",
    "    position = []\n",
    "    for i in range(conf.GetNumAtoms()):\n",
    "        pos = conf.GetAtomPosition(i)\n",
    "        position.append([pos.x, pos.y, pos.z])\n",
    "    position = np.array(position)\n",
    "    if not np.any(position):\n",
    "        return(False)\n",
    "    else:\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf7a94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import SDMolSupplier\n",
    "from rdkit.Chem import rdMolDescriptors as molDesc\n",
    "from mordred import Calculator, descriptors\n",
    "\n",
    "\n",
    "def load_sdf_file(file):\n",
    "\n",
    "    supplier = SDMolSupplier(file)\n",
    "    mols, attempts = [], 0\n",
    "\n",
    "    while not mols and attempts < 10:\n",
    "        mols = list(supplier)\n",
    "        attempts += 1\n",
    "    print(f\"Loaded {len(mols)} molecules after {attempts} attempts.\")\n",
    "\n",
    "    return mols\n",
    "\n",
    "def generate_descriptor_rdkit(mols):\n",
    "    \n",
    "    descript = []\n",
    "    ids = []\n",
    "    y = []\n",
    "\n",
    "    for mol in mols:\n",
    "        \n",
    "        viable = checkAtomsCoordinates(mol)\n",
    "        \n",
    "        \n",
    "        if viable:\n",
    "            \n",
    "            y.append(float(mol.GetProp(\"_SWEET\")))\n",
    "            db_id = int(mol.GetProp(\"_SourceID\"))\n",
    "            desPBF = molDesc.CalcPBF(mol)\n",
    "            desRDF = molDesc.CalcRDF(mol)\n",
    "            desRG = molDesc.CalcRadiusOfGyration(mol)\n",
    "            desAUTOCORR3D = molDesc.CalcAUTOCORR3D(mol)\n",
    "            desc_inertial_shape_factor = molDesc.CalcInertialShapeFactor(mol)\n",
    "            desc_eccentricity = molDesc.CalcEccentricity(mol)\n",
    "            desc_asphericity = molDesc.CalcAsphericity(mol)\n",
    "            desc_spherocity_index = molDesc.CalcSpherocityIndex(mol)\n",
    "            desc_morse = molDesc.CalcMORSE(mol)\n",
    "            desc_whim = molDesc.CalcWHIM(mol)\n",
    "            desc_getaway = molDesc.CalcGETAWAY(mol)\n",
    "            #fp = molDesc.GetHashedAtomPairFingerprintAsBitVect(mol,\n",
    "             #                                                           nBits = 1024,\n",
    "              #                                                          includeChirality = True)\n",
    "            #fp = list(np.asarray(fp, dtype=np.float))\n",
    "            \n",
    "            des1 = desRDF + [desPBF, desRG, desc_inertial_shape_factor, desc_eccentricity, desc_asphericity, desc_spherocity_index]+ desAUTOCORR3D + desc_morse + desc_whim \n",
    "            \n",
    "            descript.append(des1)\n",
    "            ids.append(db_id)\n",
    "    \n",
    "    return ids,descript,y\n",
    "\n",
    "def generate_descriptor_mordred(mols):\n",
    "    \n",
    "    descript = []\n",
    "    ids = []\n",
    "    y = []\n",
    "    \n",
    "    i = 0\n",
    "    for mol in mols:\n",
    "        \n",
    "        i += 1\n",
    "        viable = checkAtomsCoordinates(mol)\n",
    "        \n",
    "        \n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print(i)\n",
    "        \n",
    "        if viable:\n",
    "            \n",
    "            db_id = int(mol.GetProp(\"_SourceID\"))\n",
    "            y.append(float(mol.GetProp(\"_SWEET\")))\n",
    "            calculator = Calculator(descriptors,ignore_3D=False)\n",
    "            err = calculator(mol)\n",
    "            desc = err.drop_missing()\n",
    "            descript.append(list(desc))\n",
    "            ids.append(db_id)\n",
    "    \n",
    "    return ids,descript,y\n",
    "\n",
    "from padelpy.functions import from_mdl\n",
    "\n",
    "def featurize_padel(file):\n",
    "    \n",
    "    fingerprints = from_mdl(file)\n",
    "    \n",
    "    return fingerprints\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f29fc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 molecules after 1 attempts.\n"
     ]
    }
   ],
   "source": [
    "mols_not_sweet = load_sdf_file(\"not_sweet.sdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "447af1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:25] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:26] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:31] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:31] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:36] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [20:42:36] Warning: molecule is tagged as 3D, but all Z coords are zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25795 molecules after 1 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [20:42:37] Warning: molecule is tagged as 3D, but all Z coords are zero\n"
     ]
    }
   ],
   "source": [
    "#mols_not_sweet = load_sdf_file(\"not_sweet_2.sdf\")\n",
    "\n",
    "mols_sweet = load_sdf_file(\"./data/dataset_sweet_3D.sdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac88a2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1507"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mordred import Calculator, descriptors, get_descriptors_in_module, CPSA,GeometricalIndex,GravitationalIndex,MoRSE, MomentOfInertia\n",
    "from mordred.CPSA import PNSA, PPSA, DPSA\n",
    "from mordred.GeometricalIndex import Radius3D\n",
    "\n",
    "new_descriptors = get_descriptors_in_module( MomentOfInertia)\n",
    "\n",
    "calculator = Calculator( descriptors,ignore_3D=False)\n",
    "err = calculator(mols_sweet[300])\n",
    "desc = err.drop_missing()\n",
    "len(desc)\n",
    "#print(err.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "824ebbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ids_not_sweet,descript_not_sweet,y_not_sweet = generate_descriptor_rdkit(mols_not_sweet)\n",
    "\n",
    "ids_sweet,descript_sweet,y_sweet = generate_descriptor_rdkit(mols_sweet)\n",
    "\n",
    "len(descript_sweet[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c97e6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25786\n",
      "25786\n",
      "25786\n"
     ]
    }
   ],
   "source": [
    "print(len(descript_sweet))\n",
    "print(len(ids_sweet))\n",
    "print(len(y_sweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e211dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25779,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#ids = ids_not_sweet + ids_sweet\n",
    "#descript = descript_not_sweet + descript_sweet\n",
    "#y = y_not_sweet + y_sweet\n",
    "\n",
    "ids = ids_sweet\n",
    "descript = descript_sweet\n",
    "y = y_sweet\n",
    "\n",
    "\n",
    "########################### remove nan ################################\n",
    "\n",
    "descript = np.array(descript)\n",
    "ids = np.array(ids)\n",
    "y = np.array(y)\n",
    "\n",
    "boo = np.isnan(descript).any(axis=1)\n",
    "#boo = np.where(descript==0)\n",
    "indexes_to_remove = [index[0] for index in np.argwhere(boo==True)]\n",
    "\n",
    "descript = np.delete(descript, indexes_to_remove,axis=0)\n",
    "ids = np.delete(ids, indexes_to_remove)\n",
    "y = np.delete(y, indexes_to_remove)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"ids\":ids, \"3D\": list(descript), \"sweet\": y})\n",
    "df[\"3D\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74d09496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25779, 634)\n",
      "(25779, 634)\n"
     ]
    }
   ],
   "source": [
    "descript = np.array(descript)\n",
    "print(descript.shape)\n",
    "descript = descript[~np.isnan(descript).any(axis=1), :]\n",
    "print(descript.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecd6564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset= df.columns.difference([\"3D\",\"sweet\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d602b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "\n",
    "not_sweet_to_join = df[df[\"sweet\"]==0].sample(n=1900, random_state=1)\n",
    "sweet = df[df[\"sweet\"]==1]\n",
    "\n",
    "final_dataset = not_sweet_to_join.append(sweet)\n",
    "final_dataset[\"sweet\"] = final_dataset[\"sweet\"].map({1:1,2:0})\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(final_dataset[\"3D\"],final_dataset[\"sweet\"],test_size=0.20,random_state=1)\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train, test_size=0.25,random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "843ee60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2265, 634)\n",
      "(756, 634)\n",
      "(755, 634)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(list(X_train))\n",
    "X_test = np.array(list(X_test))\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_val = np.array(list(X_val))\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04538b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df418f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "def runRF(data, max_depth, max_features, min_samples_split, bootstrap, criterion, n_estimators):\n",
    "    print('=== RANDOM FOREST ===')\n",
    "    X_train, X_test, y_train, y_test = data[0], data[1], data[2], data[3]\n",
    "    \n",
    "    rf = RandomForestClassifier(max_depth = max_depth, max_features = max_features, \n",
    "                                min_samples_split = min_samples_split, bootstrap = bootstrap, \n",
    "                                criterion = criterion, n_estimators = n_estimators, n_jobs = -1)\n",
    "    \n",
    "    rf = rf.fit(X_train,y_train)\n",
    "    \n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=5, n_jobs = -1)\n",
    "    print(scores)\n",
    "    print(\"CV accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = 'models3D/modelRF.sav'\n",
    "    pickle.dump(rf, open(filename, 'wb'))\n",
    "    \n",
    "    rfc_predict = rf.predict(X_test)\n",
    "    \n",
    "    print(\"=== Confusion Matrix ===\")\n",
    "    print(confusion_matrix(y_test, rfc_predict))\n",
    "    print('\\n')\n",
    "    print(\"=== Classification Report ===\")\n",
    "    print(classification_report(y_test, rfc_predict))\n",
    "    print('\\n')\n",
    "    print(\"=== Test accuracy ===\")\n",
    "    print(accuracy_score(y_test, rfc_predict))\n",
    "    print('\\n')\n",
    "\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9847c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def runSVM(data, kernel, c, gamma):\n",
    "    print('=== SVM ===')\n",
    "    X_train, X_test, y_train, y_test = data[0], data[1], data[2], data[3]\n",
    "    \n",
    "    svmc = svm.SVC(kernel=kernel, C=c, gamma = gamma, probability = True).fit(X_train,y_train)\n",
    "    #svmc = svm.SVC(kernel=kernel, C=c, gamma = gamma).fit(X_train,y_train)\n",
    "    \n",
    "    scores = cross_val_score(svmc, X_train, y_train, cv=5, n_jobs = -1)\n",
    "    print(scores)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    #with kernel='rbf', C=1000, gamma = 0.001  Accuracy: 0.88 (+/- 0.01)\n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = 'models3D/modelSVM.sav'\n",
    "    pickle.dump(svmc, open(filename, 'wb'))\n",
    "    \n",
    "    svmc_predict = svmc.predict(X_test)\n",
    "    print(\"=== Confusion Matrix ===\")\n",
    "    print(confusion_matrix(y_test, svmc_predict))\n",
    "    print('\\n')\n",
    "    print(\"=== Classification Report ===\")\n",
    "    print(classification_report(y_test, svmc_predict))\n",
    "    print('\\n')\n",
    "    print(\"=== Test accuracy ===\")\n",
    "    print(accuracy_score(y_test, svmc_predict))\n",
    "    print('\\n')\n",
    "    \n",
    "    return svmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dca615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "config_tf = tf.compat.v1.ConfigProto()\n",
    "config_tf.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config_tf)\n",
    "set_session(sess)\n",
    "\n",
    "def runDNN(data, optimizer, dropout_rate, hidden_layers, l1, l2,units1,units2):\n",
    "    def create_model(units1 = 512, units2 = 512, dropout_rate=0.0, hidden_layers=1, l1 = 0, l2 = 0, \n",
    "                        optimizer = 'adam', batchNormalization = True):\n",
    "        # create model\n",
    "        print(\"unit1: \", units1)\n",
    "        print('dropout_rate = ', dropout_rate)\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=units1, activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            model.add(Dense(units=units2, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        ##Compile model and make it ready for optimization\n",
    "        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        # Reduce lr callback\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    print('=== DNN ===')\n",
    "    model = KerasClassifier(build_fn=create_model, dropout_rate = dropout_rate, \n",
    "                            hidden_layers = hidden_layers, epochs=500,\n",
    "                            l1 = l1, l2 = l2, units1 = units1,units2 = units2,verbose=1)\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = data[0], data[1], data[2], data[3]\n",
    "    \n",
    "    # simple early stopping\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
    "    # reduce learning rate\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=50, min_lr=0.00001, verbose=0)\n",
    "    \n",
    "    #callbacks = [es, reduce_lr]\n",
    "    callbacks = [reduce_lr]\n",
    "    #Training\n",
    "    history = model.fit(X_train, y_train, batch_size=10, callbacks=callbacks, \n",
    "                        validation_data = (X_test, y_test))\n",
    "\n",
    "    print('Training Accuracy: ', np.mean(history.history['accuracy']))\n",
    "    print('Validation Accuracy: ', np.mean(history.history['val_accuracy']))\n",
    "    \n",
    "    dnn_predict = model.predict(X_test)\n",
    "    print(\"=== Confusion Matrix ===\")\n",
    "    print(confusion_matrix(y_test, dnn_predict))\n",
    "    print(\"=== Classification Report ===\")\n",
    "    print(classification_report(y_test, dnn_predict))\n",
    "    print('\\n')\n",
    "    print(\"=== Test accuracy ===\")\n",
    "    print(accuracy_score(y_test, dnn_predict))\n",
    "    print('\\n')\n",
    "    \n",
    "    print(model.model.summary())\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    model.model.save('models3D/modelDNN.h5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11418053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DNN ===\n",
      "unit1:  755\n",
      "dropout_rate =  0.3\n",
      "Epoch 1/500\n",
      "227/227 [==============================] - 50s 22ms/step - loss: 20.9205 - accuracy: 0.6481 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "223/227 [============================>.] - ETA: 0s - loss: 3.4415 - accuracy: 0.6645"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-fc8589420d7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#model = runSVM(data, 'rbf', 10, 0.001)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#svm = runSVM(data, 'rbf', 1000, 0.001)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunDNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-72145bbad5c6>\u001b[0m in \u001b[0;36mrunDNN\u001b[0;34m(data, optimizer, dropout_rate, hidden_layers, l1, l2, units1, units2)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m#Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     history = model.fit(X_train, y_train, batch_size=10, callbacks=callbacks, \n\u001b[0m\u001b[1;32m     58\u001b[0m                         validation_data = (X_test, y_test))\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1189\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = X_train, X_val, y_train , y_val\n",
    "\n",
    "\n",
    "\n",
    "units = int(len(data[1]))\n",
    "\n",
    "\n",
    "\n",
    "#model = runRF(data, 10, 'sqrt', 2, False, 'gini', 900) # 0.87\n",
    "#runRF(data, None, 'sqrt', 11, False, 'gini', 100) #0.87\n",
    "#runRF(data, 50, 'auto', 8, True, 'gini', 400)\n",
    "#model = runSVM(data, 'rbf', 10, 0.001)\n",
    "#svm = runSVM(data, 'rbf', 1000, 0.001)\n",
    "model = runDNN(data,'Adam', 0.3, 1, 0.001, 0.01,units,units*2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7b0b3180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step\n",
      "=== Confusion Matrix ===\n",
      "[[323  65]\n",
      " [ 27 302]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.88       388\n",
      "           1       0.82      0.92      0.87       329\n",
      "\n",
      "    accuracy                           0.87       717\n",
      "   macro avg       0.87      0.88      0.87       717\n",
      "weighted avg       0.88      0.87      0.87       717\n",
      "\n",
      "\n",
      "\n",
      "=== Test accuracy ===\n",
      "0.8716875871687587\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcapela/miniconda3/envs/deepmol/lib/python3.9/site-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, predictions))\n",
    "print('\\n')\n",
    "print(\"=== Test accuracy ===\")\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4e5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
