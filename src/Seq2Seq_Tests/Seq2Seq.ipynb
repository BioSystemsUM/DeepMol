{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Seq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LHtY75PpoGFa"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gonkalos/AA2-Embeddings/blob/main/Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHtY75PpoGFa"
      },
      "source": [
        "# Importes gerais / Instalações"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lph0Cm7fXotU"
      },
      "source": [
        "% matplotlib inline\n",
        "!pip install kora\n",
        "from IPython.display import clear_output \n",
        "clear_output()\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import requests\n",
        "import io\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import kora.install.rdkit\n",
        "from rdkit           import Chem\n",
        "from rdkit.Chem      import AllChem\n",
        "from rdkit.Chem      import Draw, Descriptors\n",
        "from rdkit.Chem      import PandasTools\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras           import regularizers\n",
        "from keras.models    import Model\n",
        "from keras.layers    import Input, LSTM, Dense, Concatenate \n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGkva-iIpnvO"
      },
      "source": [
        "#Get dataset from repository \n",
        "- Using original dataset instead of lastest review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBAfPMkBs991"
      },
      "source": [
        "def get_data_From_GitHub(url, df):\n",
        "    if url is None:\n",
        "        url ='https://github.com/GLambard/Molecules_Dataset_Collection/raw/master/originals/HIV.csv'\n",
        "    df = pd.read_csv(io.StringIO(requests.get(url).content.decode('utf-8')), index_col = 0)\n",
        "    df.reset_index(inplace=True)\n",
        "    return df\n",
        "\n",
        "def process_smiles_array(smiles_array):\n",
        "  lengths = list()\n",
        "  for i in smiles_array:\n",
        "      lengths.append(len(i))\n",
        "  return lengths\n",
        "\n",
        "def Cut_Range_of_Smiles(df,save,plot,smiles_lengths):\n",
        "    if save is True:\n",
        "        df['smiles_length'] = smiles_lengths\n",
        "    plt.hist(smiles_lengths, bins=100)\n",
        "    plt.ylabel('Number of SMILES')\n",
        "    plt.xlabel('Length of SMILES')\n",
        "    if plot is True:\n",
        "        plt.show()\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wn6pOj2pPLL"
      },
      "source": [
        "\n",
        "df = get_data_From_GitHub(None,None)\n",
        "smiles_lengths = process_smiles_array(df['smiles'].values)\n",
        "df = Cut_Range_of_Smiles(df,True,True,smiles_lengths)\n",
        "\n",
        "\n",
        "length_range = (0, 120) #Range of the cut\n",
        "filtered = filter(lambda x: length_range[0] <= x <= length_range[1], smiles_lengths)\n",
        "percentage = len(list(filtered)) / len(df['smiles'].values)\n",
        "print('Percentage of instances with SMILES\\' length between %s and %s: %s' % (length_range[0], length_range[1], percentage))\n",
        "\n",
        "df = df[(df['smiles_length'] >= length_range[0]) & (df['smiles_length'] <= length_range[1])]\n",
        "df = df.drop('smiles_length', axis='columns')\n",
        "print(df.shape)\n",
        "\n",
        "smiles_lengths = process_smiles_array(df['smiles'].values)\n",
        "df = Cut_Range_of_Smiles(df,False,True,smiles_lengths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0WqKY42x-D1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5BMtslzOkXR"
      },
      "source": [
        "\n",
        "# Seq2Seq Fingerprint\n",
        "> informações utilizadas\n",
        "> - https://github.com/XericZephyr/seq2seq-fingerprint/\n",
        "> - https://www.cheminformania.com/master-your-molecule-generator-seq2seq-rnn-models-with-smiles-in-keras/df.shape()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prxTT2xoQCsf"
      },
      "source": [
        "Seguimento do seguinte post: [**Master your molecule generator: Seq2seq RNN models with SMILES in Keras** ](https://www.cheminformania.com/master-your-molecule-generator-seq2seq-rnn-models-with-smiles-in-keras/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "0e_K1Y6URM9e",
        "outputId": "4eb1eb13-0366-4e8a-f3c2-64b7034be72f"
      },
      "source": [
        "# General Imports\n",
        "%matplotlib inline\n",
        "data = df\n",
        "\n",
        "smiles_train, smiles_test = train_test_split(data[\"smiles\"], random_state=42)\n",
        "print(smiles_train.shape)\n",
        "print(smiles_test.shape)\n",
        "print(df.fillna('').astype(str).apply(lambda x:x.str.len()).mean())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e9cea76dfbd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# General Imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msmiles_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmiles_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"smiles\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwD1NI5BUvcn"
      },
      "source": [
        "É necessário vectorizar os *SMILES* para um array.\n",
        "para isto, um conjunto de caracteres é construido a partir de todos os caracteres encontrados nos *SMILES* (os de teste e de treino). \n",
        "Além disso, alguns caracteres são adicionaidos ao inicio e fim de cada *SMILE* para sinalizar quando a começou e acabou\n",
        "\n",
        "\n",
        "*The stop character also work as padding to get the same length of all vectors, so that the network can be trained in batch mode. The character set is used to define two dictionaries to translate back and forth between index and character. The maximum length of the SMILES strings is needed as the RNN’s will be trained in batch mode, and is set to the maximum encountered + some extra.*\n",
        "\n",
        "<!---The SMILES must be vectorized to one-hot encoded arrays. To do this a character set is built from all characters found in the SMILES string (both train and test). Also, some start and stop characters are added, which will be used to initiate the decoder and to signal when SMILES generation has stopped. The stop character also work as padding to get the same length of all vectors, so that the network can be trained in batch mode. The character set is used to define two dictionaries to translate back and forth between index and character. The maximum length of the SMILES strings is needed as the RNN’s will be trained in batch mode, and is set to the maximum encountered + some extra.-->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "o9LG6RqmRSpc",
        "outputId": "ab38e2fd-49d7-4fd2-c19a-e6e33d3ace73"
      },
      "source": [
        "charset = set(\"\".join(list(data.smiles))+\"!E\")\n",
        "char_to_int = dict((c,i) for i,c in enumerate(charset))\n",
        "int_to_char = dict((i,c) for i,c in enumerate(charset))\n",
        "embed = max([len(smile) for smile in data.smiles]) + 5\n",
        "print(str(charset))\n",
        "print(len(charset), embed)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c89d0438cf2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcharset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"!E\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mchar_to_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mint_to_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msmile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx2MpsINWlCt"
      },
      "source": [
        "*Afterwards the character set and dictionaries are used to set the necessary bits in the Numpy arrays. The result will be a “piano-roll” of each molecules SMILES string. The X data starts with !, but the output Y is offset by one character, and starts with the first character of the actual SMILES.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz_7GoIlTdRd"
      },
      "source": [
        "def vectorize(smiles):\n",
        "        one_hot =  np.zeros((smiles.shape[0], embed , len(charset)),dtype=np.int8)\n",
        "        for i,smile in enumerate(smiles):\n",
        "            #encode the startchar\n",
        "            one_hot[i,0,char_to_int[\"!\"]] = 1\n",
        "            #encode the rest of the chars\n",
        "            for j,c in enumerate(smile):\n",
        "                one_hot[i,j+1,char_to_int[c]] = 1\n",
        "            #Encode endchar\n",
        "            one_hot[i,len(smile)+1:,char_to_int[\"E\"]] = 1\n",
        "        #Return two, one for input and the other for output\n",
        "        return one_hot[:,0:-1,:], one_hot[:,1:,:]\n",
        "\n",
        "X_train, Y_train = vectorize(smiles_train.values)\n",
        "X_test,Y_test = vectorize(smiles_test.values)\n",
        "print(smiles_train.iloc[0])\n",
        "plt.matshow(X_train[0].T)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjUkaKYNxnow"
      },
      "source": [
        "#The int_to_char dictionary can be used to go from vectorized form back to a readable string, here with a joined list comprehension.\n",
        "\"\".join([int_to_char[idx] for idx in np.argmax(X_train[0,:,:], axis=1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cngNY4U8nSF5"
      },
      "source": [
        "Agora é o momento para construir o AutoEncoder, começando por calcular as dimenções dos vetores de treino e tambem o numero de LSTM cells para utilização do decoder e encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emf6JhB5xt3M"
      },
      "source": [
        "#Import Keras objects\n",
        "input_shape = X_train.shape[1:]\n",
        "output_dim = Y_train.shape[-1]\n",
        "latent_dim = 512\n",
        "lstm_dim = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC0xOm4wyL5x"
      },
      "source": [
        "unroll = False\n",
        "encoder_inputs = Input(shape=input_shape)\n",
        "encoder        = LSTM(lstm_dim, return_state=True,unroll=unroll)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "states = Concatenate(axis=-1)([state_h, state_c])\n",
        "neck = Dense(latent_dim, activation=\"relu\")\n",
        "neck_outputs = neck(states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71yBmG3Tyry5"
      },
      "source": [
        "decode_h        = Dense(lstm_dim, activation=\"relu\")\n",
        "decode_c        = Dense(lstm_dim, activation=\"relu\")\n",
        "state_h_decoded = decode_h(neck_outputs)\n",
        "state_c_decoded = decode_c(neck_outputs)\n",
        "encoder_states  = [state_h_decoded, state_c_decoded]\n",
        "decoder_inputs  = Input(shape=input_shape)\n",
        "decoder_lstm    = LSTM(lstm_dim,return_sequences=True,unroll=unroll)\n",
        "decoder_outputs = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense   = Dense(output_dim, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "#Define the model, that inputs the training vector for two places, and predicts one character ahead of the input\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "print (model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4t5sDpi3pAa"
      },
      "source": [
        "from keras.callbacks import History, ReduceLROnPlateau\n",
        "from keras.optimizers import RMSprop, Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkLNZNHA9xiQ"
      },
      "source": [
        "print(X_test.shape)\n",
        "print(X_train.shape)\n",
        "print(len([X_train,X_train]))\n",
        "np.array(X_train).shape\n",
        "#np.array(X_test[1]).shape()\n",
        "#np.array(Y_test).shape()\n",
        "#[X_test,X_test].shape()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPndlB-GzC2P"
      },
      "source": [
        "h = History()\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=10, min_lr=0.000001, verbose=1, epsilon=1e-5)\n",
        "es = EarlyStopping(monitor='val_loss', min_delta = 0, patience = 5, verbose = True, mode ='auto')\n",
        "opt=Adam(lr=0.005) #Default 0.001 origem 0.005\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9gXrBhVAG1D"
      },
      "source": [
        "model.fit([X_train,X_train],Y_train,\n",
        "                    epochs=300,\n",
        "                    batch_size=256,\n",
        "                    shuffle=True,\n",
        "                    callbacks=[h, rlr, es],\n",
        "                    validation_data=([X_test,X_test],Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JatnAnKyg8QG"
      },
      "source": [
        "# Nova secção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MEwxBSxzp_B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "829ac489-bbce-49ec-9be8-94b58378d250"
      },
      "source": [
        "plt.plot(h.history[\"loss\"], label=\"Loss\")\n",
        "plt.plot(h.history[\"val_loss\"], label=\"Val_Loss\")\n",
        "plt.yscale(\"log\")\n",
        "plt.legend()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fabc47d8850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAFu5_3Rzp0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7aaf855-a748-4d3b-9282-3f2571273d6e"
      },
      "source": [
        "for i in range(100):\n",
        "    v = model.predict([X_test[i:i+1], X_test[i:i+1]]) #Can't be done as output not necessarely 1\n",
        "    idxs = np.argmax(v, axis=2)\n",
        "    pred=  \"\".join([int_to_char[h] for h in idxs[0]])[:-1]\n",
        "    idxs2 = np.argmax(X_test[i:i+1], axis=2)\n",
        "    true =  \"\".join([int_to_char[k] for k in idxs2[0]])[1:]\n",
        "    if true != pred:\n",
        "        print(true, pred)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O=C1Sc2ccccc2C(=O)N2CS(=O)CC12EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=C1CC2ccccc2C1=O)N1CCC=O)(C12EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CCOC(=O)NC(OCc1ccccc1)(C(=O)OC)C(F)(F)FEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(C(=O)CC(=)(1ccccc1)Cc)=O)cCCC(=)(F)FEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Nc1ncnc2c1ncn2C1OC(CO)(C(F)(F)F)C(O)C1OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C#1cc(c2c1ncncc1CC(C))CCO=)(F)F)C(F)C(OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cc1ccc(-c2n[nH]c(CC#N)n2)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1ccc(Cc2ccnH]c3=)CN)ccCcc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CCCCCC#COC1CC(C)CCC1C(C)CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(CCCCCCC(=CCCCC(C((C=)((EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CCN1CC2(COC)CCC(O)C34C5CC6C(OC)CC(O)(C5C6O)C(O)(C(OC)C23)C14EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC((CCC(C)C(C(CCCCC(CCCCCCCCCC(C(CC)CC)CCCCCCC)CC)C)(C())C1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cn1c(=O)sc2cc(C(=S)N3CCOCC3)ccc21EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1c(=O)cc2c((C)=O)NcCCCCC3)ccc2cEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COc1cc(OC)c(C=Cc2cc(C=Cc3c(OC)cc(OC)cc3OC)[n+](C)c3ccccc23)c(OC)c1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc1cccC))c(O(C22cccO)Cc3ccc))cccO))c(3CC)cnH]2C)c2ccccc33)ccO))c1OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CC1CNC2(c3ccccc3)CSC=C(c3ccccc3)N12EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=C(((C3ccccc3)C(C1C2C3ccccc3)C22EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CCCCCCCC(=O)[OH+][Co-4](N)(N)(N)(N)N.[O-][Cl+3]([O-])([O-])OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(CCCCCC=O)COH+][Cu-4](C((C)(C)([)[([N-]EOl+3]([O-])([O-])OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CN1C(=O)CN2C(Cl)(Cl)C2(c2ccccc2F)c2cc([N+](=O)[O-])ccc21EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(C(=O)C((C(=))CCl)C(=C3ccccc2))=1cccCN+](=O)[O-])ccc2CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CN(C)CCCN1c2ccccc2Sc2ccc(Cl)cc21EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(C)CCCC1C2ccccc2C(2ccccCl)cc2CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Nc1ncnc2c1ncn2C1CC(CO)C(CO)C1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C#1cc(c2c1ncncc1CCCC))C(O))C(OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "N#Cc1ccc(OCc2nc3cc(C(F)(F)F)ccc3nc2-c2ccccc2)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C#CC1ccc(CCc2cc3cccOl=)(F)F)ccc3nc2cc2ccccc2)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cc1nc2ccccc2c(=O)n1N1C2CCCC21EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1cc(ccccc2n1CO)n(CCCC=CCCC(EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CC(C)(C)C1COP(=O)(C(C)(C)C)OC1.CC(C)(C)C1COP(=O)(C(C)(C)C)OC1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=)(C)C(CCC(=O)(O(=)=C)C)CC(CClCC)CC)CECCC(=O)(O)C)CC)C)CC(CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "O=C1NC(N2CCOCC2)=NC1=Cc1ccccc1OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=C1CC(=CCCCC(2)CCC1=Oc1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CCOC(=O)c1c(O)cn2c1[nH]c1cccc3cccc2c31EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(C(=O)C1ccC)c((c(cnH]c1ccccccccccc1cEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cl.N=C(N)NN=Cc1c(Cl)nc2n1CCS2EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC.O=C(NCNC=C11ccC))cccccE(CCEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "C=CCCNCCC=C[Si](C)(C)CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCCCCC1(CCCCNH](C)(C)CCEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CC(=O)OC1C=C2c3cc4c(c(O)c3C(=O)NC2C(OC(C)=O)C1OC(C)=O)OCO4EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=O)OC1C(CCC3cccc(ccOCc3cC=O)CC(=C=)(C)=O)C(OC(C)=OECC(3EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CS(=O)(=O)Oc1cccc(C=NNC(=N)NO)c1.Cc1ccc(S(=O)(=O)O)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc=O)(OO)cC1cccccC(CNC(=O)NC)c2c[l1ccccC(=O)(=O)c)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Fc1cc(-c2ncc(Cl)cc2Cl)c2cccccc1-2EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE Cc1cccCc2cc3cCl)cc2)l)ccccccc2222EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "NC(=O)C(=O)n1ncc(Cl)c(Cl)c1=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C#(=O)C(CC)N1cc22C()ccCl)c1EOEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "C=CCCCCCCCCCOC1C=CC(O)C(CO)O1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCCCCCCCCCCCCCCCCCC(=CC(O))CCEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cc1c(NC(=S)NC(=O)c2ccc([N+](=O)[O-])cc2)c(=O)n(-c2ccccc2)n1CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1ccC)(=O)Nc(=O)c2ccccCN+](=O)[O-])cc2)cc=O)n(Cc1ccccc2)c1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Oc1nc(CC(O)c2ccc(Cl)c(Cl)c2)cc(-c2ccccc2)n1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=1cc(C)C=)C2ccccCl)ccCl)c2)cc1Cc2ccccc2)ccEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "O=C1OCCN1N1C(=O)CC2(CCCCC2)C1=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=C1CC(((C=CC=O)C(C(C)CCCC)C1EOEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cn1cccc(C(=O)c2ccccc2)c1=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1c((c1C(=O)N2ccccc2)ccCOEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CC(=O)OC1C(COC(N)=O)OC(n2c(-c3ccc(C)cc3)cc(-c3ccccc3)c(C#N)c2=O)C(OC(C)=O)C1OC(C)=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=O)OC1C(=()(=)=O)CC(C2cc=c3ccccClcc3)C(2Cc3ccccc3)c2=)N)c2CO)C(=)(C)=O)C(OC(C)=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Oc1nc2[nH]c(-c3ccc(Br)cc3)cc2c2ccccc12EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=1cc(cnH]c(=c3ccccCr)cc3)cc2c1ccccc22EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CCN(CC)c1ccc2cc(-n3nnc4ccccc43)c(=O)oc2c1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC((CC)C1ccc(c(cCc3ccc(ccccc4c)ccCO)nc2c1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CC(C)CCCC(C)C1CCC2C3CCC4CC(CCC=CCCC5CCC6(C)C(CCC7C6CCC6(C)C(C(C)CCCC(C)C)CCC76)C5)CCC4(C)C3CCC12CEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=)(CCCC=)C(CCC(C(CCCCCC(C)(CCC(CC(CCC(C)CCC)(4)6CCC4(C)C(C)C)=)(((C)C(C(((=)C(CCCCC(C)CCCCCC2EEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CSC(=S)Nc1cc(C)ccn1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc(=O)NC1cccClc(11CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CCCCCCc1ccc(C(=O)NO)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(CCCC1ccc(C==O)NcCc21EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CCOC(=O)c1nc2c3c(ncn2n1)Oc1c(c(-c2ccccc2)nn1-c1ccccc1)C3c1ccc(Cl)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(C(=O)C1cc2ccc(cc(cCcECC1ccCcCc2ccccc2)cc1Ec1ccccc1EC(C1ccccCl)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COc1ccc2c(c1)CSCC2=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc1ccc(c(c1)O(C(CEOEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cc1ccc(S(=O)(=O)ON=C2CCCC2=Cc2ccccc2)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1ccc(C(=O)(=O)cCCCcCCCCC)O(2ccccc2)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CCCCCCCCCCNC(C)=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(CCCCCCCCC(=)(C)EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cn1c(=O)c2c3ccccc3c(C(=O)c3ccccc3)n2c2ccccc21EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1c(=O)c2ccc(ccc3c(C)=O)O2ccccc3)ccC1ccccc21EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "NC(=O)c1ncn(CC2(COC(=O)c3ccccc3)CCC2)n1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C#(=O)C1cc(cC(CCC))(CO)C3ccccc3)c(22)ccEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COC(=O)C(NC(=O)OCc1ccccc1)(C(C)O)C(F)(F)FEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc(=O)C(=C(=O)CCC1ccccc1)Cc)=)=CC(=)(F)FEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COc1ccccc1NC(=O)C1=C(C)NC(C)=C(C(=O)Nc2ccccc2OC)C1c1ccc(C(C)C)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc1ccc((1CC(=O)C(CC(C(CC(=)(C(C(=O)Oc2ccccc2)))c1=1ccccCl=)()cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CNC(=O)CNC(=O)CCC(=O)N(C)CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC((=O)C(C(=O)C(CC=O)NcC)C(EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COC(=O)C(C(=NNC(=O)c1ccncc1)C(=O)Nc1ccccc1OC)c1nc2ccc(Cl)cc2nc1OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc(=O)C(=(=O)C(=O)c1ccccc1)C(=O)OC1ccccc1EEEC1cc2ccccCl)cc2111OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "c1ccc2c(c1)-n1nnnc1-c1nnnn1-2EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C1ccc(c(c1)Cc1cccc1Cc1cccc1EcEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cc1nc2ccc(S(=O)(=O)NS(=O)(=O)c3ccc(-c4ccccc4)cc3)cc2c(=O)n1NS(=O)(=O)c1ccc(-c2ccccc2)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1cc(ccccC(=O)(=O)cc(=O)(=O)c2ccccCc3ccccc4)cc3)cc2)c=O)n(CE(=O)(=O)c1ccccCc2ccccc2)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CC(=O)OC(C=C1C=CC(=O)O1)COC(=O)c1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=O)OC1C)CcCCCC(=O)CCEC(C(=O)C1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COc1cc(C)c2c(c1C=O)Oc1c(c(C)c(O)c3c1C(O)OC3=O)OC2=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc1cccC(c(c(c1)CC)cC1ccOcC)c2O)c2ccOC=)CC(EOECCCEOEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CN(C)C=C1C(Cl)=C(C=O)CC(C=O)=C1ClEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(C)CCCCCC=()CC(C(C)C(1C)C)CC1C(EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "N#Cc1c(-c2ccc(Cl)cc2)c(C#N)c(=O)n(NS(=O)(=O)c2ccccc2)c1-c1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C#CC1ccCc2ccccCl)cc2)ccC)N)cc=O)n1Cc(=O)(=O)c2ccccc2)ccEc1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COC1=CC(=O)C(CO)=CC1=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc(=C((=O)C(C(CCC((=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cc1cn(COCCCO[Si](C)(C)C(C)(C)C)c(=O)[nH]c1=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1cc(C2C(CCCnn](C)(C)C)C)(C)C)C1CO)nnH]c1=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CCCCCCCCCC=C(CC(=O)O)C(=O)OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(CCCCCCCCCCC)CCO)OCC(=O)OCEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COC(=O)c1ccc2c(c1)CC1(C2)Cc2cc3c(cc2C1)CCC3EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc(=O)C1ccc(c(c1)C(C(C)CC(2cccc(cc2O1=C(CCEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COC(=O)CC(c1ccc(OC)cc1)C(CC(=O)OC)c1ccc(OC)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc(=O)C((=1ccccC))c(1)C(=))=O)OC)C1ccccCC)c(1OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COc1ccc(OC)c(CCc2ccccc2CC(=O)O)c1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc1ccc(CCcc(O((2ccccc2)(1OO)NCc1OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Oc1nnnc2cc(Cl)ccc12EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=1cccc2c1cC))cc11CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COc1ccc(C(=O)O)c2c(=O)c3ccccc3[nH]c12EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc1ccc(C==O)NCc2cccO)n3ccccc3cnH]222EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "C#CC[N+](C)(CC#C)CC#C.[Br-]EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCCC(N+](C)(C)CN)C(CNEONr-]EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CCOC(=O)COS(=O)(=O)C(F)(F)FEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(C(=O)C(C(=O)(=O)c(C)(F)FEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CC12CCC3(C1)C(CC2=O)CC(OC(=O)c1ccccc1)C1C(C)(CO)CCCC13CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=CCCCCCCCC2=)(CC)C11C)(CO)C2ccccc1EC(CC=)(C))C((11EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "O=C1c2ccc([N+](=O)[O-])cc2C(=O)N1CC[PH](c1ccccc1)(c1ccccc1)c1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=C1C2ccccCN+](=O)[O-])cc2c1=O)NcC(CNH](c1ccccc1)Cc1ccccc1)C1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CCc1cc(Cc2cc(CC)c(NC(=O)C3=CC(=O)CC(c4ccc(OC)cc4)O3)c(CC)c2Cl)c(Cl)c(CC)c1NC(=O)C1=CC(=O)CC(c2ccc(OC)cc2)O1EEEEEEEEEEEEEEEE CC(1cccC(2cccC)CccOC(=O)C(CC((=O)C(C=3ccccCC)cc3)cC)ccO))c2)1)ccC))c1Cl(c1EC(=O)C(CCC(=O)C(CC2ccccC))cc2)CCEEEEEEEEEEEEEEEE\n",
            "CC1=C(C(=O)NCc2ccccc2)C(c2ccccc2O)C(C(=O)NCc2ccccc2)=C(C)N1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=C(C(=O)Oc(2ccccc2)C(=2ccccc2))c(=)=O)OC(2ccccc2)CC1C)C1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "N#Cc1c(C#N)c(-c2cccc([N+](=O)[O-])c2)n(-c2ccccc2)c1NEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C#CC1ccC)N)ccCc2cccccCN+](=O)[O-])c2)ccCc2ccccc2)ccEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CC1OC(OC2C(Oc3cc(O)c4c(=O)cc(-c5ccc(O)cc5)oc4c3)OC(CO)C(O)C2O)C(O)C(O)C1OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=C(=C(CCCC3cccOCc(c(cO)c4cCc3ccccCCcc3)cc3cc)CC2C))C(O)C(O)C1O)C1O)C(OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "O=C(NNC(=O)c1ccccc1O)c1ccco1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=C1OC=(=O)c1ccccc1))c1cccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "O=[N+]([O-])c1cc(C(F)(F)F)cc2c1SC1=Nc3ccccc3CN12EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=CN+]([O-])c1cccCl=)(F)F)cc1ccc(CCCC2ccccc3C11CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Nc1nc(Cl)c2ncn(C3OC(CO)CC3F)c2n1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C#1cc(N))cccc(cC)CC(CO)C(C))c(ccEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Nc1ccccc1N1C(=O)C(Cl)=C(Cl)C1=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C#1ccc(c1CCCC=O)C(=()CC(C()C(=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CC(C)(CN1CCCCC1)C(=O)CC(SCCS(=O)(=O)O)c1ccc(Br)cc1.Cl.[NaH]EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=)(C))CCCCCC)C(=O)C(C=((CC=O)(=O)OEC1ccccCr)cc1E[lE[NaH]EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CSC1=NN=C(SC)NN1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc(=CC(C(CCCcC=CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COc1c2occc2c(N)c2ccc(=O)oc12EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc1cccc(c2c(cCccccccCO)oc22EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "O=C1c2ccccc2C2(O)NC(=S)N(c3ccccc3)C12OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=C1C2ccccc2C(=C)C((=O)N1c2ccccc3)C22EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cc1nc(C(N)=S)sc1C(=O)C=Cc1c(O)ccc2ccccc12EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1cc(N)=)=O)cc2c(=O)N(Cc1ccC)ccccccccc12EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "C#CCN(Cc1ccc2nc(-c3ccccc3)c(Cl)nc2c1)c1cc(OC)c(OC)c(OC)c1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCCC(1CC1cccccc3Cc3ccccc3)ccC))cc2c1Ec1cccCC)ccOC)c1OC)c1OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COc1cc(-c2oc(C=Nc3ccccc3)c([N+](=O)[O-])c2-c2ccc(O)c(OC)c2)ccc1OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc1cccCc2cc(=)Cc3ccc(c3)ccCN+](=O)[O-])cc)c2ccccC)ccO))c2)cc11OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cc1ccc(SSC(=S)Nc2ccccc2)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1ccc(C(c(=O)Nc2ccccc2)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COc1cc(Cl)cc(O)c(=O)c1OCEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc1cccC()cc(CCc1CO)n1cC(EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cc1ccc(N2C(=O)C(=Cc3ccc(N(CCC#N)CCC#N)cc3C)N=C2c2cc([N+](=O)[O-])ccc2Cl)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1ccc(CCC(=O)C(=Oc3ccccCCC)CCN)cCCCN)cc2))cCC2CccccCN+](=O)[O-])ccc2C()cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "C=CC1=C(C)C2=[N+]3C1=Cc1c(C)c(C=C)c4n1[Fe-3]31(Cl)n3c(c(C)c(CCC(=O)O)c3=CC3=[N+]1C(=C4)C(C)=C3CCC(=O)O)=C2EEEEEEEEEEEEEEEEE CCCCCCCCC(C(CCN+]=(CCCC1ccC)ccC)CcccccENe-]]((C[))C1ccccC)c2C)CC=O)O)c2cO((CCN+](2(=OcCC(C)(C(C(CCCO)CCCC2EEEEEEEEEEEEEEEEE\n",
            "CCCCN(CCCC)CC(=O)Nc1ccc(C(=O)OCC(C)C)cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(CCCCCCCCC(C=O)CC1ccccCl=O)O))CC)()cc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COC(=O)C1=COC(C)C2C[n+]3ccc4c([nH]c5ccccc54)c3CC12EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc(=O)C(CC(C(=(((CCN+]1cccccccNH]c3ccccc4c)CccCC2EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cc1c(N)c(C#N)c2n(C)c3ncccc3n2c1=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1ccC)c(N)N)c(ccC)c(cc(cc2c2C1=OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "O=C(c1ccncc1)n1nc(-c2ccccc2)c(N=Nc2ccccc2[N+](=O)[O-])c1-c1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=C1O1ccccc1)c1cc2-c2ccccc2)ccC)Nc2ccc(c2)n+](=O)[O-])c1Ec1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Oc1ccc(C2Oc3cc(O)cc(C4c5c(cc(O)cc5C5C(c6ccc(O)cc6)OC(c6ccc(O)cc6)C5c5cc(O)cc(O)c5)OC4c4ccc(O)cc4)c3C2c2cc(O)cc(O)c2)cc1EEEE C=1ccc(C=CC3cccO)cccO(=3cccccOCc43cCCC=4ccccOCcc5ccC4=4ccccOCcc5cc(C4cccOCcccO)cc)cC4C4ccccOCcc4ccccC=1cccOCcccO)c3)cc1EEEE\n",
            "O=S(=O)(NCCSSCCNS(=O)(=O)c1ccccc1)c1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=C(=O)(Oc(CSCCCC(=O)(=O)c1ccccc1Ec1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CC(=O)C=Cc1cc([N+](=O)[O-])ccc1OEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=O)O(C11cccCN+](=O)[O-])cc11C)EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "C=C(CN)CO[Si](C)(C)C(C)(C)CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCCCC)CC(CSi](C)(C)CCC)(C)C(EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "O=C(NC(CSSCC(NC(=O)c1cnc2ccccc2n1)C(=O)O)C(=O)O)c1cnc2ccccc2n1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=C1OC(=)SC(C=)(=O)c1ccc2ccccc2c1)c(=O)NEc(=O)OEc1ccc2ccccc111EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Nc1c2ccccc2nc2ccc3c(=O)cc(-c4ccccc4)oc3c12EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C#1ccccccc2cc1cccccccO)nccCc3ccccc4)cc3c22EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CC(C)N(C)C(=O)C12C3C4C1C1C2C3C41C#NEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=)(1C)C(=O)N(CCCCCCCCCCCC3CCCC(NEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CC(C)N(C(=O)C12C3C4C5(C#N)C3C1(C#N)C5C42I)C(C)CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(=)(1C)=O)c(CCCCCCCCC)N)C(C42C)N)C1(CCEEC(=)((EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CN1CCN=C1c1nnn(-c2ccc([N+](=O)[O-])cc2)c1-c1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC(C(C(C(C2cccc-c2ccccCN+](=O)[O-])cc2)ccEc1ccccc1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cc1cc(C)nc(NC(=S)Nc2ccc(Cl)cc2)c1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1cccC)cc(NC(=O)Nc2ccc(Cl)cc2)ccEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "COc1ccc(C(CC(=O)c2ccc3c(c2)OCO3)c2c(O)c3ccccc3oc2=O)cc1OCEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CCc1ccc(C==)(=O)O2ccccccc2)cC)))ccccc)c3ccccc3c22=O)cc1ECEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "O=C1C(=Cc2c(O)cc(O)cc2O)C(=O)c2ccccc21EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE C=C1CC=Oc2ccC)cccC)c(2C)c(=O)N1ccccc21EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "CNC(=O)CCNC(=O)CCC(=O)OCEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC((=O)C((1(=O)C(CC=O)OCCEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
            "Cc1ccc2ccc(=O)oc2c1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE CC1ccc(c(ccCO)nc2c1CEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RprJYJ35Lx7h"
      },
      "source": [
        "smiles_to_latent_model = Model(encoder_inputs, neck_outputs)\n",
        "smiles_to_latent_model.save(\"Blog_simple_smi2lat.h5\")"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEvP9gatL04C"
      },
      "source": [
        "latent_input = Input(shape=(latent_dim,))\n",
        "#reuse_layers\n",
        "state_h_decoded_2 =  decode_h(latent_input)\n",
        "state_c_decoded_2 =  decode_c(latent_input)\n",
        "latent_to_states_model = Model(latent_input, [state_h_decoded_2, state_c_decoded_2])\n",
        "latent_to_states_model.save(\"Blog_simple_lat2state.h5\")"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGBUPPO3L20F"
      },
      "source": [
        "#Last one is special, we need to change it to stateful, and change the input shape\n",
        "inf_decoder_inputs = Input(batch_shape=(1, 1, input_shape[1]))\n",
        "inf_decoder_lstm = LSTM(lstm_dim,\n",
        "                    return_sequences=True,\n",
        "                    unroll=unroll,\n",
        "                    stateful=True\n",
        "                   )\n",
        "inf_decoder_outputs = inf_decoder_lstm(inf_decoder_inputs)\n",
        "inf_decoder_dense = Dense(output_dim, activation='softmax')\n",
        "inf_decoder_outputs = inf_decoder_dense(inf_decoder_outputs)\n",
        "sample_model = Model(inf_decoder_inputs, inf_decoder_outputs)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekLGFSpXL66n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3f406c-f36c-43b3-fd86-cf908d7d41c1"
      },
      "source": [
        "#Transfer Weights\n",
        "for i in range(1,3):\n",
        "    sample_model.layers[i].set_weights(model.layers[i+6].get_weights())\n",
        "sample_model.save(\"Blog_simple_samplemodel.h5\")\n",
        "sample_model.summary()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_27 (InputLayer)        [(1, 1, 58)]              0         \n",
            "_________________________________________________________________\n",
            "lstm_23 (LSTM)               (1, 1, 512)               1169408   \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (1, 1, 58)                29754     \n",
            "=================================================================\n",
            "Total params: 1,199,162\n",
            "Trainable params: 1,199,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFXgMqVmP9mD"
      },
      "source": [
        "def latent_to_smiles(latent):\n",
        "    #decode states and set Reset the LSTM cells with them\n",
        "    states = latent_to_states_model.predict(latent)\n",
        "    sample_model.layers[1].reset_states(states=[states[0],states[1]])\n",
        "    #Prepare the input char\n",
        "    startidx = char_to_int[\"!\"]\n",
        "    samplevec = np.zeros((1,1,22))\n",
        "    samplevec[0,0,startidx] = 1\n",
        "    smiles = \"\"\n",
        "    #Loop and predict next char\n",
        "    for i in range(28):\n",
        "        o = sample_model.predict(samplevec)\n",
        "        sampleidx = np.argmax(o)\n",
        "        samplechar = int_to_char[sampleidx]\n",
        "        if samplechar != \"E\":\n",
        "            smiles = smiles + int_to_char[sampleidx]\n",
        "            samplevec = np.zeros((1,1,22))\n",
        "            samplevec[0,0,sampleidx] = 1\n",
        "        else:\n",
        "            break\n",
        "    return smiles"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zcMjEWcOOaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7327c43f-e618-4dde-f9a1-a4af80719910"
      },
      "source": [
        "#Model LogP?\n",
        "x_train_latent = smiles_to_latent_model.predict(X_train)\n",
        "logp_train = smiles_train.apply(Chem.MolFromSmiles).apply(Descriptors.MolLogP)\n",
        "from keras.models import Sequential\n",
        "logp_model = Sequential()\n",
        "logp_model.add(Dense(128, input_shape=(latent_dim,), activation=\"relu\"))\n",
        "logp_model.add(Dense(128, activation=\"relu\"))\n",
        "logp_model.add(Dense(1))\n",
        "logp_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=10, min_lr=0.000001, verbose=1, epsilon=1e-5)\n",
        "logp_model.fit(x_train_latent, logp_train, batch_size=128, epochs=400, callbacks = [rlr])\n"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "Epoch 1/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 281915.7561\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 2/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5319\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 3/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.6858\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 4/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.3176\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 5/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 9.0341\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 6/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 9.0993\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 7/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 163.6475\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 8/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 845.7269\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 9/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 4168.6806\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 10/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 20441.1214\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 11/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.3468\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 12/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.4261\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 13/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.2631\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 14/400\n",
            "238/238 [==============================] - 0s 2ms/step - loss: 7.3757\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 15/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 7.6041\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 16/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 10.8878\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 17/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 238.5318\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 18/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 723.0554\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 19/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 442.7279\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 20/400\n",
            "238/238 [==============================] - 0s 2ms/step - loss: 236.9317\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 21/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 56.5402\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 22/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 236.9551\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 23/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 239.3989\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 24/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 541.0516\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 25/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 210.3708\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 26/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 256.6530\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 27/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 52.5043\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 28/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 54.5704\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 29/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 171.9039\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 30/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 3500.8199\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 31/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 8.8087\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 32/400\n",
            "238/238 [==============================] - 0s 2ms/step - loss: 6.1870\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 33/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.0792\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 34/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.7702\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 35/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 7.2589\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 36/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 7.0277\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 37/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 11.1643\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 38/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 23.3892\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 39/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 44.7955\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 40/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 67.6712\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 41/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 74.6979\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 42/400\n",
            "238/238 [==============================] - 0s 2ms/step - loss: 41.9117\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 43/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 34.6539\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 44/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 40.8242\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 45/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 27.5586\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 46/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 24.7463\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 47/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 32.0191\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 48/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 26.2081\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 49/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 18.8041\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 50/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 25.3693\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 51/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 19.5597\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 52/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 13.4873\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 53/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 13.2309\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 54/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 19.5232\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 55/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 14.4346\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 56/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 10.7363\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 57/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 15.2308\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 58/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 11.9203\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 59/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 8.8514\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 60/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 9.2393\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 61/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 7.3935\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 62/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 8.8705\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 63/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.5122\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 64/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 853.8457\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 65/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.7598\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 66/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.7855\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 67/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.8609\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 68/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.0175\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 69/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.1031\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 70/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.9316\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 71/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.1083\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 72/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.2586\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 73/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.9738\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 74/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.2589\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 75/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 7.0393\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 76/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.9453\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 77/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 7.6850\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 78/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 8.5746\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 79/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.3650\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 80/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 7.2181\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 81/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.8646\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 82/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.7960\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 83/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 7.4236\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 84/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 7.0304\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 85/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.8241\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 86/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.9990\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 87/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.5483\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 88/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.9486\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 89/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.8420\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 90/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.0356\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 91/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.7788\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 92/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.6803\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 93/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5619\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 94/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.8871\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 95/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5525\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 96/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.6292\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 97/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5359\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 98/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4347\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 99/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4835\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 100/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5605\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 101/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4280\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 102/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5763\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 103/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5819\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 104/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.6587\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 105/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5374\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 106/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4257\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 107/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5022\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 108/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5788\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 109/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5541\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 110/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.7861\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 111/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4364\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 112/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5285\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 113/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5544\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 114/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5866\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 115/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5672\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 116/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5419\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 117/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.6037\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 118/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.6826\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 119/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5869\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 120/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.6526\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 121/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4912\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 122/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 24.2285\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 123/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 6.6207\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 124/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.8574\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 125/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.6408\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 126/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4600\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 127/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5694\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 128/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.2548\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 129/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3336\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 130/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4445\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 131/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.5417\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 132/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3679\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 133/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5669\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 134/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3380\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 135/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4251\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 136/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4845\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 137/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3568\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 138/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4427\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 139/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4986\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 140/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4135\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 141/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5425\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 142/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5366\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 143/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4448\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 144/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4121\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 145/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3462\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 146/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4833\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 147/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4954\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 148/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3985\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 149/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4778\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 150/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4268\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 151/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5167\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 152/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3913\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 153/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4189\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 154/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4728\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 155/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3706\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 156/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5028\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 157/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4424\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 158/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5253\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 159/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4294\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 160/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3777\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 161/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5260\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 162/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4930\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 163/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4182\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 164/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4734\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 165/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3797\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 166/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5234\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 167/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4301\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 168/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3902\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 169/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4536\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 170/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4042\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 171/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4492\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 172/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3840\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 173/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4034\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 174/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3801\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 175/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.6469\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 176/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5593\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 177/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3678\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 178/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4457\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 179/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.2911\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 180/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3292\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 181/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4423\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 182/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5312\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 183/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5153\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 184/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4584\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 185/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5068\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 186/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4944\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 187/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4378\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 188/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3895\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 189/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3541\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 190/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5218\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 191/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3889\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 192/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5439\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 193/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4077\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 194/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4007\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 195/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5155\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 196/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3308\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 197/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4692\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 198/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3584\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 199/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4505\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 200/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4201\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 201/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4364\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 202/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3242\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 203/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3990\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 204/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4119\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 205/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3834\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 206/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4340\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 207/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4384\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 208/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3966\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 209/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5151\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 210/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4996\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 211/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3942\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 212/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3708\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 213/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4595\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 214/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4123\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 215/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4535\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 216/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3165\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 217/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4617\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 218/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4127\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 219/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4673\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 220/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4861\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 221/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4148\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 222/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5409\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 223/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4075\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 224/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4798\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 225/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3787\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 226/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4591\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 227/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3023\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 228/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3995\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 229/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4416\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 230/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4524\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 231/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4175\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 232/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3464\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 233/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4858\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 234/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4829\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 235/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3147\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 236/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5300\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 237/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3974\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 238/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4728\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 239/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3277\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 240/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3764\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 241/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4642\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 242/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5066\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 243/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3623\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 244/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3460\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 245/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4187\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 246/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5425\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 247/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.5399\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 248/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4057\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 249/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3904\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 250/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4976\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 251/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4769\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 252/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4079\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 253/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4960\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 254/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3752\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 255/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4436\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 256/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3399\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 257/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5569\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 258/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4433\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 259/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4914\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 260/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.6078\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 261/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3482\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 262/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4362\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 263/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3207\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 264/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5984\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 265/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5164\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 266/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3372\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 267/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3961\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 268/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4876\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 269/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4784\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 270/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4439\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 271/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3712\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 272/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4630\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 273/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4426\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 274/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4609\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 275/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5344\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 276/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4177\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 277/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3152\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 278/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4786\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 279/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3894\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 280/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4363\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 281/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3325\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 282/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4473\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 283/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3467\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 284/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5667\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 285/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4208\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 286/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4230\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 287/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3451\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 288/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3911\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 289/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4637\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 290/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4748\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 291/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4279\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 292/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5475\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 293/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4865\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 294/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4193\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 295/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5369\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 296/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4681\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 297/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.2771\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 298/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4574\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 299/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4460\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 300/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4309\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 301/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.5000\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 302/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4397\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 303/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4766\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 304/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4033\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 305/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4543\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 306/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4948\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 307/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4081\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 308/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3474\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 309/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4513\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 310/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3974\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 311/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4703\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 312/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3794\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 313/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3312\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 314/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4528\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 315/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5352\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 316/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5615\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 317/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5141\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 318/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3062\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 319/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4914\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 320/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4536\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 321/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4712\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 322/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4213\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 323/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.2867\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 324/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.5213\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 325/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4197\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 326/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.5742\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 327/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4114\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 328/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3971\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 329/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3815\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 330/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4128\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 331/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4799\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 332/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4890\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 333/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3903\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 334/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4749\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 335/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.5072\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 336/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4104\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 337/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4478\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 338/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4348\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 339/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3873\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 340/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5103\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 341/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4353\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 342/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4853\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 343/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4817\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 344/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5062\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 345/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4914\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 346/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3725\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 347/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4757\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 348/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.5113\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 349/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3851\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 350/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.5220\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 351/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4908\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 352/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.2994\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 353/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3936\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 354/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4119\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 355/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4406\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 356/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3721\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 357/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4987\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 358/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3992\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 359/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4047\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 360/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4945\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 361/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3718\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 362/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5742\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 363/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3737\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 364/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5314\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 365/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4439\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 366/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4134\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 367/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3314\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 368/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4585\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 369/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4227\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 370/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4397\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 371/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.5075\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 372/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3958\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 373/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4597\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 374/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4174\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 375/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.5752\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 376/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4669\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 377/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3162\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 378/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3248\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 379/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4655\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 380/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4450\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 381/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4696\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 382/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4100\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 383/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4411\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 384/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3994\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 385/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4380\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 386/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4043\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 387/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4563\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 388/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3561\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 389/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4655\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 390/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3531\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 391/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4980\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 392/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.3824\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 393/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.5498\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 394/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.5252\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 395/400\n",
            "238/238 [==============================] - 1s 2ms/step - loss: 5.4179\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 396/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3857\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 397/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4809\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 398/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.4693\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 399/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.3869\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
            "Epoch 400/400\n",
            "238/238 [==============================] - 1s 3ms/step - loss: 5.5028\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7facb1299a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdxH0pUYP_Yg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "3f187423-a895-479e-8eda-596d4182aee1"
      },
      "source": [
        "logp_pred_train = logp_model.predict(x_train_latent)\n",
        "logp_pred_test = logp_model.predict(x_latent)\n",
        "plt.scatter(logp, logp_pred_test, label=\"Test\")\n",
        "plt.scatter(logp_train, logp_pred_train, label=\"Train\")\n",
        "plt.legend()"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-163-29d8bd98ddda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogp_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogp_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected axis -1 of input shape to have value 512 but received input with shape (None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3h1uzBoRsEc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}