{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd05a32229f79db43f07d72d9c56c5ffd133bcfb31fffe276eac449177781abc69c",
   "display_name": "Python 3.9.5 64-bit ('cd_aa2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Random Forest with SMILES Embeddings from BERT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Make sure that the parent directory is on our python path"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "source": [
    "Install necessary packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: deepchem in /usr/local/Caskroom/miniconda/base/envs/cd_aa2/lib/python3.9/site-packages (2.5.0)\n",
      "Requirement already satisfied: scipy in /usr/local/Caskroom/miniconda/base/envs/cd_aa2/lib/python3.9/site-packages (from deepchem) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/Caskroom/miniconda/base/envs/cd_aa2/lib/python3.9/site-packages (from deepchem) (0.24.2)\n",
      "Requirement already satisfied: joblib in /usr/local/Caskroom/miniconda/base/envs/cd_aa2/lib/python3.9/site-packages (from deepchem) (1.0.1)\n",
      "Requirement already satisfied: numpy in /usr/local/Caskroom/miniconda/base/envs/cd_aa2/lib/python3.9/site-packages (from deepchem) (1.19.5)\n",
      "Requirement already satisfied: pandas in /usr/local/Caskroom/miniconda/base/envs/cd_aa2/lib/python3.9/site-packages (from deepchem) (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/Caskroom/miniconda/base/envs/cd_aa2/lib/python3.9/site-packages (from pandas->deepchem) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/Caskroom/miniconda/base/envs/cd_aa2/lib/python3.9/site-packages (from pandas->deepchem) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Caskroom/miniconda/base/envs/cd_aa2/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/Caskroom/miniconda/base/envs/cd_aa2/lib/python3.9/site-packages (from scikit-learn->deepchem) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install deepchem"
   ]
  },
  {
   "source": [
    "Load dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mols_shape:  40358\nFeatures_shape:  (40358, 768)\nLabels_shape:  (40358,)\n"
     ]
    }
   ],
   "source": [
    "from loaders.Loaders import CSVLoader\n",
    "\n",
    "dataset = CSVLoader(dataset_path='../data/HIV_featurized.csv',\n",
    "                    mols_field='mols',\n",
    "                    features_fields='X', \n",
    "                    labels_fields='y')\n",
    "\n",
    "dataset = dataset.create_dataset()\n",
    "dataset.splitFeatures()\n",
    "dataset.get_shape()"
   ]
  },
  {
   "source": [
    "Data split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splitters.splitters import SingletaskStratifiedSplitter\n",
    "\n",
    "splitter = SingletaskStratifiedSplitter()\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset=dataset, \n",
    "                                                                             frac_train=0.6, \n",
    "                                                                             frac_valid=0.2, \n",
    "                                                                             frac_test=0.2)"
   ]
  },
  {
   "source": [
    "Random Forest from Scikit-Learn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from models.sklearnModels import SklearnModel\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "model = SklearnModel(model=rf)"
   ]
  },
  {
   "source": [
    "Cross validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computing Stratified K-fold split\n",
      "\n",
      "Split 1 :\n",
      "Train Score: \n",
      "roc_auc_score: \n",
      " 1.0\n",
      "Test Score: \n",
      "roc_auc_score: \n",
      " 0.5587288714505411\n",
      "\n",
      "Split 2 :\n",
      "Train Score: \n",
      "roc_auc_score: \n",
      " 0.9994419642857143\n",
      "Test Score: \n",
      "roc_auc_score: \n",
      " 0.547452816911078\n",
      "\n",
      "Split 3 :\n",
      "Train Score: \n",
      "roc_auc_score: \n",
      " 1.0\n",
      "Test Score: \n",
      "roc_auc_score: \n",
      " 0.553803156721009\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(SklearnModel(model=RandomForestClassifier()),\n",
       " 1.0,\n",
       " 0.5587288714505411,\n",
       " [1.0, 0.9994419642857143, 1.0],\n",
       " [0.5587288714505411, 0.547452816911078, 0.553803156721009],\n",
       " 0.9998139880952381,\n",
       " 0.5533282816942093)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "from metrics.Metrics import Metric\n",
    "from metrics.metricsFunctions import roc_auc_score\n",
    "\n",
    "model.cross_validate(dataset, Metric(roc_auc_score), folds=3)"
   ]
  },
  {
   "source": [
    "Model training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#############################\n",
      "Training Dataset: \n",
      "roc_auc_score: \n",
      " 0.9993757802746567\n",
      "precision_score: \n",
      " 1.0\n",
      "accuracy_score: \n",
      " 0.9999586947542338\n",
      "confusion_matrix: \n",
      " [[23409     0]\n",
      " [    1   800]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     23409\n",
      "           1       1.00      1.00      1.00       801\n",
      "\n",
      "    accuracy                           1.00     24210\n",
      "   macro avg       1.00      1.00      1.00     24210\n",
      "weighted avg       1.00      1.00      1.00     24210\n",
      "\n",
      "WARNING: task averager  cannot perform reduce with flexible type\n",
      "#############################\n",
      "Validation Dataset: \n",
      "roc_auc_score: \n",
      " 0.5556671519309053\n",
      "precision_score: \n",
      " 0.7894736842105263\n",
      "accuracy_score: \n",
      " 0.969640644361834\n",
      "confusion_matrix: \n",
      " [[7795    8]\n",
      " [ 237   30]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7803\n",
      "           1       0.79      0.11      0.20       267\n",
      "\n",
      "    accuracy                           0.97      8070\n",
      "   macro avg       0.88      0.56      0.59      8070\n",
      "weighted avg       0.96      0.97      0.96      8070\n",
      "\n",
      "WARNING: task averager  cannot perform reduce with flexible type\n",
      "#############################\n",
      "Test Dataset: \n",
      "roc_auc_score: \n",
      " 0.5422695864435831\n",
      "precision_score: \n",
      " 0.696969696969697\n",
      "accuracy_score: \n",
      " 0.9684014869888475\n",
      "confusion_matrix: \n",
      " [[7792   10]\n",
      " [ 245   23]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7802\n",
      "           1       0.70      0.09      0.15       268\n",
      "\n",
      "    accuracy                           0.97      8070\n",
      "   macro avg       0.83      0.54      0.57      8070\n",
      "weighted avg       0.96      0.97      0.96      8070\n",
      "\n",
      "WARNING: task averager  cannot perform reduce with flexible type\n",
      "#############################\n"
     ]
    }
   ],
   "source": [
    "from metrics.metricsFunctions import precision_score, accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "metrics = [Metric(roc_auc_score), Metric(precision_score), Metric(accuracy_score), Metric(confusion_matrix), \n",
    "           Metric(classification_report)]\n",
    "print(\"#############################\")\n",
    "# evaluate the model\n",
    "print('Training Dataset: ')\n",
    "train_score = model.evaluate(train_dataset, metrics)\n",
    "print(\"#############################\")\n",
    "print('Validation Dataset: ')\n",
    "valid_score = model.evaluate(valid_dataset, metrics)\n",
    "print(\"#############################\")\n",
    "print('Test Dataset: ')\n",
    "test_score = model.evaluate(test_dataset, metrics)\n",
    "print(\"#############################\")"
   ]
  }
 ]
}