{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48038994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from loaders.Loaders import SDFLoader, CSVLoader\n",
    "from metrics.Metrics import Metric\n",
    "from models.DeepChemModels import DeepChemModel\n",
    "from models.kerasModels import KerasModel\n",
    "from models.sklearnModels import SklearnModel\n",
    "from splitters.splitters import SingletaskStratifiedSplitter\n",
    "from utils import utils as preproc\n",
    "\n",
    "config_tf = tf.compat.v1.ConfigProto()\n",
    "config_tf.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config_tf)\n",
    "set_session(sess)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "56d56a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [22:54:03] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:03] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:03] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:03] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:03] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:03] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:03] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:03] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:03] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:03] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:04] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:04] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:04] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:04] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:04] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:04] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:04] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:04] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:04] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:04] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:09] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:09] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:14] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:14] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [22:54:15] Warning: molecule is tagged as 3D, but all Z coords are zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25795 molecules after 1 attempts.\n",
      "Featurizing datapoint 0\n",
      "error in molecule: <rdkit.Chem.rdchem.Mol object at 0x7f698f7e6ee0>\n",
      "Featurizing datapoint 1000\n",
      "Featurizing datapoint 2000\n",
      "Featurizing datapoint 3000\n",
      "Elements with indexes:  [559]  were removed due to the presence of NAs!\n",
      "The elements in question are:  [<rdkit.Chem.rdchem.Mol object at 0x7f698f7e6ee0>]\n",
      "Featurizing datapoint 0\n",
      "Featurizing datapoint 1000\n",
      "Featurizing datapoint 2000\n",
      "Featurizing datapoint 3000\n",
      "Featurizing datapoint 0\n",
      "error in molecule: <rdkit.Chem.rdchem.Mol object at 0x7f698f7e6ee0>\n",
      "Featurizing datapoint 1000\n",
      "Featurizing datapoint 2000\n",
      "Featurizing datapoint 3000\n",
      "Elements with indexes:  [559]  were removed due to the presence of NAs!\n",
      "The elements in question are:  [<rdkit.Chem.rdchem.Mol object at 0x7f698f7e6ee0>]\n"
     ]
    }
   ],
   "source": [
    "from compoundFeaturization.rdkitFingerprints import MorganFingerprint,AtomPairFingerprint\n",
    "from compoundFeaturization.mixedDescriptors import MixedFeaturizer\n",
    "from compoundFeaturization.mordredDescriptors import MordredFeaturizer, Mordred3DFeaturizer\n",
    "from copy import copy\n",
    "\n",
    "loader = SDFLoader(\"./data/dataset_sweet_3D.sdf\", \"_SourceID\", labels_fields=[\"_SWEET\"])\n",
    "dataset = loader.create_dataset()\n",
    "\n",
    "dataset.sample_part(0, 1800)\n",
    "\n",
    "from compoundFeaturization.rdkit3DDescriptors import All3DDescriptors\n",
    "\n",
    "dataset_3d = All3DDescriptors().featurize(copy(dataset))\n",
    "dataset_morgan = MorganFingerprint().featurize(copy(dataset))\n",
    "dataset_mixed = MixedFeaturizer([All3DDescriptors(),MorganFingerprint()],1024+973).featurize(copy(dataset))\n",
    "\n",
    "\n",
    "splitter = SingletaskStratifiedSplitter()\n",
    "train_dataset_morgan, valid_dataset_morgan, test_dataset_morgan = splitter.train_valid_test_split(\n",
    "    dataset=dataset_morgan,\n",
    "    frac_train=0.6,\n",
    "    frac_valid=0.15,\n",
    "    frac_test=0.25)\n",
    "\n",
    "train_dataset_3d, valid_dataset_3d, test_dataset_3d = splitter.train_valid_test_split(\n",
    "    dataset=dataset_3d,\n",
    "    frac_train=0.6,\n",
    "    frac_valid=0.15,\n",
    "    frac_test=0.25)\n",
    "\n",
    "train_dataset_mixed, valid_dataset_mixed, test_dataset_mixed = splitter.train_valid_test_split(\n",
    "    dataset=dataset_mixed,\n",
    "    frac_train=0.6,\n",
    "    frac_valid=0.15,\n",
    "    frac_test=0.25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9654384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:35] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:40] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:40] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:46] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:46] Warning: molecule is tagged as 3D, but all Z coords are zero\n",
      "RDKit WARNING: [14:39:46] Warning: molecule is tagged as 3D, but all Z coords are zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25795 molecules after 1 attempts.\n",
      "Featurizing datapoint 0\n",
      "Featurizing datapoint 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcapela/miniconda3/envs/deepmol/lib/python3.9/site-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizing datapoint 400\n",
      "Featurizing datapoint 600\n",
      "Featurizing datapoint 800\n",
      "Featurizing datapoint 1000\n",
      "Featurizing datapoint 1200\n",
      "Featurizing datapoint 1400\n",
      "Featurizing datapoint 1600\n",
      "Featurizing datapoint 1800\n",
      "Featurizing datapoint 2000\n",
      "Featurizing datapoint 2200\n",
      "Featurizing datapoint 2400\n",
      "Featurizing datapoint 2600\n",
      "Featurizing datapoint 2800\n",
      "Featurizing datapoint 3000\n",
      "Featurizing datapoint 3200\n",
      "Featurizing datapoint 3400\n",
      "Featurizing datapoint 3600\n",
      "Columns in indexes:  (array([  15,   53,   54,   55,   56,   57,   58,   59,   60,   61,  136,\n",
      "        137,  138,  139,  140,  141,  142,  145,  146,  147,  148,  149,\n",
      "        150,  151,  152,  153,  154,  155,  156,  157,  158,  159,  160,\n",
      "        163,  164,  165,  166,  167,  168,  169,  172,  173,  174,  175,\n",
      "        176,  177,  178,  181,  182,  183,  184,  185,  186,  187,  190,\n",
      "        191,  192,  193,  194,  195,  196,  199,  200,  201,  202,  203,\n",
      "        204,  205,  208,  209,  210,  211,  212,  213,  214,  217,  218,\n",
      "        219,  220,  221,  222,  223,  226,  227,  228,  229,  230,  231,\n",
      "        232,  233,  234,  235,  236,  237,  238,  239,  240,  241,  260,\n",
      "        261,  262,  263,  264,  265,  266,  267,  268,  341,  342,  343,\n",
      "        344,  345,  346,  347,  348,  349,  352,  353,  354,  355,  356,\n",
      "        357,  358,  361,  362,  363,  364,  365,  366,  367,  368,  369,\n",
      "        370,  371,  372,  373,  374,  375,  376,  379,  380,  381,  382,\n",
      "        383,  384,  385,  388,  389,  390,  391,  392,  393,  394,  397,\n",
      "        398,  399,  400,  401,  402,  403,  406,  407,  408,  409,  410,\n",
      "        411,  412,  415,  416,  417,  418,  419,  420,  421,  424,  425,\n",
      "        426,  427,  428,  429,  430,  433,  434,  435,  436,  437,  438,\n",
      "        439,  442,  443,  444,  445,  446,  447,  448,  449,  450,  451,\n",
      "        452,  453,  454,  455,  456,  457,  458,  459,  460,  461,  462,\n",
      "        463,  464,  465,  466,  467,  468,  469,  470,  471,  472,  473,\n",
      "        474,  475,  476,  477,  478,  479,  480,  482,  483,  484,  485,\n",
      "        486,  487,  488,  490,  491,  492,  493,  494,  495,  496,  498,\n",
      "        499,  500,  501,  502,  503,  504,  506,  507,  508,  509,  510,\n",
      "        511,  512,  514,  515,  516,  517,  518,  519,  520,  522,  523,\n",
      "        524,  525,  526,  527,  528,  530,  531,  532,  533,  534,  535,\n",
      "        536,  538,  539,  540,  541,  542,  543,  544,  545,  546,  547,\n",
      "        548,  549,  550,  551,  552,  553,  554,  555,  556,  557,  558,\n",
      "        559,  560,  561,  562,  563,  564,  565,  566,  567,  568,  569,\n",
      "        570,  571,  572,  573,  574,  575,  576,  578,  579,  580,  581,\n",
      "        582,  583,  584,  586,  587,  588,  589,  590,  591,  592,  594,\n",
      "        595,  596,  597,  598,  599,  600,  602,  603,  604,  605,  606,\n",
      "        607,  608,  610,  611,  612,  613,  614,  615,  616,  618,  619,\n",
      "        620,  621,  622,  623,  624,  626,  627,  628,  629,  630,  631,\n",
      "        632,  634,  635,  636,  637,  638,  639,  640,  641,  642,  647,\n",
      "        648,  678,  691,  704,  717,  730,  743,  756,  769,  780,  781,\n",
      "        782,  783,  784,  785,  786,  787,  788,  789,  790,  791,  792,\n",
      "        793,  794,  795,  796,  797,  798,  799,  800,  801,  802,  803,\n",
      "        804,  805,  806,  807,  808,  809,  810,  811,  812,  813,  814,\n",
      "        815,  816,  817,  818,  819,  820,  821,  822,  832,  858,  866,\n",
      "        867,  868,  869,  870,  871,  872,  873,  874,  882,  883,  884,\n",
      "        885,  886,  887,  888,  889,  906,  907,  908,  909,  910,  911,\n",
      "        912,  913,  914,  915,  916,  917,  918,  919,  931, 1090, 1091,\n",
      "       1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102,\n",
      "       1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113,\n",
      "       1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124,\n",
      "       1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135,\n",
      "       1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146,\n",
      "       1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157,\n",
      "       1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168,\n",
      "       1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179,\n",
      "       1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190,\n",
      "       1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201,\n",
      "       1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212,\n",
      "       1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,\n",
      "       1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234,\n",
      "       1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245,\n",
      "       1246, 1247, 1274, 1275, 1276, 1277, 1301, 1303, 1324, 1325, 1326,\n",
      "       1327, 1328, 1329, 1348, 1349, 1350, 1356, 1357, 1358, 1359, 1360,\n",
      "       1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371,\n",
      "       1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382,\n",
      "       1383, 1384, 1385, 1386, 1388, 1389, 1390, 1391, 1392, 1393, 1394,\n",
      "       1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405,\n",
      "       1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416,\n",
      "       1417, 1418, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428,\n",
      "       1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439,\n",
      "       1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450,\n",
      "       1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462,\n",
      "       1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473,\n",
      "       1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1484, 1485,\n",
      "       1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496,\n",
      "       1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507,\n",
      "       1508, 1509, 1510, 1511, 1512, 1513, 1514, 1568, 1569, 1570, 1571,\n",
      "       1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582,\n",
      "       1583, 1584, 1585, 1586, 1765, 1793, 1794, 1795, 1796, 1824]),)  were removed due to the presence of NAs!\n"
     ]
    }
   ],
   "source": [
    "from compoundFeaturization import mordredDescriptors\n",
    "from copy import copy\n",
    "from loaders.Loaders import SDFLoader\n",
    "\n",
    "loader = SDFLoader(\"./data/dataset_sweet_3D.sdf\", \"_SourceID\", labels_fields=[\"_SWEET\"])\n",
    "dataset = loader.create_dataset()\n",
    "\n",
    "dataset.sample_part(0, 1800)\n",
    "\n",
    "dataset_mordred = mordredDescriptors.MordredFeaturizer().featurize(copy(dataset),log_every_n = 200,scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b39a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SingletaskStratifiedSplitter()\n",
    "train_dataset_mordred, valid_dataset_mordred, test_dataset_mordred = splitter.train_valid_test_split(\n",
    "    dataset=dataset_mordred,\n",
    "    frac_train=0.6,\n",
    "    frac_valid=0.15,\n",
    "    frac_test=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "539c8895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(units1 = 512, units2 = 512, dropout_rate=0.0, hidden_layers=1, l1 = 0, l2 = 0, \n",
    "                        optimizer = 'adam', batchNormalization = True):\n",
    "    # create model\n",
    "    print(\"unit1: \", units1)\n",
    "    print('dropout_rate = ', dropout_rate)\n",
    "    model = Sequential()\n",
    "    #model.add(BatchNormalization(scale=True))\n",
    "    model.add(Dense(units=units1, activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for i in range(hidden_layers):\n",
    "        model.add(Dense(units=units2, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    ##Compile model and make it ready for optimization\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    # Reduce lr callback\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2bc204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "def train_dnn(train_dataset,validation_dataset):\n",
    "    \n",
    "    # simple early stopping\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=100)\n",
    "    # reduce learning rate\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=100, min_lr=0.00001, verbose=1)\n",
    "\n",
    "    callbacks = [reduce_lr]\n",
    "    #callbacks = [reduce_lr]\n",
    "    #Training\n",
    "\n",
    "    units = int(train_dataset.X.shape[1]//2)\n",
    "    \n",
    "    #units = 1452\n",
    "\n",
    "    model = KerasModel(create_model, optimizer = 'adam', dropout_rate = 0.5, hidden_layers = 1, \n",
    "                       l1 = 0.001, l2 = 0.01,units1 = units,units2 = units*2, batch_size= 50, epochs = 500,\n",
    "                       callbacks=callbacks, validation_data = (validation_dataset.X, validation_dataset.y), \n",
    "                       verbose = 1)\n",
    "\n",
    "\n",
    "    history = model.fit(train_dataset)\n",
    "    \n",
    "    return model\n",
    "\n",
    "    #model.fit(train_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0bae98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, precision_score, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def validate_model(model,train_dataset,valid_dataset,test_dataset):\n",
    "    \n",
    "    metrics = [Metric(roc_auc_score), Metric(precision_score),\n",
    "           Metric(accuracy_score), Metric(confusion_matrix),\n",
    "           Metric(classification_report)]\n",
    "\n",
    "    print(\"#############################\")\n",
    "    # evaluate the model\n",
    "    print('Training Dataset: ')\n",
    "    train_score = model.evaluate(train_dataset, metrics)\n",
    "\n",
    "    print('Validation Dataset: ')\n",
    "    valid_score = model.evaluate(valid_dataset, metrics)\n",
    "\n",
    "    print('Test Dataset: ')\n",
    "    test_score = model.evaluate(test_dataset, metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e645f696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcapela/miniconda3/envs/deepmol/lib/python3.9/site-packages/sklearn/utils/extmath.py:847: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/jcapela/miniconda3/envs/deepmol/lib/python3.9/site-packages/sklearn/utils/extmath.py:689: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/home/jcapela/miniconda3/envs/deepmol/lib/python3.9/site-packages/sklearn/utils/extmath.py:847: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/jcapela/miniconda3/envs/deepmol/lib/python3.9/site-packages/sklearn/utils/extmath.py:689: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n",
      "/home/jcapela/miniconda3/envs/deepmol/lib/python3.9/site-packages/sklearn/utils/extmath.py:847: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/jcapela/miniconda3/envs/deepmol/lib/python3.9/site-packages/sklearn/utils/extmath.py:689: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit1:  913\n",
      "dropout_rate =  0.5\n",
      "Epoch 1/500\n",
      "45/45 [==============================] - 2s 16ms/step - loss: nan - accuracy: 0.5003 - val_loss: nan - val_accuracy: 0.4905\n",
      "Epoch 2/500\n",
      "45/45 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4817 - val_loss: nan - val_accuracy: 0.4905\n",
      "Epoch 3/500\n",
      "45/45 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4773 - val_loss: nan - val_accuracy: 0.4905\n",
      "Epoch 4/500\n",
      "45/45 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4648 - val_loss: nan - val_accuracy: 0.4905\n",
      "Epoch 5/500\n",
      "45/45 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.5032 - val_loss: nan - val_accuracy: 0.4905\n",
      "Epoch 6/500\n",
      "45/45 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.4996 - val_loss: nan - val_accuracy: 0.4905\n",
      "Epoch 7/500\n",
      "13/45 [=======>......................] - ETA: 0s - loss: nan - accuracy: 0.4656"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6096d6b3eb93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvalid_dataset_mordred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset_mordred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_mordred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_dataset_mordred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-aa4ea35e0907>\u001b[0m in \u001b[0;36mtrain_dnn\u001b[0;34m(train_dataset, validation_dataset)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepMol/src/models/kerasModels.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepmol/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# define standard scaler\n",
    "scaler = StandardScaler()\n",
    "# transform data\n",
    "train_dataset_mordred.X = scaler.fit_transform(train_dataset_mordred.X)\n",
    "test_dataset_mordred.X = scaler.fit_transform(test_dataset_mordred.X)\n",
    "valid_dataset_mordred.X = scaler.fit_transform(valid_dataset_mordred.X)\n",
    "\n",
    "model = train_dnn(train_dataset_mordred,valid_dataset_mordred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0f86164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(np.array([np.NaN,1,2,3])).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5103d208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42785042, -0.4655573 , -0.45859221, ..., -0.52696665,\n",
       "        -0.58810931, -0.20469013],\n",
       "       [ 1.66296437,  1.57426432, -0.45859221, ...,  1.64705269,\n",
       "         1.58345298,  1.51145536],\n",
       "       [-0.80944109, -0.85760245, -0.45859221, ..., -0.77350492,\n",
       "        -0.73288012, -0.83495595],\n",
       "       ...,\n",
       "       [-0.69125544, -0.66001724, -0.45859221, ..., -0.6390295 ,\n",
       "        -0.57906113, -0.72105249],\n",
       "       [-0.69125544, -0.66001724, -0.45859221, ..., -0.6390295 ,\n",
       "        -0.57906113, -0.72105249],\n",
       "       [-0.69125544, -0.66001724, -0.45859221, ..., -0.6390295 ,\n",
       "        -0.57906113, -0.72105249]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_mordred.X.shape\n",
    "train_dataset_mordred.y.shape\n",
    "valid_dataset_mordred.X\n",
    "#valid_dataset_mordred.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b7c550c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit1:  506\n",
      "dropout_rate =  0.5\n",
      "Epoch 1/500\n",
      "45/45 [==============================] - 41s 48ms/step - loss: 20.6905 - accuracy: 0.7195 - val_loss: 13.0619 - val_accuracy: 0.7902\n",
      "Epoch 2/500\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 11.5067 - accuracy: 0.8152 - val_loss: 7.5837 - val_accuracy: 0.8338\n",
      "Epoch 3/500\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 6.6764 - accuracy: 0.8253 - val_loss: 4.6569 - val_accuracy: 0.8324\n",
      "Epoch 4/500\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 4.3429 - accuracy: 0.8128 - val_loss: 3.1553 - val_accuracy: 0.8202\n",
      "Epoch 5/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 2.9058 - accuracy: 0.8241 - val_loss: 2.5056 - val_accuracy: 0.7684\n",
      "Epoch 6/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 2.2886 - accuracy: 0.8275 - val_loss: 2.0778 - val_accuracy: 0.7480\n",
      "Epoch 7/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.9401 - accuracy: 0.8381 - val_loss: 1.8298 - val_accuracy: 0.8038\n",
      "Epoch 8/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.8087 - accuracy: 0.8141 - val_loss: 1.6856 - val_accuracy: 0.8392\n",
      "Epoch 9/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.7957 - accuracy: 0.8319 - val_loss: 1.7406 - val_accuracy: 0.8365\n",
      "Epoch 10/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.7457 - accuracy: 0.8340 - val_loss: 1.7054 - val_accuracy: 0.8161\n",
      "Epoch 11/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.8023 - accuracy: 0.8349 - val_loss: 1.6976 - val_accuracy: 0.8569\n",
      "Epoch 12/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.6199 - accuracy: 0.8496 - val_loss: 1.5294 - val_accuracy: 0.8392\n",
      "Epoch 13/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.4172 - accuracy: 0.8518 - val_loss: 1.2976 - val_accuracy: 0.8638\n",
      "Epoch 14/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.2683 - accuracy: 0.8689 - val_loss: 1.2456 - val_accuracy: 0.8542\n",
      "Epoch 15/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 1.1904 - accuracy: 0.8631 - val_loss: 1.1688 - val_accuracy: 0.8542\n",
      "Epoch 16/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.1246 - accuracy: 0.8668 - val_loss: 1.1097 - val_accuracy: 0.8597\n",
      "Epoch 17/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.3638 - accuracy: 0.8522 - val_loss: 1.4556 - val_accuracy: 0.8474\n",
      "Epoch 18/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.4611 - accuracy: 0.8571 - val_loss: 1.3372 - val_accuracy: 0.8501\n",
      "Epoch 19/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.2524 - accuracy: 0.8677 - val_loss: 1.2306 - val_accuracy: 0.8529\n",
      "Epoch 20/500\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 1.1569 - accuracy: 0.8617 - val_loss: 1.0737 - val_accuracy: 0.8706\n",
      "Epoch 21/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 1.0125 - accuracy: 0.8917 - val_loss: 1.0424 - val_accuracy: 0.8706\n",
      "Epoch 22/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.0085 - accuracy: 0.8766 - val_loss: 0.9565 - val_accuracy: 0.8692\n",
      "Epoch 23/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.9047 - accuracy: 0.8827 - val_loss: 1.0050 - val_accuracy: 0.8583\n",
      "Epoch 24/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.0280 - accuracy: 0.8723 - val_loss: 1.0138 - val_accuracy: 0.8624\n",
      "Epoch 25/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.0499 - accuracy: 0.8763 - val_loss: 1.1036 - val_accuracy: 0.8651\n",
      "Epoch 26/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.1754 - accuracy: 0.8851 - val_loss: 1.2443 - val_accuracy: 0.8447\n",
      "Epoch 27/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.2668 - accuracy: 0.8743 - val_loss: 1.2047 - val_accuracy: 0.8665\n",
      "Epoch 28/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.1717 - accuracy: 0.8835 - val_loss: 1.1840 - val_accuracy: 0.8665\n",
      "Epoch 29/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.1718 - accuracy: 0.8676 - val_loss: 1.1533 - val_accuracy: 0.8556\n",
      "Epoch 30/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.0549 - accuracy: 0.8945 - val_loss: 1.1228 - val_accuracy: 0.8692\n",
      "Epoch 31/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.4460 - accuracy: 0.8542 - val_loss: 1.4642 - val_accuracy: 0.8706\n",
      "Epoch 32/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.3553 - accuracy: 0.8792 - val_loss: 1.2231 - val_accuracy: 0.8651\n",
      "Epoch 33/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.2557 - accuracy: 0.8751 - val_loss: 1.2011 - val_accuracy: 0.8828\n",
      "Epoch 34/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.1142 - accuracy: 0.8883 - val_loss: 1.0678 - val_accuracy: 0.8692\n",
      "Epoch 35/500\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 1.0828 - accuracy: 0.8988 - val_loss: 1.1336 - val_accuracy: 0.8583\n",
      "Epoch 36/500\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 1.1842 - accuracy: 0.8785 - val_loss: 1.1590 - val_accuracy: 0.8706\n",
      "Epoch 37/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.2198 - accuracy: 0.8735 - val_loss: 1.2008 - val_accuracy: 0.8638\n",
      "Epoch 38/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.1231 - accuracy: 0.8721 - val_loss: 1.0490 - val_accuracy: 0.8651\n",
      "Epoch 39/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.0108 - accuracy: 0.8792 - val_loss: 0.9833 - val_accuracy: 0.8665\n",
      "Epoch 40/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.9100 - accuracy: 0.8911 - val_loss: 0.9302 - val_accuracy: 0.8760\n",
      "Epoch 41/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9578 - accuracy: 0.8880 - val_loss: 0.9834 - val_accuracy: 0.8515\n",
      "Epoch 42/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.9588 - accuracy: 0.8617 - val_loss: 0.9840 - val_accuracy: 0.8610\n",
      "Epoch 43/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.9401 - accuracy: 0.8829 - val_loss: 0.9411 - val_accuracy: 0.8747\n",
      "Epoch 44/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9802 - accuracy: 0.8831 - val_loss: 1.0263 - val_accuracy: 0.8692\n",
      "Epoch 45/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.9068 - accuracy: 0.9062 - val_loss: 0.9236 - val_accuracy: 0.8692\n",
      "Epoch 46/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8645 - accuracy: 0.8961 - val_loss: 0.9085 - val_accuracy: 0.8665\n",
      "Epoch 47/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8963 - accuracy: 0.8836 - val_loss: 0.9295 - val_accuracy: 0.8787\n",
      "Epoch 48/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8535 - accuracy: 0.8953 - val_loss: 0.9389 - val_accuracy: 0.8515\n",
      "Epoch 49/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.9293 - accuracy: 0.8896 - val_loss: 0.9817 - val_accuracy: 0.8569\n",
      "Epoch 50/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.8689 - accuracy: 0.8948 - val_loss: 0.9347 - val_accuracy: 0.8447\n",
      "Epoch 51/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8553 - accuracy: 0.9041 - val_loss: 0.8737 - val_accuracy: 0.8828\n",
      "Epoch 52/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.8807 - accuracy: 0.8968 - val_loss: 0.9837 - val_accuracy: 0.8624\n",
      "Epoch 53/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.0616 - accuracy: 0.8824 - val_loss: 1.1156 - val_accuracy: 0.8610\n",
      "Epoch 54/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.0456 - accuracy: 0.8831 - val_loss: 1.0014 - val_accuracy: 0.8747\n",
      "Epoch 55/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 1.0499 - accuracy: 0.8880 - val_loss: 1.0451 - val_accuracy: 0.8774\n",
      "Epoch 56/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.0512 - accuracy: 0.9030 - val_loss: 1.0466 - val_accuracy: 0.8719\n",
      "Epoch 57/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.0470 - accuracy: 0.8926 - val_loss: 1.0540 - val_accuracy: 0.8733\n",
      "Epoch 58/500\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 1.3708 - accuracy: 0.8828 - val_loss: 1.4736 - val_accuracy: 0.8706\n",
      "Epoch 59/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.4265 - accuracy: 0.8862 - val_loss: 1.3011 - val_accuracy: 0.8774\n",
      "Epoch 60/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.2276 - accuracy: 0.8933 - val_loss: 1.1884 - val_accuracy: 0.8610\n",
      "Epoch 61/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 1.0612 - accuracy: 0.8845 - val_loss: 1.0603 - val_accuracy: 0.8665\n",
      "Epoch 62/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.8984 - accuracy: 0.9223 - val_loss: 0.9234 - val_accuracy: 0.8747\n",
      "Epoch 63/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.8800 - accuracy: 0.8898 - val_loss: 0.9272 - val_accuracy: 0.8706\n",
      "Epoch 64/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.7959 - accuracy: 0.9120 - val_loss: 0.8904 - val_accuracy: 0.8733\n",
      "Epoch 65/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8678 - accuracy: 0.8939 - val_loss: 1.0248 - val_accuracy: 0.8529\n",
      "Epoch 66/500\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.9731 - accuracy: 0.8937 - val_loss: 1.0338 - val_accuracy: 0.8747\n",
      "Epoch 67/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.9111 - accuracy: 0.9046 - val_loss: 0.9336 - val_accuracy: 0.8692\n",
      "Epoch 68/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.8199 - accuracy: 0.9027 - val_loss: 0.8824 - val_accuracy: 0.8787\n",
      "Epoch 69/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9936 - accuracy: 0.8934 - val_loss: 1.1562 - val_accuracy: 0.8460\n",
      "Epoch 70/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.1378 - accuracy: 0.8815 - val_loss: 1.0941 - val_accuracy: 0.8733\n",
      "Epoch 71/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9508 - accuracy: 0.9142 - val_loss: 1.0027 - val_accuracy: 0.8583\n",
      "Epoch 72/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.9003 - accuracy: 0.8937 - val_loss: 0.8936 - val_accuracy: 0.8774\n",
      "Epoch 73/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.9762 - accuracy: 0.9099 - val_loss: 1.0515 - val_accuracy: 0.8665\n",
      "Epoch 74/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9044 - accuracy: 0.9035 - val_loss: 0.9201 - val_accuracy: 0.8692\n",
      "Epoch 75/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7977 - accuracy: 0.9033 - val_loss: 0.8398 - val_accuracy: 0.8706\n",
      "Epoch 76/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7331 - accuracy: 0.9065 - val_loss: 0.7653 - val_accuracy: 0.8747\n",
      "Epoch 77/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.6973 - accuracy: 0.8965 - val_loss: 0.8026 - val_accuracy: 0.8624\n",
      "Epoch 78/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.6753 - accuracy: 0.8992 - val_loss: 0.7895 - val_accuracy: 0.8869\n",
      "Epoch 79/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.8600 - accuracy: 0.8999 - val_loss: 0.9994 - val_accuracy: 0.8801\n",
      "Epoch 80/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.0203 - accuracy: 0.9154 - val_loss: 1.1211 - val_accuracy: 0.8801\n",
      "Epoch 81/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.1040 - accuracy: 0.8981 - val_loss: 1.1985 - val_accuracy: 0.8706\n",
      "Epoch 82/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 1.0855 - accuracy: 0.9058 - val_loss: 1.0928 - val_accuracy: 0.8951\n",
      "Epoch 83/500\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.9406 - accuracy: 0.9089 - val_loss: 1.0269 - val_accuracy: 0.8665\n",
      "Epoch 84/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9183 - accuracy: 0.8993 - val_loss: 0.9548 - val_accuracy: 0.8678\n",
      "Epoch 85/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.8732 - accuracy: 0.9038 - val_loss: 0.9730 - val_accuracy: 0.8638\n",
      "Epoch 86/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 1.0194 - accuracy: 0.8987 - val_loss: 1.1036 - val_accuracy: 0.8774\n",
      "Epoch 87/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.9214 - accuracy: 0.9162 - val_loss: 0.9769 - val_accuracy: 0.8869\n",
      "Epoch 88/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.8962 - accuracy: 0.9157 - val_loss: 1.0455 - val_accuracy: 0.8760\n",
      "Epoch 89/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.0022 - accuracy: 0.8999 - val_loss: 1.0894 - val_accuracy: 0.8774\n",
      "Epoch 90/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.0598 - accuracy: 0.9067 - val_loss: 1.2015 - val_accuracy: 0.8624\n",
      "Epoch 91/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.2001 - accuracy: 0.9022 - val_loss: 1.2905 - val_accuracy: 0.8706\n",
      "Epoch 92/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.1979 - accuracy: 0.9081 - val_loss: 1.3191 - val_accuracy: 0.8651\n",
      "Epoch 93/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.0994 - accuracy: 0.9047 - val_loss: 1.0983 - val_accuracy: 0.8801\n",
      "Epoch 94/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.9886 - accuracy: 0.9072 - val_loss: 1.1742 - val_accuracy: 0.8542\n",
      "Epoch 95/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.0398 - accuracy: 0.8962 - val_loss: 1.1016 - val_accuracy: 0.8815\n",
      "Epoch 96/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.0910 - accuracy: 0.9143 - val_loss: 1.2083 - val_accuracy: 0.8828\n",
      "Epoch 97/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 1.0419 - accuracy: 0.9012 - val_loss: 1.0986 - val_accuracy: 0.8774\n",
      "Epoch 98/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.1081 - accuracy: 0.9006 - val_loss: 1.1908 - val_accuracy: 0.8760\n",
      "Epoch 99/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9925 - accuracy: 0.9094 - val_loss: 1.0282 - val_accuracy: 0.8719\n",
      "Epoch 100/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.8692 - accuracy: 0.9034 - val_loss: 0.9632 - val_accuracy: 0.8856\n",
      "Epoch 101/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9074 - accuracy: 0.9018 - val_loss: 1.0506 - val_accuracy: 0.8692\n",
      "Epoch 102/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.9035 - accuracy: 0.8967 - val_loss: 0.9345 - val_accuracy: 0.8856\n",
      "Epoch 103/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.8314 - accuracy: 0.9109 - val_loss: 0.9448 - val_accuracy: 0.8638\n",
      "Epoch 104/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.7649 - accuracy: 0.9061 - val_loss: 0.8717 - val_accuracy: 0.8801\n",
      "Epoch 105/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.6946 - accuracy: 0.9105 - val_loss: 0.8842 - val_accuracy: 0.8842\n",
      "Epoch 106/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7953 - accuracy: 0.9173 - val_loss: 0.9770 - val_accuracy: 0.8787\n",
      "Epoch 107/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9363 - accuracy: 0.8987 - val_loss: 1.0128 - val_accuracy: 0.8815\n",
      "Epoch 108/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.9445 - accuracy: 0.9117 - val_loss: 1.0506 - val_accuracy: 0.8842\n",
      "Epoch 109/500\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 1.0399 - accuracy: 0.9140 - val_loss: 1.1075 - val_accuracy: 0.8678\n",
      "Epoch 110/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.9422 - accuracy: 0.9077 - val_loss: 0.9581 - val_accuracy: 0.8842\n",
      "Epoch 111/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.8873 - accuracy: 0.9116 - val_loss: 0.9675 - val_accuracy: 0.8760\n",
      "Epoch 112/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.8013 - accuracy: 0.9226 - val_loss: 0.8754 - val_accuracy: 0.8869\n",
      "Epoch 113/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8365 - accuracy: 0.8988 - val_loss: 0.9143 - val_accuracy: 0.8760\n",
      "Epoch 114/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7535 - accuracy: 0.9179 - val_loss: 0.8245 - val_accuracy: 0.8787\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 19ms/step - loss: 0.6574 - accuracy: 0.9311 - val_loss: 0.8140 - val_accuracy: 0.8828\n",
      "Epoch 116/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7403 - accuracy: 0.9039 - val_loss: 0.9173 - val_accuracy: 0.8583\n",
      "Epoch 117/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8265 - accuracy: 0.9022 - val_loss: 0.9658 - val_accuracy: 0.8747\n",
      "Epoch 118/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8840 - accuracy: 0.9130 - val_loss: 1.0128 - val_accuracy: 0.8787\n",
      "Epoch 119/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.9992 - accuracy: 0.9099 - val_loss: 1.0546 - val_accuracy: 0.8774\n",
      "Epoch 120/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9588 - accuracy: 0.9171 - val_loss: 0.9906 - val_accuracy: 0.8869\n",
      "Epoch 121/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.8663 - accuracy: 0.9261 - val_loss: 0.9151 - val_accuracy: 0.8815\n",
      "Epoch 122/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8076 - accuracy: 0.9083 - val_loss: 0.9315 - val_accuracy: 0.8651\n",
      "Epoch 123/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.7495 - accuracy: 0.9106 - val_loss: 0.8433 - val_accuracy: 0.8801\n",
      "Epoch 124/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.7543 - accuracy: 0.8937 - val_loss: 0.8658 - val_accuracy: 0.8624\n",
      "Epoch 125/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.6904 - accuracy: 0.9190 - val_loss: 0.7092 - val_accuracy: 0.8828\n",
      "Epoch 126/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.6198 - accuracy: 0.9163 - val_loss: 0.7558 - val_accuracy: 0.8719\n",
      "Epoch 127/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.6161 - accuracy: 0.9144 - val_loss: 0.7365 - val_accuracy: 0.8787\n",
      "Epoch 128/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.6217 - accuracy: 0.9162 - val_loss: 0.7310 - val_accuracy: 0.8828\n",
      "Epoch 129/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.6362 - accuracy: 0.9148 - val_loss: 0.7475 - val_accuracy: 0.8774\n",
      "Epoch 130/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.5829 - accuracy: 0.9183 - val_loss: 0.7192 - val_accuracy: 0.8774\n",
      "Epoch 131/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.6794 - accuracy: 0.9217 - val_loss: 0.8691 - val_accuracy: 0.8787\n",
      "Epoch 132/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7000 - accuracy: 0.9111 - val_loss: 0.8055 - val_accuracy: 0.8801\n",
      "Epoch 133/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.6407 - accuracy: 0.9146 - val_loss: 0.7637 - val_accuracy: 0.8842\n",
      "Epoch 134/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.6039 - accuracy: 0.9123 - val_loss: 0.7152 - val_accuracy: 0.8896\n",
      "Epoch 135/500\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.6107 - accuracy: 0.9257 - val_loss: 0.7535 - val_accuracy: 0.8883\n",
      "Epoch 136/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.6223 - accuracy: 0.9211 - val_loss: 0.7291 - val_accuracy: 0.8856\n",
      "Epoch 137/500\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.6916 - accuracy: 0.9283 - val_loss: 0.8938 - val_accuracy: 0.8815\n",
      "Epoch 138/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7637 - accuracy: 0.9196 - val_loss: 0.8978 - val_accuracy: 0.8856\n",
      "Epoch 139/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.7662 - accuracy: 0.9322 - val_loss: 0.8706 - val_accuracy: 0.8842\n",
      "Epoch 140/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.8476 - accuracy: 0.9235 - val_loss: 1.0321 - val_accuracy: 0.8787\n",
      "Epoch 141/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.9714 - accuracy: 0.9236 - val_loss: 1.1055 - val_accuracy: 0.8869\n",
      "Epoch 142/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.9248 - accuracy: 0.9062 - val_loss: 0.9982 - val_accuracy: 0.8760\n",
      "Epoch 143/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.8404 - accuracy: 0.9124 - val_loss: 0.9607 - val_accuracy: 0.8842\n",
      "Epoch 144/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.8016 - accuracy: 0.9213 - val_loss: 0.9191 - val_accuracy: 0.8856\n",
      "Epoch 145/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.8226 - accuracy: 0.9325 - val_loss: 1.0471 - val_accuracy: 0.8610\n",
      "Epoch 146/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.8827 - accuracy: 0.9220 - val_loss: 1.0507 - val_accuracy: 0.8774\n",
      "Epoch 147/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9097 - accuracy: 0.9169 - val_loss: 1.1188 - val_accuracy: 0.8651\n",
      "Epoch 148/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.0153 - accuracy: 0.9250 - val_loss: 1.2305 - val_accuracy: 0.8815\n",
      "Epoch 149/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.0467 - accuracy: 0.9210 - val_loss: 1.1369 - val_accuracy: 0.8828\n",
      "Epoch 150/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.9927 - accuracy: 0.9201 - val_loss: 1.0711 - val_accuracy: 0.8828\n",
      "Epoch 151/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.9755 - accuracy: 0.9281 - val_loss: 1.1900 - val_accuracy: 0.8787\n",
      "Epoch 152/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.2007 - accuracy: 0.9084 - val_loss: 1.3489 - val_accuracy: 0.8856\n",
      "Epoch 153/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 1.1805 - accuracy: 0.8992 - val_loss: 1.1522 - val_accuracy: 0.8787\n",
      "Epoch 154/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.0430 - accuracy: 0.9202 - val_loss: 1.1143 - val_accuracy: 0.8842\n",
      "Epoch 155/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.9562 - accuracy: 0.9142 - val_loss: 1.0627 - val_accuracy: 0.8815\n",
      "Epoch 156/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.9296 - accuracy: 0.9188 - val_loss: 1.1046 - val_accuracy: 0.8774\n",
      "Epoch 157/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.9626 - accuracy: 0.9154 - val_loss: 1.1318 - val_accuracy: 0.8774\n",
      "Epoch 158/500\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.9736 - accuracy: 0.8990 - val_loss: 1.0880 - val_accuracy: 0.8896\n",
      "Epoch 159/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 1.0577 - accuracy: 0.9243 - val_loss: 1.2563 - val_accuracy: 0.8719\n",
      "Epoch 160/500\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 1.1243 - accuracy: 0.9250 - val_loss: 1.1943 - val_accuracy: 0.8842\n",
      "Epoch 161/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.1140 - accuracy: 0.9034 - val_loss: 1.1682 - val_accuracy: 0.8842\n",
      "Epoch 162/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.9309 - accuracy: 0.9296 - val_loss: 1.0497 - val_accuracy: 0.8910\n",
      "Epoch 163/500\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.8245 - accuracy: 0.9321 - val_loss: 0.9657 - val_accuracy: 0.8828\n",
      "Epoch 164/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8976 - accuracy: 0.9243 - val_loss: 1.0714 - val_accuracy: 0.8787\n",
      "Epoch 165/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 1.0012 - accuracy: 0.9093 - val_loss: 1.1429 - val_accuracy: 0.8828\n",
      "Epoch 166/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.8996 - accuracy: 0.9216 - val_loss: 1.0256 - val_accuracy: 0.8842\n",
      "Epoch 167/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7507 - accuracy: 0.9279 - val_loss: 0.8972 - val_accuracy: 0.8883\n",
      "Epoch 168/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.7004 - accuracy: 0.9245 - val_loss: 0.9868 - val_accuracy: 0.8719\n",
      "Epoch 169/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.8210 - accuracy: 0.9060 - val_loss: 0.9881 - val_accuracy: 0.8801\n",
      "Epoch 170/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7590 - accuracy: 0.9201 - val_loss: 0.9144 - val_accuracy: 0.8719\n",
      "Epoch 171/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.7881 - accuracy: 0.9123 - val_loss: 0.9395 - val_accuracy: 0.8828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8168 - accuracy: 0.9185 - val_loss: 0.9577 - val_accuracy: 0.8842\n",
      "Epoch 173/500\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.8959 - accuracy: 0.9040 - val_loss: 0.9737 - val_accuracy: 0.8815\n",
      "Epoch 174/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8967 - accuracy: 0.9065 - val_loss: 0.9427 - val_accuracy: 0.8706\n",
      "Epoch 175/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.7446 - accuracy: 0.9219 - val_loss: 0.8886 - val_accuracy: 0.8719\n",
      "Epoch 176/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.8214 - accuracy: 0.9120 - val_loss: 0.9937 - val_accuracy: 0.8787\n",
      "Epoch 177/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.9069 - accuracy: 0.9031 - val_loss: 1.0059 - val_accuracy: 0.8815\n",
      "Epoch 178/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8070 - accuracy: 0.9183 - val_loss: 0.8885 - val_accuracy: 0.8692\n",
      "Epoch 179/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.7997 - accuracy: 0.9192 - val_loss: 0.8814 - val_accuracy: 0.8815\n",
      "Epoch 180/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.7167 - accuracy: 0.9261 - val_loss: 0.8218 - val_accuracy: 0.8706\n",
      "Epoch 181/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.7207 - accuracy: 0.9173 - val_loss: 0.8150 - val_accuracy: 0.8719\n",
      "Epoch 182/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.6765 - accuracy: 0.9169 - val_loss: 0.7547 - val_accuracy: 0.8801\n",
      "Epoch 183/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.5962 - accuracy: 0.9315 - val_loss: 0.7304 - val_accuracy: 0.8924\n",
      "Epoch 184/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.6647 - accuracy: 0.9139 - val_loss: 0.8105 - val_accuracy: 0.8951\n",
      "Epoch 185/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7610 - accuracy: 0.9125 - val_loss: 0.9413 - val_accuracy: 0.8856\n",
      "Epoch 186/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.6807 - accuracy: 0.9158 - val_loss: 0.8340 - val_accuracy: 0.8815\n",
      "Epoch 187/500\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.6384 - accuracy: 0.9187 - val_loss: 0.8110 - val_accuracy: 0.8842\n",
      "Epoch 188/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.5669 - accuracy: 0.9281 - val_loss: 0.7952 - val_accuracy: 0.8760\n",
      "Epoch 189/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.5720 - accuracy: 0.9206 - val_loss: 0.7736 - val_accuracy: 0.8815\n",
      "Epoch 190/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.5321 - accuracy: 0.9262 - val_loss: 0.7754 - val_accuracy: 0.8760\n",
      "Epoch 191/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.5255 - accuracy: 0.9341 - val_loss: 0.7709 - val_accuracy: 0.8801\n",
      "Epoch 192/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.6087 - accuracy: 0.9340 - val_loss: 0.8718 - val_accuracy: 0.8842\n",
      "Epoch 193/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.6571 - accuracy: 0.9321 - val_loss: 0.8393 - val_accuracy: 0.8856\n",
      "Epoch 194/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7335 - accuracy: 0.9295 - val_loss: 0.9932 - val_accuracy: 0.8597\n",
      "Epoch 195/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.8084 - accuracy: 0.9307 - val_loss: 0.9496 - val_accuracy: 0.8801\n",
      "Epoch 196/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.7256 - accuracy: 0.9351 - val_loss: 0.8846 - val_accuracy: 0.8842\n",
      "Epoch 197/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7994 - accuracy: 0.9257 - val_loss: 0.9771 - val_accuracy: 0.8856\n",
      "Epoch 198/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7553 - accuracy: 0.9169 - val_loss: 0.8883 - val_accuracy: 0.8896\n",
      "Epoch 199/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.8025 - accuracy: 0.9025 - val_loss: 0.9285 - val_accuracy: 0.8856\n",
      "Epoch 200/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.7873 - accuracy: 0.9119 - val_loss: 0.8807 - val_accuracy: 0.8842\n",
      "Epoch 201/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.6737 - accuracy: 0.9334 - val_loss: 0.8278 - val_accuracy: 0.8842\n",
      "Epoch 202/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.7079 - accuracy: 0.9192 - val_loss: 0.8882 - val_accuracy: 0.8815\n",
      "Epoch 203/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7118 - accuracy: 0.9347 - val_loss: 0.8931 - val_accuracy: 0.8856\n",
      "Epoch 204/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7243 - accuracy: 0.9182 - val_loss: 0.7824 - val_accuracy: 0.8856\n",
      "Epoch 205/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.7261 - accuracy: 0.9246 - val_loss: 0.8374 - val_accuracy: 0.8787\n",
      "Epoch 206/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.8716 - accuracy: 0.9060 - val_loss: 0.9567 - val_accuracy: 0.8910\n",
      "Epoch 207/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.9104 - accuracy: 0.9145 - val_loss: 0.9558 - val_accuracy: 0.8883\n",
      "Epoch 208/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.8447 - accuracy: 0.9365 - val_loss: 0.9462 - val_accuracy: 0.8842\n",
      "Epoch 209/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.8061 - accuracy: 0.9283 - val_loss: 0.8651 - val_accuracy: 0.8815\n",
      "Epoch 210/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.7735 - accuracy: 0.9270 - val_loss: 0.9099 - val_accuracy: 0.8815\n",
      "Epoch 211/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.7619 - accuracy: 0.9099 - val_loss: 0.8497 - val_accuracy: 0.8815\n",
      "Epoch 212/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.6689 - accuracy: 0.9215 - val_loss: 0.7323 - val_accuracy: 0.8910\n",
      "Epoch 213/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.6287 - accuracy: 0.9242 - val_loss: 0.7854 - val_accuracy: 0.8760\n",
      "Epoch 214/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.6554 - accuracy: 0.9090 - val_loss: 0.7337 - val_accuracy: 0.9060\n",
      "Epoch 215/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.6597 - accuracy: 0.9379 - val_loss: 0.8469 - val_accuracy: 0.8937\n",
      "Epoch 216/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.8645 - accuracy: 0.9236 - val_loss: 1.0165 - val_accuracy: 0.8869\n",
      "Epoch 217/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.8097 - accuracy: 0.9226 - val_loss: 0.8942 - val_accuracy: 0.8869\n",
      "Epoch 218/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.8020 - accuracy: 0.9258 - val_loss: 0.8895 - val_accuracy: 0.8910\n",
      "Epoch 219/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.7949 - accuracy: 0.9317 - val_loss: 0.9242 - val_accuracy: 0.8815\n",
      "Epoch 220/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.7432 - accuracy: 0.9280 - val_loss: 0.8602 - val_accuracy: 0.8733\n",
      "Epoch 221/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.6634 - accuracy: 0.9260 - val_loss: 0.8312 - val_accuracy: 0.8787\n",
      "Epoch 222/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.5996 - accuracy: 0.9334 - val_loss: 0.8048 - val_accuracy: 0.8815\n",
      "Epoch 223/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.6041 - accuracy: 0.9206 - val_loss: 0.7218 - val_accuracy: 0.8842\n",
      "Epoch 224/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.6341 - accuracy: 0.9290 - val_loss: 0.8096 - val_accuracy: 0.8910\n",
      "Epoch 225/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.6528 - accuracy: 0.9170 - val_loss: 0.7669 - val_accuracy: 0.8842\n",
      "\n",
      "Epoch 00225: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 226/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.5768 - accuracy: 0.9436 - val_loss: 0.7233 - val_accuracy: 0.8801\n",
      "Epoch 227/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.5285 - accuracy: 0.9348 - val_loss: 0.6436 - val_accuracy: 0.8965\n",
      "Epoch 228/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.4625 - accuracy: 0.9398 - val_loss: 0.6629 - val_accuracy: 0.8842\n",
      "Epoch 229/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4657 - accuracy: 0.9320 - val_loss: 0.6031 - val_accuracy: 0.8910\n",
      "Epoch 230/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4147 - accuracy: 0.9485 - val_loss: 0.6120 - val_accuracy: 0.8801\n",
      "Epoch 231/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.4995 - accuracy: 0.9287 - val_loss: 0.7057 - val_accuracy: 0.8896\n",
      "Epoch 232/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.5105 - accuracy: 0.9371 - val_loss: 0.6695 - val_accuracy: 0.8828\n",
      "Epoch 233/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4632 - accuracy: 0.9371 - val_loss: 0.6376 - val_accuracy: 0.8924\n",
      "Epoch 234/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4260 - accuracy: 0.9439 - val_loss: 0.6004 - val_accuracy: 0.8896\n",
      "Epoch 235/500\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.4528 - accuracy: 0.9407 - val_loss: 0.6751 - val_accuracy: 0.8883\n",
      "Epoch 236/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4607 - accuracy: 0.9361 - val_loss: 0.6422 - val_accuracy: 0.8842\n",
      "Epoch 237/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4534 - accuracy: 0.9386 - val_loss: 0.6228 - val_accuracy: 0.8910\n",
      "Epoch 238/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4829 - accuracy: 0.9419 - val_loss: 0.6623 - val_accuracy: 0.8951\n",
      "Epoch 239/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4849 - accuracy: 0.9484 - val_loss: 0.6816 - val_accuracy: 0.8896\n",
      "Epoch 240/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4742 - accuracy: 0.9393 - val_loss: 0.6392 - val_accuracy: 0.8924\n",
      "Epoch 241/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4572 - accuracy: 0.9385 - val_loss: 0.6232 - val_accuracy: 0.8883\n",
      "Epoch 242/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4156 - accuracy: 0.9426 - val_loss: 0.6325 - val_accuracy: 0.8883\n",
      "Epoch 243/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3870 - accuracy: 0.9459 - val_loss: 0.5901 - val_accuracy: 0.8937\n",
      "Epoch 244/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3577 - accuracy: 0.9566 - val_loss: 0.5929 - val_accuracy: 0.9005\n",
      "Epoch 245/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4250 - accuracy: 0.9460 - val_loss: 0.6820 - val_accuracy: 0.8883\n",
      "Epoch 246/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4336 - accuracy: 0.9470 - val_loss: 0.6585 - val_accuracy: 0.8896\n",
      "Epoch 247/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4176 - accuracy: 0.9408 - val_loss: 0.6180 - val_accuracy: 0.8937\n",
      "Epoch 248/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4438 - accuracy: 0.9315 - val_loss: 0.6450 - val_accuracy: 0.8937\n",
      "Epoch 249/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4733 - accuracy: 0.9346 - val_loss: 0.7182 - val_accuracy: 0.8869\n",
      "Epoch 250/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.4733 - accuracy: 0.9461 - val_loss: 0.6621 - val_accuracy: 0.8924\n",
      "Epoch 251/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4038 - accuracy: 0.9431 - val_loss: 0.6674 - val_accuracy: 0.8774\n",
      "Epoch 252/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4710 - accuracy: 0.9317 - val_loss: 0.7311 - val_accuracy: 0.8787\n",
      "Epoch 253/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.5000 - accuracy: 0.9321 - val_loss: 0.6754 - val_accuracy: 0.8965\n",
      "Epoch 254/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4367 - accuracy: 0.9422 - val_loss: 0.6618 - val_accuracy: 0.8869\n",
      "Epoch 255/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4308 - accuracy: 0.9376 - val_loss: 0.6419 - val_accuracy: 0.8924\n",
      "Epoch 256/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3889 - accuracy: 0.9428 - val_loss: 0.6187 - val_accuracy: 0.8883\n",
      "Epoch 257/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4243 - accuracy: 0.9359 - val_loss: 0.6446 - val_accuracy: 0.8896\n",
      "Epoch 258/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.4017 - accuracy: 0.9450 - val_loss: 0.6220 - val_accuracy: 0.8774\n",
      "Epoch 259/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4607 - accuracy: 0.9298 - val_loss: 0.6453 - val_accuracy: 0.8842\n",
      "Epoch 260/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4026 - accuracy: 0.9455 - val_loss: 0.6152 - val_accuracy: 0.8842\n",
      "Epoch 261/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4591 - accuracy: 0.9402 - val_loss: 0.7030 - val_accuracy: 0.8774\n",
      "Epoch 262/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4593 - accuracy: 0.9363 - val_loss: 0.6302 - val_accuracy: 0.8842\n",
      "Epoch 263/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4451 - accuracy: 0.9346 - val_loss: 0.6269 - val_accuracy: 0.8815\n",
      "Epoch 264/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3998 - accuracy: 0.9553 - val_loss: 0.6157 - val_accuracy: 0.8828\n",
      "Epoch 265/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3696 - accuracy: 0.9513 - val_loss: 0.6099 - val_accuracy: 0.8869\n",
      "Epoch 266/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4191 - accuracy: 0.9471 - val_loss: 0.6857 - val_accuracy: 0.8787\n",
      "Epoch 267/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.5270 - accuracy: 0.9411 - val_loss: 0.6980 - val_accuracy: 0.8883\n",
      "Epoch 268/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.5288 - accuracy: 0.9482 - val_loss: 0.6764 - val_accuracy: 0.8896\n",
      "Epoch 269/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4718 - accuracy: 0.9467 - val_loss: 0.6249 - val_accuracy: 0.8801\n",
      "Epoch 270/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4518 - accuracy: 0.9315 - val_loss: 0.6498 - val_accuracy: 0.8883\n",
      "Epoch 271/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4524 - accuracy: 0.9418 - val_loss: 0.7029 - val_accuracy: 0.8787\n",
      "Epoch 272/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4982 - accuracy: 0.9451 - val_loss: 0.6881 - val_accuracy: 0.8869\n",
      "Epoch 273/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4815 - accuracy: 0.9394 - val_loss: 0.6573 - val_accuracy: 0.8965\n",
      "Epoch 274/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.4465 - accuracy: 0.9405 - val_loss: 0.6412 - val_accuracy: 0.8910\n",
      "Epoch 275/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4838 - accuracy: 0.9481 - val_loss: 0.6942 - val_accuracy: 0.8951\n",
      "Epoch 276/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4266 - accuracy: 0.9574 - val_loss: 0.6410 - val_accuracy: 0.8910\n",
      "Epoch 277/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4535 - accuracy: 0.9534 - val_loss: 0.6794 - val_accuracy: 0.8924\n",
      "Epoch 278/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4320 - accuracy: 0.9482 - val_loss: 0.6698 - val_accuracy: 0.8924\n",
      "Epoch 279/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4414 - accuracy: 0.9482 - val_loss: 0.6780 - val_accuracy: 0.8896\n",
      "Epoch 280/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.4667 - accuracy: 0.9502 - val_loss: 0.7097 - val_accuracy: 0.8883\n",
      "Epoch 281/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.5019 - accuracy: 0.9462 - val_loss: 0.7228 - val_accuracy: 0.8883\n",
      "Epoch 282/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4607 - accuracy: 0.9471 - val_loss: 0.6616 - val_accuracy: 0.8883\n",
      "Epoch 283/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4457 - accuracy: 0.9392 - val_loss: 0.6595 - val_accuracy: 0.8856\n",
      "Epoch 284/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4054 - accuracy: 0.9457 - val_loss: 0.6134 - val_accuracy: 0.8896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3522 - accuracy: 0.9540 - val_loss: 0.6002 - val_accuracy: 0.8951\n",
      "Epoch 286/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3948 - accuracy: 0.9569 - val_loss: 0.6143 - val_accuracy: 0.8951\n",
      "Epoch 287/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4000 - accuracy: 0.9488 - val_loss: 0.6150 - val_accuracy: 0.8883\n",
      "Epoch 288/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3606 - accuracy: 0.9536 - val_loss: 0.6016 - val_accuracy: 0.8910\n",
      "Epoch 289/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.3974 - accuracy: 0.9501 - val_loss: 0.6779 - val_accuracy: 0.8951\n",
      "Epoch 290/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3893 - accuracy: 0.9546 - val_loss: 0.6990 - val_accuracy: 0.8883\n",
      "Epoch 291/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4022 - accuracy: 0.9453 - val_loss: 0.6670 - val_accuracy: 0.8883\n",
      "Epoch 292/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4533 - accuracy: 0.9447 - val_loss: 0.6844 - val_accuracy: 0.8910\n",
      "Epoch 293/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4760 - accuracy: 0.9443 - val_loss: 0.6836 - val_accuracy: 0.8815\n",
      "Epoch 294/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4437 - accuracy: 0.9450 - val_loss: 0.6711 - val_accuracy: 0.8883\n",
      "Epoch 295/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3705 - accuracy: 0.9612 - val_loss: 0.6279 - val_accuracy: 0.8896\n",
      "Epoch 296/500\n",
      "45/45 [==============================] - 1s 22ms/step - loss: 0.3605 - accuracy: 0.9516 - val_loss: 0.6217 - val_accuracy: 0.8828\n",
      "Epoch 297/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4161 - accuracy: 0.9493 - val_loss: 0.6696 - val_accuracy: 0.8965\n",
      "Epoch 298/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4425 - accuracy: 0.9424 - val_loss: 0.7161 - val_accuracy: 0.8924\n",
      "Epoch 299/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4420 - accuracy: 0.9592 - val_loss: 0.7188 - val_accuracy: 0.8910\n",
      "Epoch 300/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4109 - accuracy: 0.9601 - val_loss: 0.7087 - val_accuracy: 0.8910\n",
      "Epoch 301/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4354 - accuracy: 0.9458 - val_loss: 0.6528 - val_accuracy: 0.8937\n",
      "Epoch 302/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3851 - accuracy: 0.9527 - val_loss: 0.7162 - val_accuracy: 0.8883\n",
      "Epoch 303/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4457 - accuracy: 0.9397 - val_loss: 0.7147 - val_accuracy: 0.8951\n",
      "Epoch 304/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4115 - accuracy: 0.9466 - val_loss: 0.6375 - val_accuracy: 0.8951\n",
      "Epoch 305/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3867 - accuracy: 0.9531 - val_loss: 0.6205 - val_accuracy: 0.8951\n",
      "Epoch 306/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4022 - accuracy: 0.9541 - val_loss: 0.6401 - val_accuracy: 0.8883\n",
      "Epoch 307/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4093 - accuracy: 0.9387 - val_loss: 0.6035 - val_accuracy: 0.8951\n",
      "Epoch 308/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3633 - accuracy: 0.9544 - val_loss: 0.6511 - val_accuracy: 0.8910\n",
      "Epoch 309/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3348 - accuracy: 0.9589 - val_loss: 0.6217 - val_accuracy: 0.8924\n",
      "Epoch 310/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3661 - accuracy: 0.9539 - val_loss: 0.6152 - val_accuracy: 0.8910\n",
      "Epoch 311/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.3692 - accuracy: 0.9439 - val_loss: 0.6037 - val_accuracy: 0.8924\n",
      "Epoch 312/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.3414 - accuracy: 0.9506 - val_loss: 0.5918 - val_accuracy: 0.8869\n",
      "Epoch 313/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3322 - accuracy: 0.9559 - val_loss: 0.5838 - val_accuracy: 0.8951\n",
      "Epoch 314/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3936 - accuracy: 0.9454 - val_loss: 0.6734 - val_accuracy: 0.8828\n",
      "Epoch 315/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4164 - accuracy: 0.9508 - val_loss: 0.6294 - val_accuracy: 0.8910\n",
      "Epoch 316/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3928 - accuracy: 0.9412 - val_loss: 0.6302 - val_accuracy: 0.8801\n",
      "Epoch 317/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3418 - accuracy: 0.9502 - val_loss: 0.5963 - val_accuracy: 0.8896\n",
      "Epoch 318/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3615 - accuracy: 0.9504 - val_loss: 0.6465 - val_accuracy: 0.8869\n",
      "Epoch 319/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3738 - accuracy: 0.9464 - val_loss: 0.6435 - val_accuracy: 0.8910\n",
      "Epoch 320/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3404 - accuracy: 0.9526 - val_loss: 0.6036 - val_accuracy: 0.8856\n",
      "Epoch 321/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3047 - accuracy: 0.9582 - val_loss: 0.6029 - val_accuracy: 0.8910\n",
      "Epoch 322/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3445 - accuracy: 0.9446 - val_loss: 0.5982 - val_accuracy: 0.8842\n",
      "Epoch 323/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2937 - accuracy: 0.9543 - val_loss: 0.6554 - val_accuracy: 0.8733\n",
      "Epoch 324/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.3568 - accuracy: 0.9492 - val_loss: 0.6627 - val_accuracy: 0.8856\n",
      "Epoch 325/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4075 - accuracy: 0.9550 - val_loss: 0.6657 - val_accuracy: 0.8896\n",
      "Epoch 326/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4166 - accuracy: 0.9509 - val_loss: 0.6897 - val_accuracy: 0.8910\n",
      "Epoch 327/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4490 - accuracy: 0.9458 - val_loss: 0.7001 - val_accuracy: 0.8896\n",
      "Epoch 328/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.4183 - accuracy: 0.9633 - val_loss: 0.6908 - val_accuracy: 0.8869\n",
      "Epoch 329/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4561 - accuracy: 0.9403 - val_loss: 0.6672 - val_accuracy: 0.8869\n",
      "Epoch 330/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.4923 - accuracy: 0.9439 - val_loss: 0.7189 - val_accuracy: 0.8815\n",
      "Epoch 331/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.4731 - accuracy: 0.9566 - val_loss: 0.7115 - val_accuracy: 0.8815\n",
      "Epoch 332/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4333 - accuracy: 0.9448 - val_loss: 0.6865 - val_accuracy: 0.8910\n",
      "Epoch 333/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.3936 - accuracy: 0.9517 - val_loss: 0.6311 - val_accuracy: 0.8801\n",
      "Epoch 334/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3578 - accuracy: 0.9513 - val_loss: 0.6157 - val_accuracy: 0.8787\n",
      "Epoch 335/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.3860 - accuracy: 0.9514 - val_loss: 0.6217 - val_accuracy: 0.8896\n",
      "Epoch 336/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3688 - accuracy: 0.9479 - val_loss: 0.5931 - val_accuracy: 0.8937\n",
      "Epoch 337/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3475 - accuracy: 0.9521 - val_loss: 0.5998 - val_accuracy: 0.8910\n",
      "Epoch 338/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3269 - accuracy: 0.9461 - val_loss: 0.6195 - val_accuracy: 0.8869\n",
      "Epoch 339/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3104 - accuracy: 0.9506 - val_loss: 0.6040 - val_accuracy: 0.8869\n",
      "Epoch 340/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2921 - accuracy: 0.9548 - val_loss: 0.5999 - val_accuracy: 0.8896\n",
      "Epoch 341/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2752 - accuracy: 0.9646 - val_loss: 0.5659 - val_accuracy: 0.8924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2909 - accuracy: 0.9565 - val_loss: 0.6067 - val_accuracy: 0.8896\n",
      "Epoch 343/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2867 - accuracy: 0.9609 - val_loss: 0.5735 - val_accuracy: 0.8869\n",
      "Epoch 344/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2630 - accuracy: 0.9610 - val_loss: 0.6127 - val_accuracy: 0.8910\n",
      "Epoch 345/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3660 - accuracy: 0.9462 - val_loss: 0.7083 - val_accuracy: 0.8896\n",
      "Epoch 346/500\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.4177 - accuracy: 0.9475 - val_loss: 0.7400 - val_accuracy: 0.8842\n",
      "Epoch 347/500\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.3934 - accuracy: 0.9571 - val_loss: 0.6995 - val_accuracy: 0.8883\n",
      "Epoch 348/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3583 - accuracy: 0.9537 - val_loss: 0.6794 - val_accuracy: 0.8896\n",
      "Epoch 349/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4232 - accuracy: 0.9477 - val_loss: 0.7109 - val_accuracy: 0.8883\n",
      "Epoch 350/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.3946 - accuracy: 0.9523 - val_loss: 0.7323 - val_accuracy: 0.8883\n",
      "Epoch 351/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4226 - accuracy: 0.9523 - val_loss: 0.7444 - val_accuracy: 0.8896\n",
      "Epoch 352/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4681 - accuracy: 0.9541 - val_loss: 0.7381 - val_accuracy: 0.8856\n",
      "Epoch 353/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4026 - accuracy: 0.9566 - val_loss: 0.7012 - val_accuracy: 0.8842\n",
      "Epoch 354/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.4765 - accuracy: 0.9439 - val_loss: 0.7512 - val_accuracy: 0.8842\n",
      "Epoch 355/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.5344 - accuracy: 0.9589 - val_loss: 0.8334 - val_accuracy: 0.8856\n",
      "Epoch 356/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4911 - accuracy: 0.9536 - val_loss: 0.7677 - val_accuracy: 0.8828\n",
      "Epoch 357/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.5159 - accuracy: 0.9444 - val_loss: 0.7262 - val_accuracy: 0.8937\n",
      "Epoch 358/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4464 - accuracy: 0.9557 - val_loss: 0.6784 - val_accuracy: 0.8856\n",
      "Epoch 359/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.5086 - accuracy: 0.9283 - val_loss: 0.7751 - val_accuracy: 0.8692\n",
      "Epoch 360/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4617 - accuracy: 0.9371 - val_loss: 0.7194 - val_accuracy: 0.8883\n",
      "Epoch 361/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4924 - accuracy: 0.9485 - val_loss: 0.7950 - val_accuracy: 0.8828\n",
      "Epoch 362/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4728 - accuracy: 0.9661 - val_loss: 0.7125 - val_accuracy: 0.8869\n",
      "Epoch 363/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4404 - accuracy: 0.9488 - val_loss: 0.7124 - val_accuracy: 0.8883\n",
      "Epoch 364/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.4661 - accuracy: 0.9507 - val_loss: 0.7493 - val_accuracy: 0.8856\n",
      "Epoch 365/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.4029 - accuracy: 0.9597 - val_loss: 0.6817 - val_accuracy: 0.8842\n",
      "Epoch 366/500\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.3766 - accuracy: 0.9598 - val_loss: 0.6492 - val_accuracy: 0.8828\n",
      "Epoch 367/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3670 - accuracy: 0.9590 - val_loss: 0.6657 - val_accuracy: 0.8883\n",
      "Epoch 368/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3481 - accuracy: 0.9531 - val_loss: 0.6666 - val_accuracy: 0.8787\n",
      "Epoch 369/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4053 - accuracy: 0.9500 - val_loss: 0.7872 - val_accuracy: 0.8842\n",
      "Epoch 370/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4907 - accuracy: 0.9523 - val_loss: 0.8188 - val_accuracy: 0.8856\n",
      "Epoch 371/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4371 - accuracy: 0.9609 - val_loss: 0.8280 - val_accuracy: 0.8610\n",
      "Epoch 372/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.5009 - accuracy: 0.9401 - val_loss: 0.8193 - val_accuracy: 0.8842\n",
      "Epoch 373/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4563 - accuracy: 0.9525 - val_loss: 0.7819 - val_accuracy: 0.8828\n",
      "Epoch 374/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4884 - accuracy: 0.9520 - val_loss: 0.7785 - val_accuracy: 0.8924\n",
      "Epoch 375/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4140 - accuracy: 0.9583 - val_loss: 0.7451 - val_accuracy: 0.8910\n",
      "Epoch 376/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3816 - accuracy: 0.9586 - val_loss: 0.6936 - val_accuracy: 0.8883\n",
      "Epoch 377/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3382 - accuracy: 0.9660 - val_loss: 0.7075 - val_accuracy: 0.8869\n",
      "Epoch 378/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3374 - accuracy: 0.9617 - val_loss: 0.7028 - val_accuracy: 0.8896\n",
      "Epoch 379/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3763 - accuracy: 0.9665 - val_loss: 0.7377 - val_accuracy: 0.8856\n",
      "Epoch 380/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3498 - accuracy: 0.9673 - val_loss: 0.7092 - val_accuracy: 0.8856\n",
      "Epoch 381/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.3386 - accuracy: 0.9549 - val_loss: 0.6767 - val_accuracy: 0.8869\n",
      "Epoch 382/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3440 - accuracy: 0.9505 - val_loss: 0.7012 - val_accuracy: 0.8856\n",
      "Epoch 383/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.3587 - accuracy: 0.9581 - val_loss: 0.7353 - val_accuracy: 0.8828\n",
      "Epoch 384/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4265 - accuracy: 0.9498 - val_loss: 0.7583 - val_accuracy: 0.8883\n",
      "Epoch 385/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.4610 - accuracy: 0.9482 - val_loss: 0.7652 - val_accuracy: 0.8883\n",
      "Epoch 386/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3956 - accuracy: 0.9589 - val_loss: 0.7216 - val_accuracy: 0.8856\n",
      "Epoch 387/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3651 - accuracy: 0.9559 - val_loss: 0.6958 - val_accuracy: 0.8856\n",
      "Epoch 388/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3196 - accuracy: 0.9619 - val_loss: 0.6993 - val_accuracy: 0.8828\n",
      "Epoch 389/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3139 - accuracy: 0.9615 - val_loss: 0.6554 - val_accuracy: 0.8869\n",
      "Epoch 390/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2913 - accuracy: 0.9617 - val_loss: 0.6475 - val_accuracy: 0.8896\n",
      "Epoch 391/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3164 - accuracy: 0.9603 - val_loss: 0.7839 - val_accuracy: 0.8883\n",
      "Epoch 392/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4305 - accuracy: 0.9431 - val_loss: 0.7441 - val_accuracy: 0.8896\n",
      "Epoch 393/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3858 - accuracy: 0.9561 - val_loss: 0.7123 - val_accuracy: 0.8924\n",
      "Epoch 394/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3848 - accuracy: 0.9622 - val_loss: 0.7279 - val_accuracy: 0.8910\n",
      "Epoch 395/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.3509 - accuracy: 0.9630 - val_loss: 0.6893 - val_accuracy: 0.8869\n",
      "Epoch 396/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4322 - accuracy: 0.9520 - val_loss: 0.7421 - val_accuracy: 0.8883\n",
      "Epoch 397/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.4265 - accuracy: 0.9577 - val_loss: 0.7359 - val_accuracy: 0.8910\n",
      "Epoch 398/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4739 - accuracy: 0.9545 - val_loss: 0.8110 - val_accuracy: 0.8842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4259 - accuracy: 0.9579 - val_loss: 0.7290 - val_accuracy: 0.8828\n",
      "Epoch 400/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4478 - accuracy: 0.9482 - val_loss: 0.7147 - val_accuracy: 0.8828\n",
      "Epoch 401/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.4027 - accuracy: 0.9518 - val_loss: 0.6691 - val_accuracy: 0.8869\n",
      "Epoch 402/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4166 - accuracy: 0.9582 - val_loss: 0.7450 - val_accuracy: 0.8856\n",
      "Epoch 403/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4465 - accuracy: 0.9549 - val_loss: 0.7882 - val_accuracy: 0.8869\n",
      "Epoch 404/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.4012 - accuracy: 0.9611 - val_loss: 0.7469 - val_accuracy: 0.8910\n",
      "Epoch 405/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4152 - accuracy: 0.9628 - val_loss: 0.7930 - val_accuracy: 0.8951\n",
      "Epoch 406/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.4182 - accuracy: 0.9647 - val_loss: 0.7658 - val_accuracy: 0.8937\n",
      "Epoch 407/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3821 - accuracy: 0.9583 - val_loss: 0.7324 - val_accuracy: 0.8883\n",
      "Epoch 408/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3590 - accuracy: 0.9604 - val_loss: 0.7213 - val_accuracy: 0.8951\n",
      "Epoch 409/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3454 - accuracy: 0.9482 - val_loss: 0.6881 - val_accuracy: 0.8924\n",
      "Epoch 410/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2816 - accuracy: 0.9709 - val_loss: 0.6485 - val_accuracy: 0.8896\n",
      "Epoch 411/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2814 - accuracy: 0.9668 - val_loss: 0.7143 - val_accuracy: 0.8856\n",
      "Epoch 412/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3422 - accuracy: 0.9617 - val_loss: 0.7414 - val_accuracy: 0.8951\n",
      "Epoch 413/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3257 - accuracy: 0.9574 - val_loss: 0.6758 - val_accuracy: 0.8924\n",
      "Epoch 414/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2968 - accuracy: 0.9617 - val_loss: 0.6584 - val_accuracy: 0.8896\n",
      "Epoch 415/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2931 - accuracy: 0.9589 - val_loss: 0.7089 - val_accuracy: 0.8883\n",
      "Epoch 416/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2758 - accuracy: 0.9563 - val_loss: 0.6354 - val_accuracy: 0.8856\n",
      "Epoch 417/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.3057 - accuracy: 0.9621 - val_loss: 0.7202 - val_accuracy: 0.8869\n",
      "Epoch 418/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.2797 - accuracy: 0.9631 - val_loss: 0.6611 - val_accuracy: 0.8842\n",
      "Epoch 419/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3008 - accuracy: 0.9573 - val_loss: 0.7102 - val_accuracy: 0.8842\n",
      "Epoch 420/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2949 - accuracy: 0.9613 - val_loss: 0.6998 - val_accuracy: 0.8869\n",
      "Epoch 421/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2891 - accuracy: 0.9534 - val_loss: 0.6809 - val_accuracy: 0.8856\n",
      "Epoch 422/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2893 - accuracy: 0.9529 - val_loss: 0.6594 - val_accuracy: 0.8869\n",
      "Epoch 423/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2651 - accuracy: 0.9647 - val_loss: 0.6959 - val_accuracy: 0.8896\n",
      "Epoch 424/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2606 - accuracy: 0.9569 - val_loss: 0.6636 - val_accuracy: 0.8869\n",
      "Epoch 425/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2592 - accuracy: 0.9591 - val_loss: 0.6478 - val_accuracy: 0.8896\n",
      "Epoch 426/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.2469 - accuracy: 0.9628 - val_loss: 0.6792 - val_accuracy: 0.8869\n",
      "Epoch 427/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2248 - accuracy: 0.9680 - val_loss: 0.6389 - val_accuracy: 0.8869\n",
      "Epoch 428/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2970 - accuracy: 0.9591 - val_loss: 0.7041 - val_accuracy: 0.8828\n",
      "Epoch 429/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2925 - accuracy: 0.9572 - val_loss: 0.6833 - val_accuracy: 0.8937\n",
      "Epoch 430/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2802 - accuracy: 0.9538 - val_loss: 0.7344 - val_accuracy: 0.8828\n",
      "Epoch 431/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3223 - accuracy: 0.9566 - val_loss: 0.7061 - val_accuracy: 0.8896\n",
      "Epoch 432/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2833 - accuracy: 0.9568 - val_loss: 0.7609 - val_accuracy: 0.8910\n",
      "Epoch 433/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2620 - accuracy: 0.9644 - val_loss: 0.6962 - val_accuracy: 0.8883\n",
      "Epoch 434/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2923 - accuracy: 0.9682 - val_loss: 0.6964 - val_accuracy: 0.8896\n",
      "Epoch 435/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2837 - accuracy: 0.9629 - val_loss: 0.7306 - val_accuracy: 0.8910\n",
      "Epoch 436/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3232 - accuracy: 0.9589 - val_loss: 0.6653 - val_accuracy: 0.8883\n",
      "Epoch 437/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3868 - accuracy: 0.9507 - val_loss: 0.7662 - val_accuracy: 0.8910\n",
      "Epoch 438/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.4102 - accuracy: 0.9601 - val_loss: 0.8049 - val_accuracy: 0.8842\n",
      "Epoch 439/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3611 - accuracy: 0.9625 - val_loss: 0.7716 - val_accuracy: 0.8896\n",
      "Epoch 440/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3498 - accuracy: 0.9555 - val_loss: 0.7153 - val_accuracy: 0.8869\n",
      "Epoch 441/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2897 - accuracy: 0.9676 - val_loss: 0.7478 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00441: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 442/500\n",
      "45/45 [==============================] - 1s 21ms/step - loss: 0.3104 - accuracy: 0.9711 - val_loss: 0.7567 - val_accuracy: 0.8910\n",
      "Epoch 443/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3020 - accuracy: 0.9659 - val_loss: 0.7104 - val_accuracy: 0.8924\n",
      "Epoch 444/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3200 - accuracy: 0.9555 - val_loss: 0.7188 - val_accuracy: 0.8924\n",
      "Epoch 445/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3554 - accuracy: 0.9526 - val_loss: 0.6846 - val_accuracy: 0.8951\n",
      "Epoch 446/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3088 - accuracy: 0.9714 - val_loss: 0.6893 - val_accuracy: 0.8883\n",
      "Epoch 447/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2922 - accuracy: 0.9677 - val_loss: 0.6517 - val_accuracy: 0.8856\n",
      "Epoch 448/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3306 - accuracy: 0.9627 - val_loss: 0.6806 - val_accuracy: 0.8896\n",
      "Epoch 449/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2981 - accuracy: 0.9672 - val_loss: 0.6600 - val_accuracy: 0.8910\n",
      "Epoch 450/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3521 - accuracy: 0.9543 - val_loss: 0.6841 - val_accuracy: 0.8896\n",
      "Epoch 451/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3402 - accuracy: 0.9652 - val_loss: 0.7014 - val_accuracy: 0.8883\n",
      "Epoch 452/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3417 - accuracy: 0.9512 - val_loss: 0.6641 - val_accuracy: 0.8883\n",
      "Epoch 453/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2630 - accuracy: 0.9725 - val_loss: 0.6613 - val_accuracy: 0.8896\n",
      "Epoch 454/500\n",
      "45/45 [==============================] - 1s 23ms/step - loss: 0.3124 - accuracy: 0.9621 - val_loss: 0.6552 - val_accuracy: 0.8883\n",
      "Epoch 455/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2871 - accuracy: 0.9714 - val_loss: 0.6551 - val_accuracy: 0.8842\n",
      "Epoch 456/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.3080 - accuracy: 0.9615 - val_loss: 0.6854 - val_accuracy: 0.8815\n",
      "Epoch 457/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3194 - accuracy: 0.9577 - val_loss: 0.6898 - val_accuracy: 0.8856\n",
      "Epoch 458/500\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.2804 - accuracy: 0.9673 - val_loss: 0.6640 - val_accuracy: 0.8856\n",
      "Epoch 459/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2720 - accuracy: 0.9570 - val_loss: 0.6530 - val_accuracy: 0.8842\n",
      "Epoch 460/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2697 - accuracy: 0.9562 - val_loss: 0.6296 - val_accuracy: 0.8842\n",
      "Epoch 461/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2570 - accuracy: 0.9633 - val_loss: 0.6198 - val_accuracy: 0.8896\n",
      "Epoch 462/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2714 - accuracy: 0.9651 - val_loss: 0.6500 - val_accuracy: 0.8828\n",
      "Epoch 463/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2817 - accuracy: 0.9702 - val_loss: 0.6507 - val_accuracy: 0.8842\n",
      "Epoch 464/500\n",
      "45/45 [==============================] - 1s 20ms/step - loss: 0.2762 - accuracy: 0.9608 - val_loss: 0.6237 - val_accuracy: 0.8883\n",
      "Epoch 465/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2736 - accuracy: 0.9726 - val_loss: 0.6503 - val_accuracy: 0.8842\n",
      "Epoch 466/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2896 - accuracy: 0.9656 - val_loss: 0.6687 - val_accuracy: 0.8869\n",
      "Epoch 467/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.2953 - accuracy: 0.9720 - val_loss: 0.6891 - val_accuracy: 0.8842\n",
      "Epoch 468/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2770 - accuracy: 0.9672 - val_loss: 0.6665 - val_accuracy: 0.8896\n",
      "Epoch 469/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2745 - accuracy: 0.9607 - val_loss: 0.6735 - val_accuracy: 0.8856\n",
      "Epoch 470/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2485 - accuracy: 0.9654 - val_loss: 0.6523 - val_accuracy: 0.8842\n",
      "Epoch 471/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2583 - accuracy: 0.9507 - val_loss: 0.6605 - val_accuracy: 0.8815\n",
      "Epoch 472/500\n",
      "45/45 [==============================] - 1s 18ms/step - loss: 0.2705 - accuracy: 0.9688 - val_loss: 0.6598 - val_accuracy: 0.8842\n",
      "Epoch 473/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2670 - accuracy: 0.9594 - val_loss: 0.6222 - val_accuracy: 0.8869\n",
      "Epoch 474/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2625 - accuracy: 0.9702 - val_loss: 0.6358 - val_accuracy: 0.8856\n",
      "Epoch 475/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2816 - accuracy: 0.9571 - val_loss: 0.6352 - val_accuracy: 0.8869\n",
      "Epoch 476/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2749 - accuracy: 0.9624 - val_loss: 0.6090 - val_accuracy: 0.8896\n",
      "Epoch 477/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2596 - accuracy: 0.9653 - val_loss: 0.6052 - val_accuracy: 0.8896\n",
      "Epoch 478/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.2882 - accuracy: 0.9633 - val_loss: 0.6338 - val_accuracy: 0.8856\n",
      "Epoch 479/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3152 - accuracy: 0.9580 - val_loss: 0.6432 - val_accuracy: 0.8883\n",
      "Epoch 480/500\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.3163 - accuracy: 0.9566 - val_loss: 0.6065 - val_accuracy: 0.8910\n",
      "Epoch 481/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3047 - accuracy: 0.9662 - val_loss: 0.6209 - val_accuracy: 0.8883\n",
      "Epoch 482/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2836 - accuracy: 0.9674 - val_loss: 0.6172 - val_accuracy: 0.8869\n",
      "Epoch 483/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3007 - accuracy: 0.9493 - val_loss: 0.6174 - val_accuracy: 0.8869\n",
      "Epoch 484/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3063 - accuracy: 0.9597 - val_loss: 0.6378 - val_accuracy: 0.8828\n",
      "Epoch 485/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2655 - accuracy: 0.9691 - val_loss: 0.6221 - val_accuracy: 0.8869\n",
      "Epoch 486/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2602 - accuracy: 0.9629 - val_loss: 0.6172 - val_accuracy: 0.8828\n",
      "Epoch 487/500\n",
      "45/45 [==============================] - 1s 14ms/step - loss: 0.2832 - accuracy: 0.9553 - val_loss: 0.6394 - val_accuracy: 0.8828\n",
      "Epoch 488/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.2642 - accuracy: 0.9660 - val_loss: 0.6127 - val_accuracy: 0.8801\n",
      "Epoch 489/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2938 - accuracy: 0.9582 - val_loss: 0.6246 - val_accuracy: 0.8896\n",
      "Epoch 490/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2908 - accuracy: 0.9625 - val_loss: 0.6044 - val_accuracy: 0.8856\n",
      "Epoch 491/500\n",
      "45/45 [==============================] - 1s 16ms/step - loss: 0.3039 - accuracy: 0.9559 - val_loss: 0.6325 - val_accuracy: 0.8883\n",
      "Epoch 492/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2842 - accuracy: 0.9672 - val_loss: 0.6269 - val_accuracy: 0.8856\n",
      "Epoch 493/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3213 - accuracy: 0.9599 - val_loss: 0.6877 - val_accuracy: 0.8883\n",
      "Epoch 494/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3175 - accuracy: 0.9617 - val_loss: 0.6558 - val_accuracy: 0.8828\n",
      "Epoch 495/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2928 - accuracy: 0.9718 - val_loss: 0.6395 - val_accuracy: 0.8815\n",
      "Epoch 496/500\n",
      "45/45 [==============================] - 1s 19ms/step - loss: 0.3260 - accuracy: 0.9504 - val_loss: 0.6542 - val_accuracy: 0.8869\n",
      "Epoch 497/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2770 - accuracy: 0.9659 - val_loss: 0.6260 - val_accuracy: 0.8883\n",
      "Epoch 498/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2882 - accuracy: 0.9656 - val_loss: 0.6603 - val_accuracy: 0.8869\n",
      "Epoch 499/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.3120 - accuracy: 0.9554 - val_loss: 0.6188 - val_accuracy: 0.8856\n",
      "Epoch 500/500\n",
      "45/45 [==============================] - 1s 17ms/step - loss: 0.2598 - accuracy: 0.9629 - val_loss: 0.6080 - val_accuracy: 0.8869\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset_morgan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-26e1848c9450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_mordred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_dataset_mordred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#train_dnn(train_dataset_morgan,test_dataset_morgan)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_morgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset_morgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset_morgan' is not defined"
     ]
    }
   ],
   "source": [
    "model = train_dnn(train_dataset_mordred,valid_dataset_mordred)\n",
    "#train_dnn(train_dataset_morgan,test_dataset_morgan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6317a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################\n",
      "Training Dataset: \n",
      "45/45 [==============================] - 1s 5ms/step\n",
      "roc_auc_score: \n",
      " 0.9819617746088334\n",
      "precision_score: \n",
      " 0.9672131147540983\n",
      "accuracy_score: \n",
      " 0.9822888283378747\n",
      "confusion_matrix: \n",
      " [[1042   38]\n",
      " [   1 1121]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98      1080\n",
      "         1.0       0.97      1.00      0.98      1122\n",
      "\n",
      "    accuracy                           0.98      2202\n",
      "   macro avg       0.98      0.98      0.98      2202\n",
      "weighted avg       0.98      0.98      0.98      2202\n",
      "\n",
      "WARNING: task averager  cannot perform reduce with flexible type\n",
      "Validation Dataset: \n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "roc_auc_score: \n",
      " 0.8859699940582293\n",
      "precision_score: \n",
      " 0.8557457212713936\n",
      "accuracy_score: \n",
      " 0.8869209809264306\n",
      "confusion_matrix: \n",
      " [[301  59]\n",
      " [ 24 350]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.84      0.88       360\n",
      "         1.0       0.86      0.94      0.89       374\n",
      "\n",
      "    accuracy                           0.89       734\n",
      "   macro avg       0.89      0.89      0.89       734\n",
      "weighted avg       0.89      0.89      0.89       734\n",
      "\n",
      "WARNING: task averager  cannot perform reduce with flexible type\n",
      "Test Dataset: \n",
      "15/15 [==============================] - 0s 7ms/step\n",
      "roc_auc_score: \n",
      " 0.8878787878787879\n",
      "precision_score: \n",
      " 0.8762886597938144\n",
      "accuracy_score: \n",
      " 0.888283378746594\n",
      "confusion_matrix: \n",
      " [[312  48]\n",
      " [ 34 340]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.87      0.88       360\n",
      "         1.0       0.88      0.91      0.89       374\n",
      "\n",
      "    accuracy                           0.89       734\n",
      "   macro avg       0.89      0.89      0.89       734\n",
      "weighted avg       0.89      0.89      0.89       734\n",
      "\n",
      "WARNING: task averager  cannot perform reduce with flexible type\n"
     ]
    }
   ],
   "source": [
    "validate_model(model,train_dataset_mordred,valid_dataset_mordred,test_dataset_mordred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45e9f688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizing datapoint 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcapela/miniconda3/envs/deepmol/lib/python3.9/site-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in molecule: <rdkit.Chem.rdchem.Mol object at 0x7f8389c560a0>\n",
      "error in molecule: <rdkit.Chem.rdchem.Mol object at 0x7f8389bb8160>\n",
      "Featurizing datapoint 1000\n",
      "Featurizing datapoint 2000\n",
      "Featurizing datapoint 3000\n",
      "Columns in indexes:  (array([   0,    1,    2, ..., 3458, 3459, 3487]),)  were removed due to the presence of NAs!\n"
     ]
    }
   ],
   "source": [
    "from compoundFeaturization.rdkitFingerprints import MorganFingerprint,AtomPairFingerprint\n",
    "from compoundFeaturization.rdkit3DDescriptors import All3DDescriptors\n",
    "from compoundFeaturization.mixedDescriptors import MixedFeaturizer\n",
    "\n",
    "dataset_mixed = MixedFeaturizer([All3DDescriptors(),MorganFingerprint(1024),mordredDescriptors.MordredFeaturizer()]).featurize(copy(dataset),scale=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35e3e3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit1:  1018\n",
      "dropout_rate =  0.5\n",
      "Epoch 1/500\n",
      "52/52 [==============================] - 3s 17ms/step - loss: 46.6570 - accuracy: 0.7299 - val_loss: 17.8863 - val_accuracy: 0.8297\n",
      "Epoch 2/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 13.5503 - accuracy: 0.8573 - val_loss: 5.7636 - val_accuracy: 0.8692\n",
      "Epoch 3/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 5.0714 - accuracy: 0.8795 - val_loss: 4.1409 - val_accuracy: 0.8692\n",
      "Epoch 4/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 3.7997 - accuracy: 0.8757 - val_loss: 3.2682 - val_accuracy: 0.8719\n",
      "Epoch 5/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 3.5447 - accuracy: 0.8721 - val_loss: 2.8959 - val_accuracy: 0.8038\n",
      "Epoch 6/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 2.7620 - accuracy: 0.9016 - val_loss: 2.5007 - val_accuracy: 0.8719\n",
      "Epoch 7/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 2.4084 - accuracy: 0.9095 - val_loss: 2.2109 - val_accuracy: 0.8733\n",
      "Epoch 8/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 2.0808 - accuracy: 0.9414 - val_loss: 2.1993 - val_accuracy: 0.8760\n",
      "Epoch 9/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.9858 - accuracy: 0.9425 - val_loss: 1.8569 - val_accuracy: 0.8910\n",
      "Epoch 10/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.7599 - accuracy: 0.9373 - val_loss: 2.0247 - val_accuracy: 0.8597\n",
      "Epoch 11/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.7175 - accuracy: 0.9408 - val_loss: 1.8217 - val_accuracy: 0.8787\n",
      "Epoch 12/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.7680 - accuracy: 0.9375 - val_loss: 1.7566 - val_accuracy: 0.8597\n",
      "Epoch 13/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.5804 - accuracy: 0.9292 - val_loss: 1.7435 - val_accuracy: 0.8801\n",
      "Epoch 14/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.5145 - accuracy: 0.9535 - val_loss: 1.6148 - val_accuracy: 0.8815\n",
      "Epoch 15/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.3352 - accuracy: 0.9653 - val_loss: 1.5199 - val_accuracy: 0.8801\n",
      "Epoch 16/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.3015 - accuracy: 0.9573 - val_loss: 1.4752 - val_accuracy: 0.8801\n",
      "Epoch 17/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.3460 - accuracy: 0.9563 - val_loss: 1.5061 - val_accuracy: 0.8706\n",
      "Epoch 18/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.3427 - accuracy: 0.9593 - val_loss: 1.5171 - val_accuracy: 0.8801\n",
      "Epoch 19/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.3936 - accuracy: 0.9578 - val_loss: 1.7089 - val_accuracy: 0.8760\n",
      "Epoch 20/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.3756 - accuracy: 0.9602 - val_loss: 1.5652 - val_accuracy: 0.8678\n",
      "Epoch 21/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.2346 - accuracy: 0.9683 - val_loss: 1.3793 - val_accuracy: 0.8556\n",
      "Epoch 22/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.1143 - accuracy: 0.9697 - val_loss: 1.5397 - val_accuracy: 0.8624\n",
      "Epoch 23/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.2455 - accuracy: 0.9648 - val_loss: 1.3905 - val_accuracy: 0.8801\n",
      "Epoch 24/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0805 - accuracy: 0.9757 - val_loss: 1.4136 - val_accuracy: 0.8774\n",
      "Epoch 25/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.2222 - accuracy: 0.9654 - val_loss: 1.3834 - val_accuracy: 0.8747\n",
      "Epoch 26/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.1438 - accuracy: 0.9675 - val_loss: 1.4516 - val_accuracy: 0.8678\n",
      "Epoch 27/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.2568 - accuracy: 0.9558 - val_loss: 1.3044 - val_accuracy: 0.8638\n",
      "Epoch 28/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.2212 - accuracy: 0.9639 - val_loss: 1.3767 - val_accuracy: 0.8311\n",
      "Epoch 29/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.1965 - accuracy: 0.9607 - val_loss: 1.4197 - val_accuracy: 0.8733\n",
      "Epoch 30/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.3635 - accuracy: 0.9619 - val_loss: 1.4876 - val_accuracy: 0.8787\n",
      "Epoch 31/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0055 - accuracy: 0.9757 - val_loss: 1.2970 - val_accuracy: 0.8719\n",
      "Epoch 32/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0381 - accuracy: 0.9635 - val_loss: 1.3259 - val_accuracy: 0.8719\n",
      "Epoch 33/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0839 - accuracy: 0.9731 - val_loss: 1.3133 - val_accuracy: 0.8542\n",
      "Epoch 34/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.2180 - accuracy: 0.9623 - val_loss: 1.6963 - val_accuracy: 0.8747\n",
      "Epoch 35/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.2679 - accuracy: 0.9715 - val_loss: 1.4322 - val_accuracy: 0.8651\n",
      "Epoch 36/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.1594 - accuracy: 0.9733 - val_loss: 1.6872 - val_accuracy: 0.8692\n",
      "Epoch 37/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.1039 - accuracy: 0.9745 - val_loss: 1.3727 - val_accuracy: 0.8638\n",
      "Epoch 38/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0824 - accuracy: 0.9765 - val_loss: 1.4360 - val_accuracy: 0.8665\n",
      "Epoch 39/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9988 - accuracy: 0.9835 - val_loss: 1.3929 - val_accuracy: 0.8556\n",
      "Epoch 40/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0485 - accuracy: 0.9702 - val_loss: 1.3388 - val_accuracy: 0.8665\n",
      "Epoch 41/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0525 - accuracy: 0.9742 - val_loss: 1.6700 - val_accuracy: 0.8597\n",
      "Epoch 42/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.1552 - accuracy: 0.9671 - val_loss: 1.3718 - val_accuracy: 0.8678\n",
      "Epoch 43/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0268 - accuracy: 0.9821 - val_loss: 1.7009 - val_accuracy: 0.8638\n",
      "Epoch 44/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.1387 - accuracy: 0.9711 - val_loss: 1.4734 - val_accuracy: 0.8665\n",
      "Epoch 45/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9850 - accuracy: 0.9809 - val_loss: 1.4590 - val_accuracy: 0.8692\n",
      "Epoch 46/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0434 - accuracy: 0.9812 - val_loss: 1.2257 - val_accuracy: 0.8624\n",
      "Epoch 47/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0243 - accuracy: 0.9749 - val_loss: 1.6317 - val_accuracy: 0.8719\n",
      "Epoch 48/500\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.0621 - accuracy: 0.9715 - val_loss: 1.5946 - val_accuracy: 0.8706\n",
      "Epoch 49/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8920 - accuracy: 0.9858 - val_loss: 1.3479 - val_accuracy: 0.8597\n",
      "Epoch 50/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.1483 - accuracy: 0.9745 - val_loss: 1.3340 - val_accuracy: 0.8624\n",
      "Epoch 51/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9515 - accuracy: 0.9790 - val_loss: 1.4110 - val_accuracy: 0.8719\n",
      "Epoch 52/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9759 - accuracy: 0.9839 - val_loss: 1.3458 - val_accuracy: 0.8719\n",
      "Epoch 53/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9084 - accuracy: 0.9818 - val_loss: 1.7126 - val_accuracy: 0.8719\n",
      "Epoch 54/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.1703 - accuracy: 0.9550 - val_loss: 1.4271 - val_accuracy: 0.8747\n",
      "Epoch 55/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9937 - accuracy: 0.9759 - val_loss: 1.3562 - val_accuracy: 0.8665\n",
      "Epoch 56/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0244 - accuracy: 0.9705 - val_loss: 1.4687 - val_accuracy: 0.8638\n",
      "Epoch 57/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8867 - accuracy: 0.9804 - val_loss: 1.3431 - val_accuracy: 0.8638\n",
      "Epoch 58/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9851 - accuracy: 0.9822 - val_loss: 1.3974 - val_accuracy: 0.8692\n",
      "Epoch 59/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9490 - accuracy: 0.9797 - val_loss: 1.4332 - val_accuracy: 0.8215\n",
      "Epoch 60/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0038 - accuracy: 0.9789 - val_loss: 1.7277 - val_accuracy: 0.8706\n",
      "Epoch 61/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.1019 - accuracy: 0.9786 - val_loss: 1.3864 - val_accuracy: 0.8747\n",
      "Epoch 62/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9614 - accuracy: 0.9755 - val_loss: 1.3671 - val_accuracy: 0.8392\n",
      "Epoch 63/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9295 - accuracy: 0.9786 - val_loss: 1.3573 - val_accuracy: 0.8678\n",
      "Epoch 64/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9407 - accuracy: 0.9817 - val_loss: 1.3299 - val_accuracy: 0.8638\n",
      "Epoch 65/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8906 - accuracy: 0.9789 - val_loss: 1.1257 - val_accuracy: 0.8678\n",
      "Epoch 66/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7970 - accuracy: 0.9868 - val_loss: 1.4368 - val_accuracy: 0.8651\n",
      "Epoch 67/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9064 - accuracy: 0.9855 - val_loss: 1.3837 - val_accuracy: 0.8638\n",
      "Epoch 68/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9626 - accuracy: 0.9709 - val_loss: 1.1886 - val_accuracy: 0.8556\n",
      "Epoch 69/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8644 - accuracy: 0.9774 - val_loss: 1.3555 - val_accuracy: 0.8692\n",
      "Epoch 70/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8025 - accuracy: 0.9841 - val_loss: 1.1335 - val_accuracy: 0.8651\n",
      "Epoch 71/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7996 - accuracy: 0.9727 - val_loss: 1.3909 - val_accuracy: 0.8556\n",
      "Epoch 72/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7766 - accuracy: 0.9895 - val_loss: 1.1158 - val_accuracy: 0.8706\n",
      "Epoch 73/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7803 - accuracy: 0.9756 - val_loss: 1.2748 - val_accuracy: 0.8610\n",
      "Epoch 74/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7532 - accuracy: 0.9829 - val_loss: 1.1104 - val_accuracy: 0.8556\n",
      "Epoch 75/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6808 - accuracy: 0.9872 - val_loss: 1.2744 - val_accuracy: 0.8460\n",
      "Epoch 76/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7534 - accuracy: 0.9790 - val_loss: 1.1716 - val_accuracy: 0.8569\n",
      "Epoch 77/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7798 - accuracy: 0.9785 - val_loss: 1.2063 - val_accuracy: 0.8651\n",
      "Epoch 78/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6325 - accuracy: 0.9909 - val_loss: 1.4596 - val_accuracy: 0.8610\n",
      "Epoch 79/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8716 - accuracy: 0.9739 - val_loss: 1.3215 - val_accuracy: 0.8760\n",
      "Epoch 80/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8419 - accuracy: 0.9846 - val_loss: 1.2941 - val_accuracy: 0.8651\n",
      "Epoch 81/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9982 - accuracy: 0.9761 - val_loss: 1.3209 - val_accuracy: 0.8678\n",
      "Epoch 82/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8371 - accuracy: 0.9840 - val_loss: 1.4902 - val_accuracy: 0.8733\n",
      "Epoch 83/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8656 - accuracy: 0.9835 - val_loss: 1.2482 - val_accuracy: 0.8719\n",
      "Epoch 84/500\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.8531 - accuracy: 0.9805 - val_loss: 1.2864 - val_accuracy: 0.8760\n",
      "Epoch 85/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7286 - accuracy: 0.9886 - val_loss: 1.2568 - val_accuracy: 0.8392\n",
      "Epoch 86/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7675 - accuracy: 0.9834 - val_loss: 1.2234 - val_accuracy: 0.8638\n",
      "Epoch 87/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7330 - accuracy: 0.9828 - val_loss: 1.3774 - val_accuracy: 0.8351\n",
      "Epoch 88/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7644 - accuracy: 0.9840 - val_loss: 1.1991 - val_accuracy: 0.8583\n",
      "Epoch 89/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7427 - accuracy: 0.9907 - val_loss: 1.2320 - val_accuracy: 0.8678\n",
      "Epoch 90/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8404 - accuracy: 0.9791 - val_loss: 1.4108 - val_accuracy: 0.8706\n",
      "Epoch 91/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9675 - accuracy: 0.9798 - val_loss: 1.4407 - val_accuracy: 0.8678\n",
      "Epoch 92/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0683 - accuracy: 0.9785 - val_loss: 1.4265 - val_accuracy: 0.8556\n",
      "Epoch 93/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9296 - accuracy: 0.9840 - val_loss: 1.3508 - val_accuracy: 0.8678\n",
      "Epoch 94/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7823 - accuracy: 0.9855 - val_loss: 1.5667 - val_accuracy: 0.8202\n",
      "Epoch 95/500\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.9989 - accuracy: 0.9848 - val_loss: 1.4415 - val_accuracy: 0.8706\n",
      "Epoch 96/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8568 - accuracy: 0.9871 - val_loss: 1.3952 - val_accuracy: 0.8665\n",
      "Epoch 97/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9430 - accuracy: 0.9805 - val_loss: 1.4458 - val_accuracy: 0.8638\n",
      "Epoch 98/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7736 - accuracy: 0.9838 - val_loss: 1.2358 - val_accuracy: 0.8583\n",
      "Epoch 99/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7772 - accuracy: 0.9854 - val_loss: 1.2372 - val_accuracy: 0.8733\n",
      "Epoch 100/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7063 - accuracy: 0.9876 - val_loss: 1.3241 - val_accuracy: 0.8351\n",
      "Epoch 101/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8536 - accuracy: 0.9856 - val_loss: 1.2204 - val_accuracy: 0.8678\n",
      "Epoch 102/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7931 - accuracy: 0.9900 - val_loss: 1.7136 - val_accuracy: 0.8583\n",
      "Epoch 103/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0173 - accuracy: 0.9848 - val_loss: 1.3834 - val_accuracy: 0.8624\n",
      "Epoch 104/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8102 - accuracy: 0.9893 - val_loss: 1.4111 - val_accuracy: 0.8569\n",
      "Epoch 105/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0605 - accuracy: 0.9847 - val_loss: 1.7113 - val_accuracy: 0.8556\n",
      "Epoch 106/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8070 - accuracy: 0.9937 - val_loss: 1.1303 - val_accuracy: 0.8651\n",
      "Epoch 107/500\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.6303 - accuracy: 0.9957 - val_loss: 1.1487 - val_accuracy: 0.8638\n",
      "Epoch 108/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6527 - accuracy: 0.9860 - val_loss: 1.3648 - val_accuracy: 0.8202\n",
      "Epoch 109/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7063 - accuracy: 0.9876 - val_loss: 1.4108 - val_accuracy: 0.8624\n",
      "Epoch 110/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7731 - accuracy: 0.9794 - val_loss: 1.4981 - val_accuracy: 0.8638\n",
      "Epoch 111/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7125 - accuracy: 0.9841 - val_loss: 1.3730 - val_accuracy: 0.8597\n",
      "Epoch 112/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7159 - accuracy: 0.9838 - val_loss: 1.2761 - val_accuracy: 0.8624\n",
      "Epoch 113/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7502 - accuracy: 0.9858 - val_loss: 1.4556 - val_accuracy: 0.8610\n",
      "Epoch 114/500\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.7192 - accuracy: 0.9859 - val_loss: 1.2463 - val_accuracy: 0.8638\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 11ms/step - loss: 0.7160 - accuracy: 0.9884 - val_loss: 1.2881 - val_accuracy: 0.8651\n",
      "Epoch 116/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7264 - accuracy: 0.9820 - val_loss: 1.2797 - val_accuracy: 0.8569\n",
      "Epoch 117/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6235 - accuracy: 0.9887 - val_loss: 1.0624 - val_accuracy: 0.8610\n",
      "Epoch 118/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6374 - accuracy: 0.9825 - val_loss: 1.3140 - val_accuracy: 0.8474\n",
      "Epoch 119/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7304 - accuracy: 0.9819 - val_loss: 1.2741 - val_accuracy: 0.8597\n",
      "Epoch 120/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7697 - accuracy: 0.9748 - val_loss: 1.4444 - val_accuracy: 0.8597\n",
      "Epoch 121/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7801 - accuracy: 0.9867 - val_loss: 1.1954 - val_accuracy: 0.8379\n",
      "Epoch 122/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8118 - accuracy: 0.9722 - val_loss: 1.4190 - val_accuracy: 0.8638\n",
      "Epoch 123/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6379 - accuracy: 0.9890 - val_loss: 1.0836 - val_accuracy: 0.8583\n",
      "Epoch 124/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5306 - accuracy: 0.9899 - val_loss: 1.1190 - val_accuracy: 0.8542\n",
      "Epoch 125/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5961 - accuracy: 0.9833 - val_loss: 1.3861 - val_accuracy: 0.8678\n",
      "Epoch 126/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7290 - accuracy: 0.9807 - val_loss: 1.3776 - val_accuracy: 0.8624\n",
      "Epoch 127/500\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.5751 - accuracy: 0.9903 - val_loss: 1.1921 - val_accuracy: 0.8597\n",
      "Epoch 128/500\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.5741 - accuracy: 0.9880 - val_loss: 1.0544 - val_accuracy: 0.8488\n",
      "Epoch 129/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5365 - accuracy: 0.9894 - val_loss: 1.0579 - val_accuracy: 0.8583\n",
      "Epoch 130/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6073 - accuracy: 0.9905 - val_loss: 1.2959 - val_accuracy: 0.8583\n",
      "Epoch 131/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6049 - accuracy: 0.9934 - val_loss: 1.1487 - val_accuracy: 0.8569\n",
      "Epoch 132/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5226 - accuracy: 0.9875 - val_loss: 1.4070 - val_accuracy: 0.8651\n",
      "Epoch 133/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6843 - accuracy: 0.9831 - val_loss: 1.1579 - val_accuracy: 0.8583\n",
      "Epoch 134/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5752 - accuracy: 0.9913 - val_loss: 1.1234 - val_accuracy: 0.8597\n",
      "Epoch 135/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7699 - accuracy: 0.9716 - val_loss: 1.1951 - val_accuracy: 0.8665\n",
      "Epoch 136/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6303 - accuracy: 0.9918 - val_loss: 1.1872 - val_accuracy: 0.8556\n",
      "Epoch 137/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5383 - accuracy: 0.9950 - val_loss: 1.1611 - val_accuracy: 0.8610\n",
      "Epoch 138/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5460 - accuracy: 0.9904 - val_loss: 1.1686 - val_accuracy: 0.8610\n",
      "Epoch 139/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5982 - accuracy: 0.9865 - val_loss: 1.2509 - val_accuracy: 0.8556\n",
      "Epoch 140/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6610 - accuracy: 0.9833 - val_loss: 1.1680 - val_accuracy: 0.8706\n",
      "Epoch 141/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5654 - accuracy: 0.9919 - val_loss: 1.1660 - val_accuracy: 0.8474\n",
      "Epoch 142/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6102 - accuracy: 0.9855 - val_loss: 1.2612 - val_accuracy: 0.8501\n",
      "Epoch 143/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.1369 - accuracy: 0.9718 - val_loss: 1.9439 - val_accuracy: 0.8392\n",
      "Epoch 144/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8761 - accuracy: 0.9891 - val_loss: 1.1805 - val_accuracy: 0.8488\n",
      "Epoch 145/500\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.6154 - accuracy: 0.9914 - val_loss: 1.3068 - val_accuracy: 0.8529\n",
      "Epoch 146/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7505 - accuracy: 0.9863 - val_loss: 1.3157 - val_accuracy: 0.8569\n",
      "Epoch 147/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6793 - accuracy: 0.9863 - val_loss: 1.4025 - val_accuracy: 0.8583\n",
      "Epoch 148/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5914 - accuracy: 0.9886 - val_loss: 1.2870 - val_accuracy: 0.8569\n",
      "Epoch 149/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6212 - accuracy: 0.9887 - val_loss: 1.1310 - val_accuracy: 0.8420\n",
      "Epoch 150/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5274 - accuracy: 0.9931 - val_loss: 1.1170 - val_accuracy: 0.8501\n",
      "Epoch 151/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5507 - accuracy: 0.9880 - val_loss: 1.2364 - val_accuracy: 0.8569\n",
      "Epoch 152/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5492 - accuracy: 0.9914 - val_loss: 1.1008 - val_accuracy: 0.8542\n",
      "Epoch 153/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5721 - accuracy: 0.9816 - val_loss: 1.1068 - val_accuracy: 0.8529\n",
      "Epoch 154/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5018 - accuracy: 0.9898 - val_loss: 1.2302 - val_accuracy: 0.8678\n",
      "Epoch 155/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5796 - accuracy: 0.9876 - val_loss: 1.4204 - val_accuracy: 0.8706\n",
      "Epoch 156/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6318 - accuracy: 0.9868 - val_loss: 1.1602 - val_accuracy: 0.8678\n",
      "Epoch 157/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4955 - accuracy: 0.9943 - val_loss: 1.1634 - val_accuracy: 0.8678\n",
      "Epoch 158/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4900 - accuracy: 0.9924 - val_loss: 1.1466 - val_accuracy: 0.8638\n",
      "Epoch 159/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5319 - accuracy: 0.9897 - val_loss: 1.1812 - val_accuracy: 0.8501\n",
      "Epoch 160/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5086 - accuracy: 0.9909 - val_loss: 1.4032 - val_accuracy: 0.8624\n",
      "Epoch 161/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5821 - accuracy: 0.9876 - val_loss: 1.3470 - val_accuracy: 0.8447\n",
      "Epoch 162/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5111 - accuracy: 0.9931 - val_loss: 1.6158 - val_accuracy: 0.8488\n",
      "Epoch 163/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5831 - accuracy: 0.9939 - val_loss: 1.0518 - val_accuracy: 0.8529\n",
      "Epoch 164/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4804 - accuracy: 0.9896 - val_loss: 1.6739 - val_accuracy: 0.8447\n",
      "Epoch 165/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5396 - accuracy: 0.9934 - val_loss: 1.1700 - val_accuracy: 0.8597\n",
      "Epoch 166/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5978 - accuracy: 0.9885 - val_loss: 1.2171 - val_accuracy: 0.8651\n",
      "Epoch 167/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5401 - accuracy: 0.9846 - val_loss: 1.1541 - val_accuracy: 0.8501\n",
      "Epoch 168/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4723 - accuracy: 0.9923 - val_loss: 1.1250 - val_accuracy: 0.8583\n",
      "Epoch 169/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4069 - accuracy: 0.9970 - val_loss: 1.0666 - val_accuracy: 0.8638\n",
      "Epoch 170/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4610 - accuracy: 0.9885 - val_loss: 1.0158 - val_accuracy: 0.8556\n",
      "Epoch 171/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3836 - accuracy: 0.9973 - val_loss: 1.1557 - val_accuracy: 0.8624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4503 - accuracy: 0.9870 - val_loss: 1.2280 - val_accuracy: 0.8501\n",
      "Epoch 173/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4475 - accuracy: 0.9929 - val_loss: 1.1064 - val_accuracy: 0.8651\n",
      "Epoch 174/500\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.4040 - accuracy: 0.9930 - val_loss: 1.0729 - val_accuracy: 0.8610\n",
      "Epoch 175/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3921 - accuracy: 0.9932 - val_loss: 1.3093 - val_accuracy: 0.8569\n",
      "Epoch 176/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6009 - accuracy: 0.9823 - val_loss: 1.5840 - val_accuracy: 0.8638\n",
      "Epoch 177/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5316 - accuracy: 0.9936 - val_loss: 1.2727 - val_accuracy: 0.8638\n",
      "Epoch 178/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4742 - accuracy: 0.9897 - val_loss: 1.0553 - val_accuracy: 0.8665\n",
      "Epoch 179/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4161 - accuracy: 0.9964 - val_loss: 0.9680 - val_accuracy: 0.8569\n",
      "Epoch 180/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4214 - accuracy: 0.9905 - val_loss: 1.2749 - val_accuracy: 0.8774\n",
      "Epoch 181/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4518 - accuracy: 0.9925 - val_loss: 1.3275 - val_accuracy: 0.8569\n",
      "Epoch 182/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4948 - accuracy: 0.9848 - val_loss: 1.3602 - val_accuracy: 0.8583\n",
      "Epoch 183/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4585 - accuracy: 0.9915 - val_loss: 1.3974 - val_accuracy: 0.8556\n",
      "Epoch 184/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6268 - accuracy: 0.9909 - val_loss: 1.1715 - val_accuracy: 0.8542\n",
      "Epoch 185/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5614 - accuracy: 0.9893 - val_loss: 1.1957 - val_accuracy: 0.8665\n",
      "Epoch 186/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4887 - accuracy: 0.9915 - val_loss: 1.1672 - val_accuracy: 0.8529\n",
      "Epoch 187/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5056 - accuracy: 0.9901 - val_loss: 1.0510 - val_accuracy: 0.8597\n",
      "Epoch 188/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5101 - accuracy: 0.9887 - val_loss: 1.1410 - val_accuracy: 0.8597\n",
      "Epoch 189/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4459 - accuracy: 0.9933 - val_loss: 1.0111 - val_accuracy: 0.8474\n",
      "Epoch 190/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4346 - accuracy: 0.9917 - val_loss: 1.0544 - val_accuracy: 0.8624\n",
      "Epoch 191/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4024 - accuracy: 0.9936 - val_loss: 1.2891 - val_accuracy: 0.8610\n",
      "Epoch 192/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4814 - accuracy: 0.9933 - val_loss: 1.1193 - val_accuracy: 0.8392\n",
      "Epoch 193/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4249 - accuracy: 0.9927 - val_loss: 1.1926 - val_accuracy: 0.8651\n",
      "Epoch 194/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4971 - accuracy: 0.9899 - val_loss: 1.1324 - val_accuracy: 0.8597\n",
      "Epoch 195/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3974 - accuracy: 0.9954 - val_loss: 1.1605 - val_accuracy: 0.8556\n",
      "Epoch 196/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4873 - accuracy: 0.9925 - val_loss: 1.1345 - val_accuracy: 0.8597\n",
      "Epoch 197/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4739 - accuracy: 0.9906 - val_loss: 1.2252 - val_accuracy: 0.8651\n",
      "Epoch 198/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4917 - accuracy: 0.9904 - val_loss: 1.1207 - val_accuracy: 0.8665\n",
      "Epoch 199/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3963 - accuracy: 0.9974 - val_loss: 1.0174 - val_accuracy: 0.8665\n",
      "Epoch 200/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4464 - accuracy: 0.9868 - val_loss: 1.4655 - val_accuracy: 0.8624\n",
      "Epoch 201/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5562 - accuracy: 0.9848 - val_loss: 1.3267 - val_accuracy: 0.8678\n",
      "Epoch 202/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5038 - accuracy: 0.9890 - val_loss: 1.1898 - val_accuracy: 0.8542\n",
      "Epoch 203/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4733 - accuracy: 0.9910 - val_loss: 1.2539 - val_accuracy: 0.8488\n",
      "Epoch 204/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5524 - accuracy: 0.9885 - val_loss: 1.2005 - val_accuracy: 0.8719\n",
      "Epoch 205/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4684 - accuracy: 0.9873 - val_loss: 1.1165 - val_accuracy: 0.8610\n",
      "Epoch 206/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5257 - accuracy: 0.9891 - val_loss: 1.2833 - val_accuracy: 0.8638\n",
      "Epoch 207/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4423 - accuracy: 0.9937 - val_loss: 1.1249 - val_accuracy: 0.8706\n",
      "Epoch 208/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5012 - accuracy: 0.9881 - val_loss: 1.1282 - val_accuracy: 0.8706\n",
      "Epoch 209/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4392 - accuracy: 0.9923 - val_loss: 0.9752 - val_accuracy: 0.8597\n",
      "Epoch 210/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3856 - accuracy: 0.9931 - val_loss: 1.0627 - val_accuracy: 0.8665\n",
      "Epoch 211/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5034 - accuracy: 0.9933 - val_loss: 1.2928 - val_accuracy: 0.8610\n",
      "Epoch 212/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4610 - accuracy: 0.9891 - val_loss: 1.1824 - val_accuracy: 0.8651\n",
      "Epoch 213/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4012 - accuracy: 0.9959 - val_loss: 1.1321 - val_accuracy: 0.8556\n",
      "Epoch 214/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4152 - accuracy: 0.9947 - val_loss: 1.0484 - val_accuracy: 0.8529\n",
      "Epoch 215/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3939 - accuracy: 0.9947 - val_loss: 1.2010 - val_accuracy: 0.8692\n",
      "Epoch 216/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4206 - accuracy: 0.9939 - val_loss: 1.1116 - val_accuracy: 0.8515\n",
      "Epoch 217/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6803 - accuracy: 0.9803 - val_loss: 1.5927 - val_accuracy: 0.8542\n",
      "Epoch 218/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5520 - accuracy: 0.9922 - val_loss: 1.2108 - val_accuracy: 0.8460\n",
      "Epoch 219/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5467 - accuracy: 0.9906 - val_loss: 1.2478 - val_accuracy: 0.8569\n",
      "Epoch 220/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4447 - accuracy: 0.9932 - val_loss: 1.1058 - val_accuracy: 0.8706\n",
      "Epoch 221/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4736 - accuracy: 0.9878 - val_loss: 1.1088 - val_accuracy: 0.8638\n",
      "Epoch 222/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4923 - accuracy: 0.9948 - val_loss: 0.9866 - val_accuracy: 0.8651\n",
      "Epoch 223/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4383 - accuracy: 0.9896 - val_loss: 1.1358 - val_accuracy: 0.8706\n",
      "Epoch 224/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4141 - accuracy: 0.9958 - val_loss: 1.0875 - val_accuracy: 0.8733\n",
      "Epoch 225/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4645 - accuracy: 0.9955 - val_loss: 1.1423 - val_accuracy: 0.8665\n",
      "Epoch 226/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3844 - accuracy: 0.9972 - val_loss: 1.0583 - val_accuracy: 0.8583\n",
      "Epoch 227/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3963 - accuracy: 0.9967 - val_loss: 1.1287 - val_accuracy: 0.8460\n",
      "Epoch 228/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4317 - accuracy: 0.9900 - val_loss: 1.2695 - val_accuracy: 0.8488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4600 - accuracy: 0.9929 - val_loss: 1.2463 - val_accuracy: 0.8638\n",
      "Epoch 230/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4416 - accuracy: 0.9862 - val_loss: 1.0905 - val_accuracy: 0.8624\n",
      "Epoch 231/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3825 - accuracy: 0.9951 - val_loss: 1.0122 - val_accuracy: 0.8610\n",
      "Epoch 232/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3149 - accuracy: 0.9986 - val_loss: 0.9914 - val_accuracy: 0.8542\n",
      "Epoch 233/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3964 - accuracy: 0.9919 - val_loss: 1.0082 - val_accuracy: 0.8692\n",
      "Epoch 234/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3639 - accuracy: 0.9939 - val_loss: 1.1939 - val_accuracy: 0.8556\n",
      "Epoch 235/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4550 - accuracy: 0.9896 - val_loss: 1.2443 - val_accuracy: 0.8651\n",
      "Epoch 236/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4091 - accuracy: 0.9933 - val_loss: 1.1447 - val_accuracy: 0.8379\n",
      "Epoch 237/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4302 - accuracy: 0.9889 - val_loss: 1.1629 - val_accuracy: 0.8597\n",
      "Epoch 238/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3970 - accuracy: 0.9903 - val_loss: 1.2740 - val_accuracy: 0.8665\n",
      "Epoch 239/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4423 - accuracy: 0.9939 - val_loss: 1.3646 - val_accuracy: 0.8597\n",
      "Epoch 240/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4129 - accuracy: 0.9965 - val_loss: 0.9793 - val_accuracy: 0.8529\n",
      "Epoch 241/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3344 - accuracy: 0.9975 - val_loss: 1.0131 - val_accuracy: 0.8610\n",
      "Epoch 242/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4067 - accuracy: 0.9914 - val_loss: 1.2116 - val_accuracy: 0.8597\n",
      "Epoch 243/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4252 - accuracy: 0.9874 - val_loss: 1.4353 - val_accuracy: 0.8447\n",
      "Epoch 244/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4311 - accuracy: 0.9936 - val_loss: 1.1148 - val_accuracy: 0.8447\n",
      "Epoch 245/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4817 - accuracy: 0.9939 - val_loss: 1.0596 - val_accuracy: 0.8610\n",
      "Epoch 246/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3521 - accuracy: 0.9962 - val_loss: 0.9826 - val_accuracy: 0.8651\n",
      "Epoch 247/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3551 - accuracy: 0.9951 - val_loss: 1.0308 - val_accuracy: 0.8733\n",
      "Epoch 248/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3788 - accuracy: 0.9955 - val_loss: 1.0524 - val_accuracy: 0.8542\n",
      "Epoch 249/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4940 - accuracy: 0.9901 - val_loss: 1.3273 - val_accuracy: 0.8651\n",
      "Epoch 250/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4745 - accuracy: 0.9858 - val_loss: 1.2294 - val_accuracy: 0.8610\n",
      "Epoch 251/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4502 - accuracy: 0.9901 - val_loss: 1.2023 - val_accuracy: 0.8610\n",
      "Epoch 252/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4615 - accuracy: 0.9875 - val_loss: 1.3407 - val_accuracy: 0.8651\n",
      "Epoch 253/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4264 - accuracy: 0.9916 - val_loss: 1.1736 - val_accuracy: 0.8406\n",
      "Epoch 254/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4581 - accuracy: 0.9893 - val_loss: 1.1284 - val_accuracy: 0.8501\n",
      "Epoch 255/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3867 - accuracy: 0.9956 - val_loss: 1.0917 - val_accuracy: 0.8542\n",
      "Epoch 256/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3764 - accuracy: 0.9945 - val_loss: 1.0096 - val_accuracy: 0.8460\n",
      "Epoch 257/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3911 - accuracy: 0.9966 - val_loss: 1.2385 - val_accuracy: 0.8665\n",
      "Epoch 258/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4282 - accuracy: 0.9917 - val_loss: 1.1189 - val_accuracy: 0.8542\n",
      "Epoch 259/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4518 - accuracy: 0.9853 - val_loss: 1.2915 - val_accuracy: 0.8583\n",
      "Epoch 260/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4471 - accuracy: 0.9917 - val_loss: 1.0778 - val_accuracy: 0.8638\n",
      "Epoch 261/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3777 - accuracy: 0.9931 - val_loss: 1.0979 - val_accuracy: 0.8569\n",
      "Epoch 262/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3557 - accuracy: 0.9960 - val_loss: 1.1965 - val_accuracy: 0.8692\n",
      "Epoch 263/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3540 - accuracy: 0.9946 - val_loss: 1.1244 - val_accuracy: 0.8665\n",
      "Epoch 264/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4469 - accuracy: 0.9896 - val_loss: 1.1827 - val_accuracy: 0.8624\n",
      "Epoch 265/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3689 - accuracy: 0.9947 - val_loss: 1.1896 - val_accuracy: 0.8624\n",
      "Epoch 266/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4855 - accuracy: 0.9855 - val_loss: 1.2418 - val_accuracy: 0.8624\n",
      "Epoch 267/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3747 - accuracy: 0.9965 - val_loss: 1.3756 - val_accuracy: 0.8665\n",
      "Epoch 268/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4818 - accuracy: 0.9927 - val_loss: 1.2090 - val_accuracy: 0.8638\n",
      "Epoch 269/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3944 - accuracy: 0.9927 - val_loss: 1.0338 - val_accuracy: 0.8542\n",
      "Epoch 270/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3594 - accuracy: 0.9904 - val_loss: 1.1522 - val_accuracy: 0.8501\n",
      "Epoch 271/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4068 - accuracy: 0.9889 - val_loss: 1.2434 - val_accuracy: 0.8665\n",
      "Epoch 272/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4177 - accuracy: 0.9905 - val_loss: 1.1408 - val_accuracy: 0.8678\n",
      "Epoch 273/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4040 - accuracy: 0.9878 - val_loss: 1.3632 - val_accuracy: 0.8515\n",
      "Epoch 274/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4082 - accuracy: 0.9958 - val_loss: 1.2039 - val_accuracy: 0.8624\n",
      "Epoch 275/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4061 - accuracy: 0.9946 - val_loss: 1.0876 - val_accuracy: 0.8638\n",
      "Epoch 276/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3809 - accuracy: 0.9919 - val_loss: 1.0746 - val_accuracy: 0.8610\n",
      "Epoch 277/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3203 - accuracy: 0.9959 - val_loss: 1.1209 - val_accuracy: 0.8624\n",
      "Epoch 278/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3621 - accuracy: 0.9907 - val_loss: 1.2802 - val_accuracy: 0.8624\n",
      "Epoch 279/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4697 - accuracy: 0.9841 - val_loss: 1.2216 - val_accuracy: 0.8460\n",
      "\n",
      "Epoch 00279: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 280/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3172 - accuracy: 0.9962 - val_loss: 0.9276 - val_accuracy: 0.8542\n",
      "Epoch 281/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2311 - accuracy: 0.9910 - val_loss: 0.9065 - val_accuracy: 0.8556\n",
      "Epoch 282/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2096 - accuracy: 0.9960 - val_loss: 0.9008 - val_accuracy: 0.8515\n",
      "Epoch 283/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2134 - accuracy: 0.9966 - val_loss: 0.8723 - val_accuracy: 0.8638\n",
      "Epoch 284/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1958 - accuracy: 0.9961 - val_loss: 0.8423 - val_accuracy: 0.8597\n",
      "Epoch 285/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1935 - accuracy: 0.9980 - val_loss: 0.8545 - val_accuracy: 0.8638\n",
      "Epoch 286/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1728 - accuracy: 0.9975 - val_loss: 0.8971 - val_accuracy: 0.8638\n",
      "Epoch 287/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1782 - accuracy: 0.9964 - val_loss: 0.8333 - val_accuracy: 0.8638\n",
      "Epoch 288/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1737 - accuracy: 0.9963 - val_loss: 0.9207 - val_accuracy: 0.8610\n",
      "Epoch 289/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1773 - accuracy: 0.9956 - val_loss: 0.8839 - val_accuracy: 0.8583\n",
      "Epoch 290/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1632 - accuracy: 0.9990 - val_loss: 0.8662 - val_accuracy: 0.8515\n",
      "Epoch 291/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1851 - accuracy: 0.9971 - val_loss: 0.8947 - val_accuracy: 0.8583\n",
      "Epoch 292/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1844 - accuracy: 0.9941 - val_loss: 0.8802 - val_accuracy: 0.8474\n",
      "Epoch 293/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2124 - accuracy: 0.9942 - val_loss: 0.9815 - val_accuracy: 0.8569\n",
      "Epoch 294/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1786 - accuracy: 0.9994 - val_loss: 0.8555 - val_accuracy: 0.8610\n",
      "Epoch 295/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1695 - accuracy: 0.9963 - val_loss: 0.8398 - val_accuracy: 0.8460\n",
      "Epoch 296/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1984 - accuracy: 0.9920 - val_loss: 1.0110 - val_accuracy: 0.8597\n",
      "Epoch 297/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2641 - accuracy: 0.9960 - val_loss: 1.1539 - val_accuracy: 0.8583\n",
      "Epoch 298/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2222 - accuracy: 0.9941 - val_loss: 1.0590 - val_accuracy: 0.8638\n",
      "Epoch 299/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2094 - accuracy: 0.9987 - val_loss: 0.9168 - val_accuracy: 0.8597\n",
      "Epoch 300/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1983 - accuracy: 0.9952 - val_loss: 0.9086 - val_accuracy: 0.8515\n",
      "Epoch 301/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1790 - accuracy: 0.9975 - val_loss: 0.8583 - val_accuracy: 0.8569\n",
      "Epoch 302/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1829 - accuracy: 0.9960 - val_loss: 1.0495 - val_accuracy: 0.8597\n",
      "Epoch 303/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2120 - accuracy: 0.9930 - val_loss: 0.9112 - val_accuracy: 0.8542\n",
      "Epoch 304/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1888 - accuracy: 0.9949 - val_loss: 0.9309 - val_accuracy: 0.8556\n",
      "Epoch 305/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2290 - accuracy: 0.9923 - val_loss: 0.9820 - val_accuracy: 0.8515\n",
      "Epoch 306/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1856 - accuracy: 0.9962 - val_loss: 0.9041 - val_accuracy: 0.8583\n",
      "Epoch 307/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1626 - accuracy: 0.9982 - val_loss: 0.8852 - val_accuracy: 0.8542\n",
      "Epoch 308/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1652 - accuracy: 0.9974 - val_loss: 0.8668 - val_accuracy: 0.8515\n",
      "Epoch 309/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1846 - accuracy: 0.9959 - val_loss: 1.0387 - val_accuracy: 0.8583\n",
      "Epoch 310/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1958 - accuracy: 0.9953 - val_loss: 0.9655 - val_accuracy: 0.8542\n",
      "Epoch 311/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1759 - accuracy: 0.9951 - val_loss: 0.9338 - val_accuracy: 0.8474\n",
      "Epoch 312/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1738 - accuracy: 0.9958 - val_loss: 1.0354 - val_accuracy: 0.8583\n",
      "Epoch 313/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1801 - accuracy: 0.9973 - val_loss: 1.0134 - val_accuracy: 0.8583\n",
      "Epoch 314/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1678 - accuracy: 0.9984 - val_loss: 0.8850 - val_accuracy: 0.8529\n",
      "Epoch 315/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1538 - accuracy: 0.9988 - val_loss: 0.8917 - val_accuracy: 0.8529\n",
      "Epoch 316/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1735 - accuracy: 0.9944 - val_loss: 1.0139 - val_accuracy: 0.8651\n",
      "Epoch 317/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1828 - accuracy: 0.9950 - val_loss: 0.9842 - val_accuracy: 0.8542\n",
      "Epoch 318/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1781 - accuracy: 0.9970 - val_loss: 0.9090 - val_accuracy: 0.8447\n",
      "Epoch 319/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1637 - accuracy: 0.9982 - val_loss: 1.1051 - val_accuracy: 0.8583\n",
      "Epoch 320/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1828 - accuracy: 0.9964 - val_loss: 1.0092 - val_accuracy: 0.8488\n",
      "Epoch 321/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1972 - accuracy: 0.9965 - val_loss: 1.1264 - val_accuracy: 0.8583\n",
      "Epoch 322/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1944 - accuracy: 0.9951 - val_loss: 0.9213 - val_accuracy: 0.8569\n",
      "Epoch 323/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1764 - accuracy: 0.9965 - val_loss: 0.8912 - val_accuracy: 0.8529\n",
      "Epoch 324/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1739 - accuracy: 0.9938 - val_loss: 0.9469 - val_accuracy: 0.8529\n",
      "Epoch 325/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1767 - accuracy: 0.9936 - val_loss: 0.8958 - val_accuracy: 0.8460\n",
      "Epoch 326/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1712 - accuracy: 0.9948 - val_loss: 0.9169 - val_accuracy: 0.8529\n",
      "Epoch 327/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1727 - accuracy: 0.9977 - val_loss: 1.0236 - val_accuracy: 0.8556\n",
      "Epoch 328/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1783 - accuracy: 0.9979 - val_loss: 1.0280 - val_accuracy: 0.8515\n",
      "Epoch 329/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2033 - accuracy: 0.9937 - val_loss: 1.4963 - val_accuracy: 0.8433\n",
      "Epoch 330/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2414 - accuracy: 0.9977 - val_loss: 1.1123 - val_accuracy: 0.8447\n",
      "Epoch 331/500\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.2006 - accuracy: 0.9963 - val_loss: 0.9676 - val_accuracy: 0.8556\n",
      "Epoch 332/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1922 - accuracy: 0.9966 - val_loss: 0.9241 - val_accuracy: 0.8569\n",
      "Epoch 333/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1934 - accuracy: 0.9955 - val_loss: 0.9031 - val_accuracy: 0.8542\n",
      "Epoch 334/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1870 - accuracy: 0.9959 - val_loss: 0.9302 - val_accuracy: 0.8583\n",
      "Epoch 335/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1685 - accuracy: 0.9972 - val_loss: 0.8809 - val_accuracy: 0.8488\n",
      "Epoch 336/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1991 - accuracy: 0.9953 - val_loss: 1.1619 - val_accuracy: 0.8651\n",
      "Epoch 337/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2283 - accuracy: 0.9957 - val_loss: 0.9966 - val_accuracy: 0.8515\n",
      "Epoch 338/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1718 - accuracy: 0.9979 - val_loss: 0.9462 - val_accuracy: 0.8529\n",
      "Epoch 339/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1814 - accuracy: 0.9961 - val_loss: 0.9698 - val_accuracy: 0.8569\n",
      "Epoch 340/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1749 - accuracy: 0.9966 - val_loss: 0.9534 - val_accuracy: 0.8556\n",
      "Epoch 341/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1700 - accuracy: 0.9954 - val_loss: 0.9406 - val_accuracy: 0.8529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1729 - accuracy: 0.9952 - val_loss: 0.9644 - val_accuracy: 0.8624\n",
      "Epoch 343/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1697 - accuracy: 0.9975 - val_loss: 1.0225 - val_accuracy: 0.8474\n",
      "Epoch 344/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1779 - accuracy: 0.9969 - val_loss: 0.9647 - val_accuracy: 0.8610\n",
      "Epoch 345/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1768 - accuracy: 0.9962 - val_loss: 1.0398 - val_accuracy: 0.8515\n",
      "Epoch 346/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2004 - accuracy: 0.9970 - val_loss: 1.0683 - val_accuracy: 0.8610\n",
      "Epoch 347/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1790 - accuracy: 0.9968 - val_loss: 0.9737 - val_accuracy: 0.8529\n",
      "Epoch 348/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1656 - accuracy: 0.9970 - val_loss: 0.9597 - val_accuracy: 0.8556\n",
      "Epoch 349/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1713 - accuracy: 0.9953 - val_loss: 0.9513 - val_accuracy: 0.8474\n",
      "Epoch 350/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1609 - accuracy: 0.9976 - val_loss: 0.9141 - val_accuracy: 0.8529\n",
      "Epoch 351/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1806 - accuracy: 0.9938 - val_loss: 0.9885 - val_accuracy: 0.8501\n",
      "Epoch 352/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1765 - accuracy: 0.9929 - val_loss: 1.1165 - val_accuracy: 0.8501\n",
      "Epoch 353/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2070 - accuracy: 0.9909 - val_loss: 1.1111 - val_accuracy: 0.8474\n",
      "Epoch 354/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1723 - accuracy: 0.9972 - val_loss: 1.0451 - val_accuracy: 0.8610\n",
      "Epoch 355/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1599 - accuracy: 0.9949 - val_loss: 0.9244 - val_accuracy: 0.8569\n",
      "Epoch 356/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1549 - accuracy: 0.9974 - val_loss: 0.9602 - val_accuracy: 0.8610\n",
      "Epoch 357/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1527 - accuracy: 0.9980 - val_loss: 0.9628 - val_accuracy: 0.8515\n",
      "Epoch 358/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1574 - accuracy: 0.9971 - val_loss: 0.9876 - val_accuracy: 0.8488\n",
      "Epoch 359/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2018 - accuracy: 0.9982 - val_loss: 1.1158 - val_accuracy: 0.8597\n",
      "Epoch 360/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1803 - accuracy: 0.9978 - val_loss: 0.9342 - val_accuracy: 0.8556\n",
      "Epoch 361/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2336 - accuracy: 0.9949 - val_loss: 1.0508 - val_accuracy: 0.8542\n",
      "Epoch 362/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1828 - accuracy: 0.9988 - val_loss: 0.9783 - val_accuracy: 0.8610\n",
      "Epoch 363/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1773 - accuracy: 0.9961 - val_loss: 1.0715 - val_accuracy: 0.8501\n",
      "Epoch 364/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1960 - accuracy: 0.9950 - val_loss: 1.0541 - val_accuracy: 0.8515\n",
      "Epoch 365/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1967 - accuracy: 0.9949 - val_loss: 1.0053 - val_accuracy: 0.8420\n",
      "Epoch 366/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2347 - accuracy: 0.9934 - val_loss: 1.2000 - val_accuracy: 0.8488\n",
      "Epoch 367/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2019 - accuracy: 0.9989 - val_loss: 1.0252 - val_accuracy: 0.8597\n",
      "Epoch 368/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1742 - accuracy: 0.9991 - val_loss: 0.9386 - val_accuracy: 0.8556\n",
      "Epoch 369/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2001 - accuracy: 0.9968 - val_loss: 0.9729 - val_accuracy: 0.8556\n",
      "Epoch 370/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2024 - accuracy: 0.9935 - val_loss: 1.0860 - val_accuracy: 0.8624\n",
      "Epoch 371/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2009 - accuracy: 0.9954 - val_loss: 1.0640 - val_accuracy: 0.8542\n",
      "Epoch 372/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1711 - accuracy: 0.9969 - val_loss: 1.0047 - val_accuracy: 0.8597\n",
      "Epoch 373/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1819 - accuracy: 0.9950 - val_loss: 0.9910 - val_accuracy: 0.8529\n",
      "Epoch 374/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1530 - accuracy: 0.9989 - val_loss: 1.0246 - val_accuracy: 0.8488\n",
      "Epoch 375/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1910 - accuracy: 0.9965 - val_loss: 1.0801 - val_accuracy: 0.8556\n",
      "Epoch 376/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1631 - accuracy: 0.9977 - val_loss: 0.9660 - val_accuracy: 0.8488\n",
      "Epoch 377/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1733 - accuracy: 0.9967 - val_loss: 1.0571 - val_accuracy: 0.8460\n",
      "Epoch 378/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1744 - accuracy: 0.9976 - val_loss: 1.0304 - val_accuracy: 0.8529\n",
      "Epoch 379/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1657 - accuracy: 0.9979 - val_loss: 0.9269 - val_accuracy: 0.8556\n",
      "Epoch 380/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1613 - accuracy: 0.9964 - val_loss: 0.9627 - val_accuracy: 0.8569\n",
      "Epoch 381/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1577 - accuracy: 0.9980 - val_loss: 1.0448 - val_accuracy: 0.8542\n",
      "Epoch 382/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1675 - accuracy: 0.9971 - val_loss: 1.1149 - val_accuracy: 0.8515\n",
      "Epoch 383/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2519 - accuracy: 0.9884 - val_loss: 1.4723 - val_accuracy: 0.8433\n",
      "Epoch 384/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.2238 - accuracy: 0.9970 - val_loss: 1.1493 - val_accuracy: 0.8433\n",
      "Epoch 385/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1953 - accuracy: 0.9939 - val_loss: 1.0446 - val_accuracy: 0.8474\n",
      "Epoch 386/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1768 - accuracy: 0.9961 - val_loss: 0.9995 - val_accuracy: 0.8569\n",
      "Epoch 387/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1810 - accuracy: 0.9921 - val_loss: 0.9314 - val_accuracy: 0.8542\n",
      "\n",
      "Epoch 00387: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 388/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1487 - accuracy: 0.9936 - val_loss: 0.8820 - val_accuracy: 0.8529\n",
      "Epoch 389/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1043 - accuracy: 0.9953 - val_loss: 0.8691 - val_accuracy: 0.8501\n",
      "Epoch 390/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0950 - accuracy: 0.9986 - val_loss: 0.8857 - val_accuracy: 0.8556\n",
      "Epoch 391/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0912 - accuracy: 0.9973 - val_loss: 0.8825 - val_accuracy: 0.8529\n",
      "Epoch 392/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0899 - accuracy: 0.9982 - val_loss: 0.9282 - val_accuracy: 0.8529\n",
      "Epoch 393/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0900 - accuracy: 0.9973 - val_loss: 0.9494 - val_accuracy: 0.8556\n",
      "Epoch 394/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0994 - accuracy: 0.9976 - val_loss: 0.9758 - val_accuracy: 0.8542\n",
      "Epoch 395/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0844 - accuracy: 0.9987 - val_loss: 0.9066 - val_accuracy: 0.8515\n",
      "Epoch 396/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0905 - accuracy: 0.9963 - val_loss: 0.9032 - val_accuracy: 0.8474\n",
      "Epoch 397/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1094 - accuracy: 0.9945 - val_loss: 0.9897 - val_accuracy: 0.8501\n",
      "Epoch 398/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1006 - accuracy: 0.9975 - val_loss: 0.9318 - val_accuracy: 0.8515\n",
      "Epoch 399/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0934 - accuracy: 0.9943 - val_loss: 0.9402 - val_accuracy: 0.8515\n",
      "Epoch 400/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0934 - accuracy: 0.9980 - val_loss: 0.9887 - val_accuracy: 0.8542\n",
      "Epoch 401/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0930 - accuracy: 0.9982 - val_loss: 0.9447 - val_accuracy: 0.8556\n",
      "Epoch 402/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1034 - accuracy: 0.9960 - val_loss: 0.9231 - val_accuracy: 0.8488\n",
      "Epoch 403/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0823 - accuracy: 0.9983 - val_loss: 0.8966 - val_accuracy: 0.8529\n",
      "Epoch 404/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0865 - accuracy: 0.9978 - val_loss: 0.9903 - val_accuracy: 0.8556\n",
      "Epoch 405/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1111 - accuracy: 0.9953 - val_loss: 1.0798 - val_accuracy: 0.8583\n",
      "Epoch 406/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0922 - accuracy: 0.9983 - val_loss: 0.9714 - val_accuracy: 0.8597\n",
      "Epoch 407/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1095 - accuracy: 0.9973 - val_loss: 0.9948 - val_accuracy: 0.8542\n",
      "Epoch 408/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1040 - accuracy: 0.9957 - val_loss: 0.9242 - val_accuracy: 0.8488\n",
      "Epoch 409/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0940 - accuracy: 0.9982 - val_loss: 0.8907 - val_accuracy: 0.8542\n",
      "Epoch 410/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0907 - accuracy: 0.9970 - val_loss: 0.9608 - val_accuracy: 0.8488\n",
      "Epoch 411/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0859 - accuracy: 0.9978 - val_loss: 0.9597 - val_accuracy: 0.8569\n",
      "Epoch 412/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0950 - accuracy: 0.9964 - val_loss: 1.0291 - val_accuracy: 0.8529\n",
      "Epoch 413/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0977 - accuracy: 0.9976 - val_loss: 0.9587 - val_accuracy: 0.8556\n",
      "Epoch 414/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0877 - accuracy: 0.9974 - val_loss: 0.8879 - val_accuracy: 0.8460\n",
      "Epoch 415/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1068 - accuracy: 0.9943 - val_loss: 0.9507 - val_accuracy: 0.8488\n",
      "Epoch 416/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0967 - accuracy: 0.9970 - val_loss: 0.9674 - val_accuracy: 0.8501\n",
      "Epoch 417/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0985 - accuracy: 0.9979 - val_loss: 0.9112 - val_accuracy: 0.8569\n",
      "Epoch 418/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0954 - accuracy: 0.9944 - val_loss: 0.9077 - val_accuracy: 0.8610\n",
      "Epoch 419/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0834 - accuracy: 0.9958 - val_loss: 0.9018 - val_accuracy: 0.8529\n",
      "Epoch 420/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0863 - accuracy: 0.9954 - val_loss: 0.9526 - val_accuracy: 0.8542\n",
      "Epoch 421/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0890 - accuracy: 0.9972 - val_loss: 1.0168 - val_accuracy: 0.8529\n",
      "Epoch 422/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0873 - accuracy: 0.9972 - val_loss: 1.0019 - val_accuracy: 0.8515\n",
      "Epoch 423/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0832 - accuracy: 0.9967 - val_loss: 0.9326 - val_accuracy: 0.8433\n",
      "Epoch 424/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0980 - accuracy: 0.9960 - val_loss: 0.9424 - val_accuracy: 0.8610\n",
      "Epoch 425/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0845 - accuracy: 0.9980 - val_loss: 0.9262 - val_accuracy: 0.8474\n",
      "Epoch 426/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0955 - accuracy: 0.9958 - val_loss: 0.9893 - val_accuracy: 0.8515\n",
      "Epoch 427/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0843 - accuracy: 0.9990 - val_loss: 0.9806 - val_accuracy: 0.8474\n",
      "Epoch 428/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0879 - accuracy: 0.9980 - val_loss: 0.9307 - val_accuracy: 0.8529\n",
      "Epoch 429/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0816 - accuracy: 0.9981 - val_loss: 0.9164 - val_accuracy: 0.8583\n",
      "Epoch 430/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0807 - accuracy: 0.9994 - val_loss: 0.9120 - val_accuracy: 0.8515\n",
      "Epoch 431/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0846 - accuracy: 0.9984 - val_loss: 0.9286 - val_accuracy: 0.8542\n",
      "Epoch 432/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0824 - accuracy: 0.9992 - val_loss: 0.8998 - val_accuracy: 0.8569\n",
      "Epoch 433/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0819 - accuracy: 0.9987 - val_loss: 0.9293 - val_accuracy: 0.8556\n",
      "Epoch 434/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0897 - accuracy: 0.9973 - val_loss: 1.0181 - val_accuracy: 0.8515\n",
      "Epoch 435/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0921 - accuracy: 0.9966 - val_loss: 1.1322 - val_accuracy: 0.8542\n",
      "Epoch 436/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0977 - accuracy: 0.9974 - val_loss: 1.0341 - val_accuracy: 0.8569\n",
      "Epoch 437/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0836 - accuracy: 0.9984 - val_loss: 0.9442 - val_accuracy: 0.8529\n",
      "Epoch 438/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0931 - accuracy: 0.9976 - val_loss: 0.9651 - val_accuracy: 0.8488\n",
      "Epoch 439/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0915 - accuracy: 0.9980 - val_loss: 0.9671 - val_accuracy: 0.8556\n",
      "Epoch 440/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1153 - accuracy: 0.9963 - val_loss: 1.1707 - val_accuracy: 0.8542\n",
      "Epoch 441/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0943 - accuracy: 0.9990 - val_loss: 0.9661 - val_accuracy: 0.8515\n",
      "Epoch 442/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0888 - accuracy: 0.9960 - val_loss: 0.9401 - val_accuracy: 0.8501\n",
      "Epoch 443/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0829 - accuracy: 0.9988 - val_loss: 0.9258 - val_accuracy: 0.8542\n",
      "Epoch 444/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0852 - accuracy: 0.9961 - val_loss: 0.8838 - val_accuracy: 0.8515\n",
      "Epoch 445/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0845 - accuracy: 0.9986 - val_loss: 0.9565 - val_accuracy: 0.8556\n",
      "Epoch 446/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0828 - accuracy: 0.9995 - val_loss: 0.9429 - val_accuracy: 0.8529\n",
      "Epoch 447/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0948 - accuracy: 0.9960 - val_loss: 0.9442 - val_accuracy: 0.8515\n",
      "Epoch 448/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0846 - accuracy: 0.9970 - val_loss: 0.9649 - val_accuracy: 0.8501\n",
      "Epoch 449/500\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.0831 - accuracy: 0.9989 - val_loss: 0.9003 - val_accuracy: 0.8488\n",
      "Epoch 450/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1018 - accuracy: 0.9989 - val_loss: 0.9715 - val_accuracy: 0.8542\n",
      "Epoch 451/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0997 - accuracy: 0.9971 - val_loss: 1.0132 - val_accuracy: 0.8529\n",
      "Epoch 452/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0893 - accuracy: 0.9959 - val_loss: 0.9681 - val_accuracy: 0.8515\n",
      "Epoch 453/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0965 - accuracy: 0.9945 - val_loss: 0.9905 - val_accuracy: 0.8529\n",
      "Epoch 454/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0925 - accuracy: 0.9987 - val_loss: 0.9665 - val_accuracy: 0.8515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0891 - accuracy: 0.9981 - val_loss: 0.9801 - val_accuracy: 0.8488\n",
      "Epoch 456/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0958 - accuracy: 0.9973 - val_loss: 0.9898 - val_accuracy: 0.8597\n",
      "Epoch 457/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0861 - accuracy: 0.9967 - val_loss: 0.9724 - val_accuracy: 0.8556\n",
      "Epoch 458/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0914 - accuracy: 0.9980 - val_loss: 0.9289 - val_accuracy: 0.8501\n",
      "Epoch 459/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0812 - accuracy: 0.9980 - val_loss: 0.9934 - val_accuracy: 0.8515\n",
      "Epoch 460/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1122 - accuracy: 0.9973 - val_loss: 1.0747 - val_accuracy: 0.8515\n",
      "Epoch 461/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1073 - accuracy: 0.9964 - val_loss: 0.9909 - val_accuracy: 0.8515\n",
      "Epoch 462/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0940 - accuracy: 0.9979 - val_loss: 0.9861 - val_accuracy: 0.8447\n",
      "Epoch 463/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1151 - accuracy: 0.9943 - val_loss: 0.9246 - val_accuracy: 0.8515\n",
      "Epoch 464/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0829 - accuracy: 0.9982 - val_loss: 0.9491 - val_accuracy: 0.8474\n",
      "Epoch 465/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0860 - accuracy: 0.9972 - val_loss: 0.9414 - val_accuracy: 0.8460\n",
      "Epoch 466/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0878 - accuracy: 0.9966 - val_loss: 0.8930 - val_accuracy: 0.8460\n",
      "Epoch 467/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0843 - accuracy: 0.9966 - val_loss: 0.9962 - val_accuracy: 0.8583\n",
      "Epoch 468/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0932 - accuracy: 0.9984 - val_loss: 1.0888 - val_accuracy: 0.8542\n",
      "Epoch 469/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1223 - accuracy: 0.9949 - val_loss: 1.0821 - val_accuracy: 0.8515\n",
      "Epoch 470/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1032 - accuracy: 0.9972 - val_loss: 1.0465 - val_accuracy: 0.8501\n",
      "Epoch 471/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0914 - accuracy: 0.9973 - val_loss: 1.0318 - val_accuracy: 0.8542\n",
      "Epoch 472/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0919 - accuracy: 0.9979 - val_loss: 0.9981 - val_accuracy: 0.8515\n",
      "Epoch 473/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0824 - accuracy: 0.9989 - val_loss: 0.9499 - val_accuracy: 0.8556\n",
      "Epoch 474/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0773 - accuracy: 0.9991 - val_loss: 0.9740 - val_accuracy: 0.8542\n",
      "Epoch 475/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0825 - accuracy: 0.9984 - val_loss: 1.1166 - val_accuracy: 0.8556\n",
      "Epoch 476/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.1070 - accuracy: 0.9984 - val_loss: 1.0264 - val_accuracy: 0.8515\n",
      "Epoch 477/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0947 - accuracy: 0.9985 - val_loss: 0.9645 - val_accuracy: 0.8569\n",
      "Epoch 478/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0989 - accuracy: 0.9958 - val_loss: 0.9749 - val_accuracy: 0.8515\n",
      "Epoch 479/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0798 - accuracy: 0.9991 - val_loss: 0.9290 - val_accuracy: 0.8542\n",
      "Epoch 480/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0962 - accuracy: 0.9965 - val_loss: 0.9889 - val_accuracy: 0.8542\n",
      "Epoch 481/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0927 - accuracy: 0.9970 - val_loss: 0.9379 - val_accuracy: 0.8488\n",
      "Epoch 482/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0857 - accuracy: 0.9979 - val_loss: 0.9392 - val_accuracy: 0.8488\n",
      "Epoch 483/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0856 - accuracy: 0.9960 - val_loss: 0.9265 - val_accuracy: 0.8447\n",
      "Epoch 484/500\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.0888 - accuracy: 0.9982 - val_loss: 0.9815 - val_accuracy: 0.8460\n",
      "Epoch 485/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0892 - accuracy: 0.9975 - val_loss: 0.9882 - val_accuracy: 0.8529\n",
      "Epoch 486/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0838 - accuracy: 0.9984 - val_loss: 0.9784 - val_accuracy: 0.8556\n",
      "Epoch 487/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0907 - accuracy: 0.9978 - val_loss: 1.0112 - val_accuracy: 0.8529\n",
      "\n",
      "Epoch 00487: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 488/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0676 - accuracy: 0.9983 - val_loss: 0.9723 - val_accuracy: 0.8515\n",
      "Epoch 489/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0488 - accuracy: 0.9988 - val_loss: 0.9494 - val_accuracy: 0.8501\n",
      "Epoch 490/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0492 - accuracy: 0.9971 - val_loss: 0.9220 - val_accuracy: 0.8542\n",
      "Epoch 491/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0486 - accuracy: 0.9977 - val_loss: 0.9397 - val_accuracy: 0.8488\n",
      "Epoch 492/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0450 - accuracy: 0.9987 - val_loss: 0.9468 - val_accuracy: 0.8488\n",
      "Epoch 493/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0641 - accuracy: 0.9962 - val_loss: 0.9399 - val_accuracy: 0.8583\n",
      "Epoch 494/500\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.0496 - accuracy: 0.9984 - val_loss: 0.9637 - val_accuracy: 0.8597\n",
      "Epoch 495/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0457 - accuracy: 0.9986 - val_loss: 0.9418 - val_accuracy: 0.8569\n",
      "Epoch 496/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0482 - accuracy: 0.9985 - val_loss: 0.9316 - val_accuracy: 0.8597\n",
      "Epoch 497/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0537 - accuracy: 0.9976 - val_loss: 0.9563 - val_accuracy: 0.8542\n",
      "Epoch 498/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0541 - accuracy: 0.9978 - val_loss: 0.9266 - val_accuracy: 0.8583\n",
      "Epoch 499/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0474 - accuracy: 0.9977 - val_loss: 0.9504 - val_accuracy: 0.8610\n",
      "Epoch 500/500\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.0645 - accuracy: 0.9963 - val_loss: 0.9955 - val_accuracy: 0.8583\n"
     ]
    }
   ],
   "source": [
    "train_dataset_mixed, valid_dataset_mixed, test_dataset_mixed = splitter.train_valid_test_split(\n",
    "    dataset=dataset_mixed,\n",
    "    frac_train=0.7,\n",
    "    frac_valid=0.15,\n",
    "    frac_test=0.15)\n",
    "\n",
    "model = train_dnn(train_dataset_mixed,valid_dataset_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9264d5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################\n",
      "Training Dataset: \n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "roc_auc_score: \n",
      " 0.9980455818691113\n",
      "precision_score: \n",
      " 0.9977099236641221\n",
      "accuracy_score: \n",
      " 0.9980537173997664\n",
      "confusion_matrix: \n",
      " [[1257    3]\n",
      " [   2 1307]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1260\n",
      "         1.0       1.00      1.00      1.00      1309\n",
      "\n",
      "    accuracy                           1.00      2569\n",
      "   macro avg       1.00      1.00      1.00      2569\n",
      "weighted avg       1.00      1.00      1.00      2569\n",
      "\n",
      "WARNING: task averager  cannot perform reduce with flexible type\n",
      "Validation Dataset: \n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "roc_auc_score: \n",
      " 0.8569073083778967\n",
      "precision_score: \n",
      " 0.8169014084507042\n",
      "accuracy_score: \n",
      " 0.8583106267029973\n",
      "confusion_matrix: \n",
      " [[282  78]\n",
      " [ 26 348]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.78      0.84       360\n",
      "         1.0       0.82      0.93      0.87       374\n",
      "\n",
      "    accuracy                           0.86       734\n",
      "   macro avg       0.87      0.86      0.86       734\n",
      "weighted avg       0.87      0.86      0.86       734\n",
      "\n",
      "WARNING: task averager  cannot perform reduce with flexible type\n",
      "Test Dataset: \n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "roc_auc_score: \n",
      " 0.8684343434343434\n",
      "precision_score: \n",
      " 0.845771144278607\n",
      "accuracy_score: \n",
      " 0.8692098092643051\n",
      "confusion_matrix: \n",
      " [[149  31]\n",
      " [ 17 170]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86       180\n",
      "         1.0       0.85      0.91      0.88       187\n",
      "\n",
      "    accuracy                           0.87       367\n",
      "   macro avg       0.87      0.87      0.87       367\n",
      "weighted avg       0.87      0.87      0.87       367\n",
      "\n",
      "WARNING: task averager  cannot perform reduce with flexible type\n"
     ]
    }
   ],
   "source": [
    "validate_model(model,train_dataset_mixed,valid_dataset_mixed,test_dataset_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f38c1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "def dense_builder(input_dim=None, task_type=None, hlayers_sizes='[10]', initializer='he_normal',\n",
    "                  l1=0, l2=0, hidden_dropout=0, batchnorm=True, learning_rate=0.001):\n",
    "    hlayers_sizes = literal_eval(hlayers_sizes)\n",
    "    # hlayers_sizes was passed as a str because Pipeline throws RuntimeError when cloning the model if parameters are lists\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_dim))\n",
    "\n",
    "    for i in range(len(hlayers_sizes)):\n",
    "        model.add(Dense(units=hlayers_sizes[i], kernel_initializer=initializer,\n",
    "                        kernel_regularizer=l1_l2(l1=l1, l2=l2)))\n",
    "        if batchnorm:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        if hidden_dropout > 0:\n",
    "            model.add(Dropout(rate=hidden_dropout))\n",
    "\n",
    "    # Add output layer\n",
    "    if task_type == 'regression':\n",
    "        model.add(Dense(1, activation='linear', kernel_initializer=initializer))\n",
    "    elif task_type == 'classification':\n",
    "        model.add(Dense(1, activation='sigmoid', kernel_initializer=initializer))\n",
    "\n",
    "    # Define optimizer\n",
    "    opt = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile model\n",
    "    if task_type == 'regression':\n",
    "        model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    else:\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\n",
    "    return model\n",
    "\n",
    "def run_dnn(dataset):\n",
    "    \n",
    "    \n",
    "    model = KerasModel(dense_builder, task_type = \"classification\", input_dim = dataset.X.shape[1], \n",
    "                       epochs= 500, batch_size= 50, \n",
    "                       hlayers_sizes='[512, 256]',l2=1e-3,\n",
    "                       hidden_dropout=0.25,batchnorm=True,learning_rate=1e-4, verbose = 1)\n",
    "    \n",
    "    history = model.fit(dataset)\n",
    "    \n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90b002b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2414 molecules after 1 attempts.\n",
      "Featurizing datapoint 0\n",
      "Featurizing datapoint 1000\n",
      "Featurizing datapoint 2000\n",
      "Columns in indexes:  (array([], dtype=int64),)  were removed due to the presence of NAs!\n"
     ]
    }
   ],
   "source": [
    "from compoundFeaturization import mordredDescriptors\n",
    "from copy import copy\n",
    "from loaders.Loaders import SDFLoader\n",
    "from compoundFeaturization import rdkitFingerprints\n",
    "from compoundFeaturization.mixedDescriptors import MixedFeaturizer\n",
    "from compoundFeaturization.rdkit3DDescriptors import All3DDescriptors\n",
    "\n",
    "loader = SDFLoader(\"./data/train_1-balance.sdf\", labels_fields='_y')\n",
    "dataset = loader.create_dataset()\n",
    "\n",
    "\n",
    "#dataset = MixedFeaturizer([All3DDescriptors(),rdkitFingerprints.LayeredFingerprint(1024)]).featurize(copy(dataset),scale=True)\n",
    "rdkit_3d_dataset = All3DDescriptors().featurize(copy(dataset),scale=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ec204d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/500\n",
      "49/49 [==============================] - 2s 10ms/step - loss: 2.0971\n",
      "Epoch 2/500\n",
      "49/49 [==============================] - 0s 10ms/step - loss: 1.8398\n",
      "Epoch 3/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 1.6486\n",
      "Epoch 4/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 1.5013\n",
      "Epoch 5/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.3600\n",
      "Epoch 6/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 1.2438\n",
      "Epoch 7/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.1536\n",
      "Epoch 8/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 1.0831\n",
      "Epoch 9/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 1.0032\n",
      "Epoch 10/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.9392\n",
      "Epoch 11/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.8928\n",
      "Epoch 12/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.8465\n",
      "Epoch 13/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.7980\n",
      "Epoch 14/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.7931\n",
      "Epoch 15/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.7496\n",
      "Epoch 16/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.7127\n",
      "Epoch 17/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.6733\n",
      "Epoch 18/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.6777\n",
      "Epoch 19/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6410\n",
      "Epoch 20/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.6298\n",
      "Epoch 21/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.6261\n",
      "Epoch 22/500\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.6028\n",
      "Epoch 23/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.5740\n",
      "Epoch 24/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.5958\n",
      "Epoch 25/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.5662\n",
      "Epoch 26/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.5710\n",
      "Epoch 27/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.5559\n",
      "Epoch 28/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.5591\n",
      "Epoch 29/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.5391\n",
      "Epoch 30/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.5430\n",
      "Epoch 31/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.5513\n",
      "Epoch 32/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.5262\n",
      "Epoch 33/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.5277\n",
      "Epoch 34/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.5254\n",
      "Epoch 35/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.5008\n",
      "Epoch 36/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.5069\n",
      "Epoch 37/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.4878\n",
      "Epoch 38/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4921\n",
      "Epoch 39/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4822\n",
      "Epoch 40/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.4924\n",
      "Epoch 41/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.5093\n",
      "Epoch 42/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.4942\n",
      "Epoch 43/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.5124\n",
      "Epoch 44/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4689\n",
      "Epoch 45/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.4790\n",
      "Epoch 46/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.4447\n",
      "Epoch 47/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4398\n",
      "Epoch 48/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4788\n",
      "Epoch 49/500\n",
      "49/49 [==============================] - 0s 10ms/step - loss: 0.4902\n",
      "Epoch 50/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.4635\n",
      "Epoch 51/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.4524\n",
      "Epoch 52/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.4448\n",
      "Epoch 53/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4714\n",
      "Epoch 54/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4582\n",
      "Epoch 55/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.4664\n",
      "Epoch 56/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4495\n",
      "Epoch 57/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4430\n",
      "Epoch 58/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4269\n",
      "Epoch 59/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4532\n",
      "Epoch 60/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4577\n",
      "Epoch 61/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.4367\n",
      "Epoch 62/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4143\n",
      "Epoch 63/500\n",
      "49/49 [==============================] - 0s 10ms/step - loss: 0.4141\n",
      "Epoch 64/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4081\n",
      "Epoch 65/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4462\n",
      "Epoch 66/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4489\n",
      "Epoch 67/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.4311\n",
      "Epoch 68/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4471\n",
      "Epoch 69/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4101\n",
      "Epoch 70/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4298\n",
      "Epoch 71/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4333\n",
      "Epoch 72/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4204\n",
      "Epoch 73/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4012\n",
      "Epoch 74/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.4317\n",
      "Epoch 75/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.4270\n",
      "Epoch 76/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.4094\n",
      "Epoch 77/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3966\n",
      "Epoch 78/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.3779\n",
      "Epoch 79/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4132\n",
      "Epoch 80/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3902\n",
      "Epoch 81/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.4018\n",
      "Epoch 82/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.4262\n",
      "Epoch 83/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.3949\n",
      "Epoch 84/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.4146\n",
      "Epoch 85/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4411\n",
      "Epoch 86/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.4071\n",
      "Epoch 87/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4545\n",
      "Epoch 88/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4097\n",
      "Epoch 89/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3873\n",
      "Epoch 90/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4123\n",
      "Epoch 91/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3996\n",
      "Epoch 92/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.3875\n",
      "Epoch 93/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.4079\n",
      "Epoch 94/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4038\n",
      "Epoch 95/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3933\n",
      "Epoch 96/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3891\n",
      "Epoch 97/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3973\n",
      "Epoch 98/500\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.3898\n",
      "Epoch 99/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4280\n",
      "Epoch 100/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3812\n",
      "Epoch 101/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4110\n",
      "Epoch 102/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3940\n",
      "Epoch 103/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3678\n",
      "Epoch 104/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.3731\n",
      "Epoch 105/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3886\n",
      "Epoch 106/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.4010\n",
      "Epoch 107/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.4024\n",
      "Epoch 108/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3791\n",
      "Epoch 109/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3837\n",
      "Epoch 110/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3749\n",
      "Epoch 111/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3698\n",
      "Epoch 112/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3953\n",
      "Epoch 113/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.3930\n",
      "Epoch 114/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3938\n",
      "Epoch 115/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3802\n",
      "Epoch 116/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3647\n",
      "Epoch 117/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3667\n",
      "Epoch 118/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3731\n",
      "Epoch 119/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3544\n",
      "Epoch 120/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3955\n",
      "Epoch 121/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3527\n",
      "Epoch 122/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3708\n",
      "Epoch 123/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3885\n",
      "Epoch 124/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3542\n",
      "Epoch 125/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3684\n",
      "Epoch 126/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.3525\n",
      "Epoch 127/500\n",
      "49/49 [==============================] - 0s 10ms/step - loss: 0.3650\n",
      "Epoch 128/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.3563\n",
      "Epoch 129/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3697\n",
      "Epoch 130/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3786\n",
      "Epoch 131/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3735\n",
      "Epoch 132/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.3769\n",
      "Epoch 133/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3776\n",
      "Epoch 134/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3612\n",
      "Epoch 135/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3580\n",
      "Epoch 136/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3505\n",
      "Epoch 137/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3593\n",
      "Epoch 138/500\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.3752\n",
      "Epoch 139/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3791\n",
      "Epoch 140/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3666\n",
      "Epoch 141/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3645\n",
      "Epoch 142/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3531\n",
      "Epoch 143/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3513\n",
      "Epoch 144/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3560\n",
      "Epoch 145/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3245\n",
      "Epoch 146/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3576\n",
      "Epoch 147/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3665\n",
      "Epoch 148/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3475\n",
      "Epoch 149/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3481\n",
      "Epoch 150/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3361\n",
      "Epoch 151/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3496\n",
      "Epoch 152/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3430\n",
      "Epoch 153/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3455\n",
      "Epoch 154/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3319\n",
      "Epoch 155/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3613\n",
      "Epoch 156/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3620\n",
      "Epoch 157/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3364\n",
      "Epoch 158/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3382\n",
      "Epoch 159/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3460\n",
      "Epoch 160/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3744\n",
      "Epoch 161/500\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.3357\n",
      "Epoch 162/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3430\n",
      "Epoch 163/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3438\n",
      "Epoch 164/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3499\n",
      "Epoch 165/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3674\n",
      "Epoch 166/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.3662\n",
      "Epoch 167/500\n",
      "49/49 [==============================] - 0s 8ms/step - loss: 0.3347\n",
      "Epoch 168/500\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.3265\n",
      "Epoch 169/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3185\n",
      "Epoch 170/500\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.3242\n",
      "Epoch 171/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3627\n",
      "Epoch 172/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3309\n",
      "Epoch 173/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3134\n",
      "Epoch 174/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3188\n",
      "Epoch 175/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3488\n",
      "Epoch 176/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3651\n",
      "Epoch 177/500\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.3440\n",
      "Epoch 178/500\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.3428\n",
      "Epoch 179/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3638\n",
      "Epoch 180/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3361\n",
      "Epoch 181/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3073\n",
      "Epoch 182/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3034\n",
      "Epoch 183/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3343\n",
      "Epoch 184/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3597\n",
      "Epoch 185/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3249\n",
      "Epoch 186/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3298\n",
      "Epoch 187/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3371\n",
      "Epoch 188/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3119\n",
      "Epoch 189/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3328\n",
      "Epoch 190/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3093\n",
      "Epoch 191/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3622\n",
      "Epoch 192/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3213\n",
      "Epoch 193/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3569\n",
      "Epoch 194/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3362\n",
      "Epoch 195/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3374\n",
      "Epoch 196/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3233\n",
      "Epoch 197/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3386\n",
      "Epoch 198/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3497\n",
      "Epoch 199/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3086\n",
      "Epoch 200/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3126\n",
      "Epoch 201/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3319\n",
      "Epoch 202/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3167\n",
      "Epoch 203/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3475\n",
      "Epoch 204/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3597\n",
      "Epoch 205/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3427\n",
      "Epoch 206/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3128\n",
      "Epoch 207/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3134\n",
      "Epoch 208/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3158\n",
      "Epoch 209/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3196\n",
      "Epoch 210/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3172\n",
      "Epoch 211/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3137\n",
      "Epoch 212/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3418\n",
      "Epoch 213/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3405\n",
      "Epoch 214/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3076\n",
      "Epoch 215/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3142\n",
      "Epoch 216/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3164\n",
      "Epoch 217/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3150\n",
      "Epoch 218/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3483\n",
      "Epoch 219/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3074\n",
      "Epoch 220/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3307\n",
      "Epoch 221/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3461\n",
      "Epoch 222/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3212\n",
      "Epoch 223/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3104\n",
      "Epoch 224/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3342\n",
      "Epoch 225/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3551\n",
      "Epoch 226/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3173\n",
      "Epoch 227/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2883\n",
      "Epoch 228/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2902\n",
      "Epoch 229/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2842\n",
      "Epoch 230/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2913\n",
      "Epoch 231/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3081\n",
      "Epoch 232/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3180\n",
      "Epoch 233/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3220\n",
      "Epoch 234/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3106\n",
      "Epoch 235/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3051\n",
      "Epoch 236/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3358\n",
      "Epoch 237/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3102\n",
      "Epoch 238/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2831\n",
      "Epoch 239/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3001\n",
      "Epoch 240/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3083\n",
      "Epoch 241/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2943\n",
      "Epoch 242/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3083\n",
      "Epoch 243/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2908\n",
      "Epoch 244/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3112\n",
      "Epoch 245/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3354\n",
      "Epoch 246/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3296\n",
      "Epoch 247/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3415\n",
      "Epoch 248/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3441\n",
      "Epoch 249/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3192\n",
      "Epoch 250/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2925\n",
      "Epoch 251/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3100\n",
      "Epoch 252/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3289\n",
      "Epoch 253/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3160\n",
      "Epoch 254/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3105\n",
      "Epoch 255/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3205\n",
      "Epoch 256/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3030\n",
      "Epoch 257/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3193\n",
      "Epoch 258/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2964\n",
      "Epoch 259/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3107\n",
      "Epoch 260/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3224\n",
      "Epoch 261/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3136\n",
      "Epoch 262/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3164\n",
      "Epoch 263/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2827\n",
      "Epoch 264/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3043\n",
      "Epoch 265/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3015\n",
      "Epoch 266/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2959\n",
      "Epoch 267/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2812\n",
      "Epoch 268/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2890\n",
      "Epoch 269/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2766\n",
      "Epoch 270/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2838\n",
      "Epoch 271/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2870\n",
      "Epoch 272/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3573\n",
      "Epoch 273/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3298\n",
      "Epoch 274/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3246\n",
      "Epoch 275/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2943\n",
      "Epoch 276/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2994\n",
      "Epoch 277/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2945\n",
      "Epoch 278/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3041\n",
      "Epoch 279/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2766\n",
      "Epoch 280/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2657\n",
      "Epoch 281/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2924\n",
      "Epoch 282/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2911\n",
      "Epoch 283/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3263\n",
      "Epoch 284/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3124\n",
      "Epoch 285/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3275\n",
      "Epoch 286/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3072\n",
      "Epoch 287/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2879\n",
      "Epoch 288/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2966\n",
      "Epoch 289/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2942\n",
      "Epoch 290/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3105\n",
      "Epoch 291/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3120\n",
      "Epoch 292/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2914\n",
      "Epoch 293/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3016\n",
      "Epoch 294/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2965\n",
      "Epoch 295/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3298\n",
      "Epoch 296/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3105\n",
      "Epoch 297/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3191\n",
      "Epoch 298/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3130\n",
      "Epoch 299/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3201\n",
      "Epoch 300/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3038\n",
      "Epoch 301/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2991\n",
      "Epoch 302/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2912\n",
      "Epoch 303/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3092\n",
      "Epoch 304/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2898\n",
      "Epoch 305/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2694\n",
      "Epoch 306/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2805\n",
      "Epoch 307/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3112\n",
      "Epoch 308/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2769\n",
      "Epoch 309/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3074\n",
      "Epoch 310/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3180\n",
      "Epoch 311/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2952\n",
      "Epoch 312/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3070\n",
      "Epoch 313/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2856\n",
      "Epoch 314/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2939\n",
      "Epoch 315/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3434\n",
      "Epoch 316/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3057\n",
      "Epoch 317/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2948\n",
      "Epoch 318/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3403\n",
      "Epoch 319/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2803\n",
      "Epoch 320/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2729\n",
      "Epoch 321/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2804\n",
      "Epoch 322/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2873\n",
      "Epoch 323/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2917\n",
      "Epoch 324/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3013\n",
      "Epoch 325/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2999\n",
      "Epoch 326/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3284\n",
      "Epoch 327/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3371\n",
      "Epoch 328/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3145\n",
      "Epoch 329/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2919\n",
      "Epoch 330/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3146\n",
      "Epoch 331/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2873\n",
      "Epoch 332/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3109\n",
      "Epoch 333/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3206\n",
      "Epoch 334/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2824\n",
      "Epoch 335/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3097\n",
      "Epoch 336/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3145\n",
      "Epoch 337/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3204\n",
      "Epoch 338/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3058\n",
      "Epoch 339/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2804\n",
      "Epoch 340/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3197\n",
      "Epoch 341/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3025\n",
      "Epoch 342/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2774\n",
      "Epoch 343/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3055\n",
      "Epoch 344/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3003\n",
      "Epoch 345/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2948\n",
      "Epoch 346/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3039\n",
      "Epoch 347/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3025\n",
      "Epoch 348/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2918\n",
      "Epoch 349/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2693\n",
      "Epoch 350/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3170\n",
      "Epoch 351/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2862\n",
      "Epoch 352/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2761\n",
      "Epoch 353/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2879\n",
      "Epoch 354/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3120\n",
      "Epoch 355/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3014\n",
      "Epoch 356/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2801\n",
      "Epoch 357/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2855\n",
      "Epoch 358/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2967\n",
      "Epoch 359/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2980\n",
      "Epoch 360/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3174\n",
      "Epoch 361/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2996\n",
      "Epoch 362/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3168\n",
      "Epoch 363/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2819\n",
      "Epoch 364/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2777\n",
      "Epoch 365/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2995\n",
      "Epoch 366/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3068\n",
      "Epoch 367/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2674\n",
      "Epoch 368/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3039\n",
      "Epoch 369/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2689\n",
      "Epoch 370/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2838\n",
      "Epoch 371/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2900\n",
      "Epoch 372/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3057\n",
      "Epoch 373/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2983\n",
      "Epoch 374/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2835\n",
      "Epoch 375/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2613\n",
      "Epoch 376/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2843\n",
      "Epoch 377/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2730\n",
      "Epoch 378/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2872\n",
      "Epoch 379/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2823\n",
      "Epoch 380/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2692\n",
      "Epoch 381/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2487\n",
      "Epoch 382/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2661\n",
      "Epoch 383/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2645\n",
      "Epoch 384/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2583\n",
      "Epoch 385/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2967\n",
      "Epoch 386/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3381\n",
      "Epoch 387/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3048\n",
      "Epoch 388/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3081\n",
      "Epoch 389/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3047\n",
      "Epoch 390/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2844\n",
      "Epoch 391/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2989\n",
      "Epoch 392/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3028\n",
      "Epoch 393/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2679\n",
      "Epoch 394/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2942\n",
      "Epoch 395/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2936\n",
      "Epoch 396/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2749\n",
      "Epoch 397/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2877\n",
      "Epoch 398/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2826\n",
      "Epoch 399/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2918\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3216\n",
      "Epoch 401/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2772\n",
      "Epoch 402/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2957\n",
      "Epoch 403/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3111\n",
      "Epoch 404/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2998\n",
      "Epoch 405/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2673\n",
      "Epoch 406/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2525\n",
      "Epoch 407/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2798\n",
      "Epoch 408/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3143\n",
      "Epoch 409/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3045\n",
      "Epoch 410/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2820\n",
      "Epoch 411/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2826\n",
      "Epoch 412/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2711\n",
      "Epoch 413/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2836\n",
      "Epoch 414/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2684\n",
      "Epoch 415/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2908\n",
      "Epoch 416/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2680\n",
      "Epoch 417/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2527\n",
      "Epoch 418/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2691\n",
      "Epoch 419/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2617\n",
      "Epoch 420/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2746\n",
      "Epoch 421/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2869\n",
      "Epoch 422/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2899\n",
      "Epoch 423/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3104\n",
      "Epoch 424/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2962\n",
      "Epoch 425/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3058\n",
      "Epoch 426/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2966\n",
      "Epoch 427/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2792\n",
      "Epoch 428/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2888\n",
      "Epoch 429/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3038\n",
      "Epoch 430/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3201\n",
      "Epoch 431/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2913\n",
      "Epoch 432/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2890\n",
      "Epoch 433/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2929\n",
      "Epoch 434/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3124\n",
      "Epoch 435/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2804\n",
      "Epoch 436/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2931\n",
      "Epoch 437/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3225\n",
      "Epoch 438/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2986\n",
      "Epoch 439/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2924\n",
      "Epoch 440/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2902\n",
      "Epoch 441/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3059\n",
      "Epoch 442/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2868\n",
      "Epoch 443/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2903\n",
      "Epoch 444/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2566\n",
      "Epoch 445/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2730\n",
      "Epoch 446/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2828\n",
      "Epoch 447/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2777\n",
      "Epoch 448/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2851\n",
      "Epoch 449/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3277\n",
      "Epoch 450/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2669\n",
      "Epoch 451/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2736\n",
      "Epoch 452/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2820\n",
      "Epoch 453/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3067\n",
      "Epoch 454/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3043\n",
      "Epoch 455/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2975\n",
      "Epoch 456/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2966\n",
      "Epoch 457/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2771\n",
      "Epoch 458/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2756\n",
      "Epoch 459/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2603\n",
      "Epoch 460/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2970\n",
      "Epoch 461/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3171\n",
      "Epoch 462/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2949\n",
      "Epoch 463/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3085\n",
      "Epoch 464/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3145\n",
      "Epoch 465/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3022\n",
      "Epoch 466/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3101\n",
      "Epoch 467/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2949\n",
      "Epoch 468/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2590\n",
      "Epoch 469/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2742\n",
      "Epoch 470/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2868\n",
      "Epoch 471/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2685\n",
      "Epoch 472/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2863\n",
      "Epoch 473/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2947\n",
      "Epoch 474/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2974\n",
      "Epoch 475/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2911\n",
      "Epoch 476/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2598\n",
      "Epoch 477/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2801\n",
      "Epoch 478/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2848\n",
      "Epoch 479/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2975\n",
      "Epoch 480/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2965\n",
      "Epoch 481/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2905\n",
      "Epoch 482/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2930\n",
      "Epoch 483/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3063\n",
      "Epoch 484/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3067\n",
      "Epoch 485/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2698\n",
      "Epoch 486/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2927\n",
      "Epoch 487/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2827\n",
      "Epoch 488/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2862\n",
      "Epoch 489/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2857\n",
      "Epoch 490/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2811\n",
      "Epoch 491/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2845\n",
      "Epoch 492/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2716\n",
      "Epoch 493/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3070\n",
      "Epoch 494/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2976\n",
      "Epoch 495/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3018\n",
      "Epoch 496/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3074\n",
      "Epoch 497/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2875\n",
      "Epoch 498/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2990\n",
      "Epoch 499/500\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2684\n",
      "Epoch 500/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2555\n"
     ]
    }
   ],
   "source": [
    "from models.kerasModels import KerasModel\n",
    "\n",
    "model = run_dnn(rdkit_3d_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7daef992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [15:16:33] Warning: molecule is tagged as 3D, but all Z coords are zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1033 molecules after 1 attempts.\n",
      "Featurizing datapoint 0\n",
      "Featurizing datapoint 1000\n",
      "Columns in indexes:  (array([], dtype=int64),)  were removed due to the presence of NAs!\n"
     ]
    }
   ],
   "source": [
    "loader = SDFLoader(\"./data/test_1-balance.sdf\", labels_fields='_y')\n",
    "test_dataset = loader.create_dataset()\n",
    "\n",
    "\n",
    "#test_dataset = MixedFeaturizer([All3DDescriptors(),rdkitFingerprints.LayeredFingerprint(1024)]).featurize(copy(test_dataset),scale=True)\n",
    "\n",
    "rdkit_3d_test_dataset = All3DDescriptors().featurize(copy(test_dataset),scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07b61498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################\n",
      "Training Dataset: \n",
      "49/49 [==============================] - 0s 1ms/step\n",
      "roc_auc_score: \n",
      " 0.9913370687760931\n",
      "precision_score: \n",
      " 0.9890664423885618\n",
      "accuracy_score: \n",
      " 0.9913007456503728\n",
      "confusion_matrix: \n",
      " [[1217   13]\n",
      " [   8 1176]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      1230\n",
      "         1.0       0.99      0.99      0.99      1184\n",
      "\n",
      "    accuracy                           0.99      2414\n",
      "   macro avg       0.99      0.99      0.99      2414\n",
      "weighted avg       0.99      0.99      0.99      2414\n",
      "\n",
      "WARNING: task averager  cannot perform reduce with flexible type\n",
      "Validation Dataset: \n",
      "21/21 [==============================] - 0s 1ms/step\n",
      "roc_auc_score: \n",
      " 0.7848767445871861\n",
      "precision_score: \n",
      " 0.7855711422845691\n",
      "accuracy_score: \n",
      " 0.7850919651500484\n",
      "confusion_matrix: \n",
      " [[419 107]\n",
      " [115 392]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.80      0.79       526\n",
      "         1.0       0.79      0.77      0.78       507\n",
      "\n",
      "    accuracy                           0.79      1033\n",
      "   macro avg       0.79      0.78      0.78      1033\n",
      "weighted avg       0.79      0.79      0.79      1033\n",
      "\n",
      "WARNING: task averager  cannot perform reduce with flexible type\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, precision_score, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "metrics = [Metric(roc_auc_score), Metric(precision_score),\n",
    "           Metric(accuracy_score), Metric(confusion_matrix),\n",
    "           Metric(classification_report)]\n",
    "\n",
    "print(\"#############################\")\n",
    "# evaluate the model\n",
    "print('Training Dataset: ')\n",
    "train_score = model.evaluate(rdkit_3d_dataset, metrics)\n",
    "\n",
    "print('Validation Dataset: ')\n",
    "valid_score = model.evaluate(rdkit_3d_test_dataset, metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
