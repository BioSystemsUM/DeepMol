{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "from loaders.Loaders import CSVLoader\n",
    "from compoundFeaturization.rdkitFingerprints import MorganFingerprint\n",
    "from featureSelection.baseFeatureSelector import LowVarianceFS\n",
    "from splitters.splitters import SingletaskStratifiedSplitter\n",
    "from models.kerasModels import KerasModel\n",
    "from metrics.Metrics import Metric\n",
    "from metrics.metricsFunctions import f1_score, roc_auc_score, precision_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)\n",
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mols_shape:  23290\n",
      "Features_shape:  X not defined!\n",
      "Labels_shape:  (23290,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Load Dataset\n",
    "dataset = CSVLoader(dataset_path='preprocessed_dataset_wfoodb.csv', \n",
    "                    mols_field='Smiles', \n",
    "                    labels_fields='Class', \n",
    "                    id_field='ID')#, shard_size=4000)\n",
    "dataset = dataset.create_dataset()\n",
    "print(dataset.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizing datapoint 0\n",
      "Featurizing datapoint 1000\n",
      "Featurizing datapoint 2000\n",
      "Featurizing datapoint 3000\n",
      "Featurizing datapoint 4000\n",
      "Featurizing datapoint 5000\n",
      "Featurizing datapoint 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [09:35:18] Explicit valence for atom # 1 Cl, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in smile: O=[Cl]=O\n",
      "Featurizing datapoint 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [09:35:22] Explicit valence for atom # 3 B, 4, is greater than permitted\n",
      "RDKit ERROR: [09:35:22] Explicit valence for atom # 1 Cl, 9, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in smile: OB1O[B]2(O)OB(O)O[B](O)(O1)O2\n",
      "error in smile: O=[Cl-](=O)(=O)=O\n",
      "Featurizing datapoint 8000\n",
      "Featurizing datapoint 9000\n",
      "Featurizing datapoint 10000\n",
      "Featurizing datapoint 11000\n",
      "Featurizing datapoint 12000\n",
      "Featurizing datapoint 13000\n",
      "Featurizing datapoint 14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [09:35:37] Explicit valence for atom # 0 P, 11, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in smile: [P](OCC=C(C)C)(OCC=C(C)C)(=O)(OP(OCC=C(C)C)(OCC=C(C)C)=O)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)CC=C(C)C\n",
      "Featurizing datapoint 15000\n",
      "Featurizing datapoint 16000\n",
      "Featurizing datapoint 17000\n",
      "Featurizing datapoint 18000\n",
      "Featurizing datapoint 19000\n",
      "Featurizing datapoint 20000\n",
      "Featurizing datapoint 21000\n",
      "Featurizing datapoint 22000\n",
      "Featurizing datapoint 23000\n",
      "Elements with indexes:  [6257, 7708, 7709, 14244]  were removed due to the presence of NAs!\n",
      "The elements in question are:  ['O=[Cl]=O' 'OB1O[B]2(O)OB(O)O[B](O)(O1)O2' 'O=[Cl-](=O)(=O)=O'\n",
      " '[P](OCC=C(C)C)(OCC=C(C)C)(=O)(OP(OCC=C(C)C)(OCC=C(C)C)=O)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)CC=C(C)C']\n",
      "Mols_shape:  23286\n",
      "Features_shape:  (23286, 1024)\n",
      "Labels_shape:  (23286,)\n"
     ]
    }
   ],
   "source": [
    "#Featurization\n",
    "dataset = MorganFingerprint().featurize(dataset)\n",
    "dataset.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mols_shape:  23286\n",
      "Features_shape:  (23286, 49)\n",
      "Labels_shape:  (23286,)\n"
     ]
    }
   ],
   "source": [
    "#Feature Selection\n",
    "dataset = LowVarianceFS(0.15).featureSelection(dataset)\n",
    "dataset.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Split\n",
    "splitter = SingletaskStratifiedSplitter()\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset=dataset, frac_train=0.6, \n",
    "                                                                             frac_valid=0.2, frac_test=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GaussianNoise, Conv1D, Flatten, Reshape\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam, RMSprop\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Hyperparameters for the network\n",
    "#DENSE = 128\n",
    "#DROPOUT = 0.5\n",
    "#C1_K  = 8 #Number of kernels/feature extractors for first layer\n",
    "#C1_S  = 32 #Width of the convolutional mini networks\n",
    "#C2_K  = 16\n",
    "#C2_S  = 32\n",
    "\n",
    "#activation='relu'\n",
    "\n",
    "input_dim = train_dataset.X.shape[1]\n",
    "\n",
    "def make_cnn_model(input_dim=input_dim,\n",
    "                   g_noise = 0.05, \n",
    "                   DENSE=128, \n",
    "                   DROPOUT=0.5, \n",
    "                   C1_K=8, \n",
    "                   C1_S=32, \n",
    "                   C2_K=16, \n",
    "                   C2_S=32,\n",
    "                   activation='relu',\n",
    "                   loss='binary_crossentropy',\n",
    "                   optimizer='adadelta', \n",
    "                   learning_rate=0.01, \n",
    "                   metrics='accuracy'):\n",
    "    model = Sequential()\n",
    "    #Adding a bit of GaussianNoise also works as regularization\n",
    "    model.add(GaussianNoise(g_noise, input_shape=(input_dim,)))\n",
    "    #First two is number of filter + kernel size\n",
    "    model.add(Reshape((input_dim, 1)))\n",
    "    model.add(Conv1D(C1_K, (C1_S), activation=activation, padding=\"same\"))\n",
    "    model.add(Conv1D(C2_K, (C2_S), padding=\"same\", activation=activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(DENSE, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    if optimizer=='adadelta':\n",
    "        opt = Adadelta(lr=learning_rate)\n",
    "    elif optimizer=='adam':\n",
    "        opt = Adam(lr=learning_rate)\n",
    "    elif optimizer=='rsmprop':\n",
    "        opt = RMSprop(lr=learning_rate)\n",
    "    else : \n",
    "        opt = optimizer\n",
    "\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models.kerasModels import KerasModel\n",
    "\n",
    "#input_dim = train_dataset.X.shape[1]\n",
    "#print(input_dim)\n",
    "#model = KerasModel(make_cnn_model, epochs = 150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(train_dataset.X.shape, train_dataset.y.shape)\n",
    "\n",
    "\n",
    "#model.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics = [Metric(roc_auc_score), \n",
    "#           Metric(precision_score), \n",
    "#           Metric(accuracy_score), \n",
    "#           Metric(confusion_matrix), \n",
    "#           Metric(classification_report)]\n",
    "\n",
    "#print('training set score:', model.evaluate(train_dataset, metrics))\n",
    "#print('test set score:', model.evaluate(test_dataset, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 random models from a space of 243 possible models.\n",
      "Fitting model 1/15\n",
      "hyperparameters: {'optimizer': 'adam', 'DROPOUT': 0.2, 'learning_rate': 0.01, 'activation': 'elu', 'g_noise': 0.01}\n",
      "<class 'sklearn.metrics._scorer._PredictScorer'>\n",
      "METRIC:  make_scorer(f1_score)\n",
      "Fitting 15 random models from a space of 243 possible models.\n",
      "(13968, 49) 4656.0\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.05, activation=selu, DROPOUT=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2081 - accuracy: 0.9369\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.05, activation=selu, DROPOUT=0.5, score=0.000, total=   3.8s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.05, activation=selu, DROPOUT=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2018 - accuracy: 0.9393\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.05, activation=selu, DROPOUT=0.5, score=0.213, total=   1.2s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.05, activation=selu, DROPOUT=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2111 - accuracy: 0.9344\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.05, activation=selu, DROPOUT=0.5, score=0.000, total=   1.2s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4299 - accuracy: 0.9345\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.4, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.9134\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.4, score=0.000, total=   1.0s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.9288\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.4, score=0.000, total=   1.1s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.01, g_noise=0.005, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1895 - accuracy: 0.9405\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.01, g_noise=0.005, activation=elu, DROPOUT=0.2, score=0.122, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.01, g_noise=0.005, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1839 - accuracy: 0.9425\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.01, g_noise=0.005, activation=elu, DROPOUT=0.2, score=0.146, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.01, g_noise=0.005, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1962 - accuracy: 0.9395\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.01, g_noise=0.005, activation=elu, DROPOUT=0.2, score=0.000, total=   1.3s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.01, activation=elu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5819\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.01, activation=elu, DROPOUT=0.4, score=0.018, total=   1.0s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.01, activation=elu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5647 - accuracy: 0.8397\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.01, activation=elu, DROPOUT=0.4, score=0.036, total=   1.1s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.01, activation=elu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.8155\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.01, activation=elu, DROPOUT=0.4, score=0.011, total=   1.0s\n",
      "[CV] optimizer=adam, learning_rate=0.0001, g_noise=0.005, activation=selu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2147 - accuracy: 0.9336\n",
      "[CV]  optimizer=adam, learning_rate=0.0001, g_noise=0.005, activation=selu, DROPOUT=0.5, score=0.051, total=   1.2s\n",
      "[CV] optimizer=adam, learning_rate=0.0001, g_noise=0.005, activation=selu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9367\n",
      "[CV]  optimizer=adam, learning_rate=0.0001, g_noise=0.005, activation=selu, DROPOUT=0.5, score=0.104, total=   1.2s\n",
      "[CV] optimizer=adam, learning_rate=0.0001, g_noise=0.005, activation=selu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9383\n",
      "[CV]  optimizer=adam, learning_rate=0.0001, g_noise=0.005, activation=selu, DROPOUT=0.5, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.01, g_noise=0.01, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.9349\n",
      "[CV]  optimizer=adam, learning_rate=0.01, g_noise=0.01, activation=elu, DROPOUT=0.2, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.01, g_noise=0.01, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2613 - accuracy: 0.9367\n",
      "[CV]  optimizer=adam, learning_rate=0.01, g_noise=0.01, activation=elu, DROPOUT=0.2, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.01, g_noise=0.01, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.2385 - accuracy: 0.9363\n",
      "[CV]  optimizer=adam, learning_rate=0.01, g_noise=0.01, activation=elu, DROPOUT=0.2, score=0.000, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.0001, g_noise=0.05, activation=relu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1899 - accuracy: 0.9434\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.0001, g_noise=0.05, activation=relu, DROPOUT=0.2, score=0.000, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.0001, g_noise=0.05, activation=relu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1816 - accuracy: 0.9448\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.0001, g_noise=0.05, activation=relu, DROPOUT=0.2, score=0.055, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.0001, g_noise=0.05, activation=relu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1941 - accuracy: 0.9420\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.0001, g_noise=0.05, activation=relu, DROPOUT=0.2, score=0.000, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.0001, g_noise=0.01, activation=elu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1926 - accuracy: 0.9423\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.0001, g_noise=0.01, activation=elu, DROPOUT=0.4, score=0.158, total=   1.6s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.0001, g_noise=0.01, activation=elu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.1882 - accuracy: 0.9415\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.0001, g_noise=0.01, activation=elu, DROPOUT=0.4, score=0.255, total=   1.4s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.0001, g_noise=0.01, activation=elu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1990 - accuracy: 0.9393\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.0001, g_noise=0.01, activation=elu, DROPOUT=0.4, score=0.000, total=   1.2s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.01, g_noise=0.01, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1898 - accuracy: 0.9419\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.01, g_noise=0.01, activation=relu, DROPOUT=0.4, score=0.022, total=   1.4s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.01, g_noise=0.01, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.9442\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.01, g_noise=0.01, activation=relu, DROPOUT=0.4, score=0.067, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.01, g_noise=0.01, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1960 - accuracy: 0.9419\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.01, g_noise=0.01, activation=relu, DROPOUT=0.4, score=0.000, total=   1.4s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.05, activation=selu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8368\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.05, activation=selu, DROPOUT=0.5, score=0.074, total=   1.0s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.05, activation=selu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7848\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.05, activation=selu, DROPOUT=0.5, score=0.024, total=   1.0s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.05, activation=selu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6582 - accuracy: 0.6208\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.05, activation=selu, DROPOUT=0.5, score=0.046, total=   1.2s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=relu, DROPOUT=0.4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4422 - accuracy: 0.8459\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=relu, DROPOUT=0.4, score=0.000, total=   1.2s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.3645 - accuracy: 0.9423: 0s - loss: 0.3951 - accuracy: \n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=relu, DROPOUT=0.4, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4026 - accuracy: 0.9017\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=relu, DROPOUT=0.4, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.7586 - accuracy: 0.1931\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5, score=0.089, total=   1.2s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.7022 - accuracy: 0.4093\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5, score=0.127, total=   1.3s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5687\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5, score=0.058, total=   1.3s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6268 - accuracy: 0.9336\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.2, score=0.000, total=   1.2s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.7097 - accuracy: 0.3793\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.2, score=0.128, total=   1.3s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.7681 - accuracy: 0.1956\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.2, score=0.161, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9409\n",
      "[CV]  optimizer=adam, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5, score=0.037, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9437\n",
      "[CV]  optimizer=adam, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5, score=0.027, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9419\n",
      "[CV]  optimizer=adam, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5, score=0.000, total=   1.0s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.01, g_noise=0.01, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1903 - accuracy: 0.9420\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.01, g_noise=0.01, activation=elu, DROPOUT=0.2, score=0.063, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.01, g_noise=0.01, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1849 - accuracy: 0.9419\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.01, g_noise=0.01, activation=elu, DROPOUT=0.2, score=0.061, total=   1.5s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.01, g_noise=0.01, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1956 - accuracy: 0.9413\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.01, g_noise=0.01, activation=elu, DROPOUT=0.2, score=0.159, total=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   56.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437/437 [==============================] - 1s 2ms/step - loss: 0.1908 - accuracy: 0.9420\n",
      "\n",
      " \n",
      " Best make_scorer(f1_score): 0.137518 using {'optimizer': 'rmsprop', 'learning_rate': 0.0001, 'g_noise': 0.01, 'activation': 'elu', 'DROPOUT': 0.4}\n",
      "\n",
      " make_scorer(f1_score): 0.071066 (0.100502) with: {'optimizer': 'rmsprop', 'learning_rate': 0.001, 'g_noise': 0.05, 'activation': 'selu', 'DROPOUT': 0.5} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.000000 (0.000000) with: {'optimizer': 'adadelta', 'learning_rate': 0.01, 'g_noise': 0.05, 'activation': 'relu', 'DROPOUT': 0.4} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.089273 (0.063918) with: {'optimizer': 'rmsprop', 'learning_rate': 0.01, 'g_noise': 0.005, 'activation': 'elu', 'DROPOUT': 0.2} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.022039 (0.010619) with: {'optimizer': 'adadelta', 'learning_rate': 0.001, 'g_noise': 0.01, 'activation': 'elu', 'DROPOUT': 0.4} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.051400 (0.042323) with: {'optimizer': 'adam', 'learning_rate': 0.0001, 'g_noise': 0.005, 'activation': 'selu', 'DROPOUT': 0.5} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.000000 (0.000000) with: {'optimizer': 'adam', 'learning_rate': 0.01, 'g_noise': 0.01, 'activation': 'elu', 'DROPOUT': 0.2} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.018203 (0.025742) with: {'optimizer': 'rmsprop', 'learning_rate': 0.0001, 'g_noise': 0.05, 'activation': 'relu', 'DROPOUT': 0.2} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.137518 (0.105009) with: {'optimizer': 'rmsprop', 'learning_rate': 0.0001, 'g_noise': 0.01, 'activation': 'elu', 'DROPOUT': 0.4} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.029713 (0.027694) with: {'optimizer': 'rmsprop', 'learning_rate': 0.01, 'g_noise': 0.01, 'activation': 'relu', 'DROPOUT': 0.4} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.048348 (0.020462) with: {'optimizer': 'adadelta', 'learning_rate': 0.001, 'g_noise': 0.05, 'activation': 'selu', 'DROPOUT': 0.5} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.000000 (0.000000) with: {'optimizer': 'adadelta', 'learning_rate': 0.01, 'g_noise': 0.005, 'activation': 'relu', 'DROPOUT': 0.4} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.091029 (0.028208) with: {'optimizer': 'adadelta', 'learning_rate': 0.001, 'g_noise': 0.005, 'activation': 'relu', 'DROPOUT': 0.5} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.096144 (0.069280) with: {'optimizer': 'adadelta', 'learning_rate': 0.001, 'g_noise': 0.005, 'activation': 'relu', 'DROPOUT': 0.2} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.021401 (0.015632) with: {'optimizer': 'adam', 'learning_rate': 0.001, 'g_noise': 0.005, 'activation': 'relu', 'DROPOUT': 0.5} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.094437 (0.045615) with: {'optimizer': 'rmsprop', 'learning_rate': 0.01, 'g_noise': 0.01, 'activation': 'elu', 'DROPOUT': 0.2} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from parameterOptimization.HyperparameterOpt import GridHyperparamOpt\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "\n",
    "#Hyperparameter Optimization\n",
    "optimizer = GridHyperparamOpt(make_cnn_model)\n",
    "\n",
    "params_dict = {'optimizer' : ['adam', 'rmsprop', 'adadelta'],\n",
    "              'DROPOUT' : [0.2, 0.4, 0.5],\n",
    "              'learning_rate' : [0.01, 0.001, 0.0001],\n",
    "              'activation' : ['relu', 'elu', 'selu'],\n",
    "              'g_noise' : [0.01, 0.05, 0.005]}\n",
    "\n",
    "#TODO: multiple scoring not working\n",
    "#scoring = {'f1': make_scorer(f1_score), 'Accuracy': 'accuracy'}\n",
    "scoring = make_scorer(f1_score)\n",
    "\n",
    "best_model, best_hyperparams, all_results = optimizer.hyperparam_search(params_dict, train_dataset,\n",
    "                                                                        valid_dataset, scoring,\n",
    "                                                                        cv=3, n_jobs=1, verbose=3)\n",
    "\n",
    "#print('#################')\n",
    "#print(best_hyperparams)\n",
    "#print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
