{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "expired-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greatest-gambling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "from Dataset.Dataset import CSVLoader\n",
    "from compoundFeaturization.rdkitFingerprints import MorganFingerprint\n",
    "from featureSelection.baseFeatureSelector import LowVarianceFS\n",
    "from splitters.splitters import SingletaskStratifiedSplitter\n",
    "from models.kerasModels import KerasModel\n",
    "from metrics.Metrics import Metric\n",
    "from metrics.metricsFunctions import f1_score, roc_auc_score, precision_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)\n",
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "separate-fetish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23290,) (23290,) (0,) (23290,)\n",
      "((23290,), (23290,), (0,), (23290,))\n"
     ]
    }
   ],
   "source": [
    "#Load Dataset\n",
    "dataset = CSVLoader('preprocessed_dataset_wfoodb.csv', 'Smiles', ['Class'], 'ID')#, chunk_size=4000)\n",
    "print(dataset.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sustainable-locator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizing datapoint 0\n",
      "Featurizing datapoint 1000\n",
      "Featurizing datapoint 2000\n",
      "Featurizing datapoint 3000\n",
      "Featurizing datapoint 4000\n",
      "Featurizing datapoint 5000\n",
      "Featurizing datapoint 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [18:10:50] Explicit valence for atom # 1 Cl, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in smile: O=[Cl]=O\n",
      "Featurizing datapoint 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [18:10:53] Explicit valence for atom # 3 B, 4, is greater than permitted\n",
      "RDKit ERROR: [18:10:53] Explicit valence for atom # 1 Cl, 9, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in smile: OB1O[B]2(O)OB(O)O[B](O)(O1)O2\n",
      "error in smile: O=[Cl-](=O)(=O)=O\n",
      "Featurizing datapoint 8000\n",
      "Featurizing datapoint 9000\n",
      "Featurizing datapoint 10000\n",
      "Featurizing datapoint 11000\n",
      "Featurizing datapoint 12000\n",
      "Featurizing datapoint 13000\n",
      "Featurizing datapoint 14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [18:11:09] Explicit valence for atom # 0 P, 11, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in smile: [P](OCC=C(C)C)(OCC=C(C)C)(=O)(OP(OCC=C(C)C)(OCC=C(C)C)=O)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)CC=C(C)C\n",
      "Featurizing datapoint 15000\n",
      "Featurizing datapoint 16000\n",
      "Featurizing datapoint 17000\n",
      "Featurizing datapoint 18000\n",
      "Featurizing datapoint 19000\n",
      "Featurizing datapoint 20000\n",
      "Featurizing datapoint 21000\n",
      "Featurizing datapoint 22000\n",
      "Featurizing datapoint 23000\n",
      "Elements with indexes:  [6257, 7708, 7709, 14244]  were removed due to the presence of NAs!\n",
      "The elements in question are:  ['O=[Cl]=O' 'OB1O[B]2(O)OB(O)O[B](O)(O1)O2' 'O=[Cl-](=O)(=O)=O'\n",
      " '[P](OCC=C(C)C)(OCC=C(C)C)(=O)(OP(OCC=C(C)C)(OCC=C(C)C)=O)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)CC=C(C)C']\n",
      "(23286,) (23286,) (23286, 1024) (23286,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((23286,), (23286,), (23286, 1024), (23286,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Featurization\n",
    "dataset = MorganFingerprint().featurize(dataset)\n",
    "dataset.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hybrid-monitor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23286,) (23286,) (23286, 49) (23286,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((23286,), (23286,), (23286, 49), (23286,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Selection\n",
    "dataset = LowVarianceFS(0.15).featureSelection(dataset)\n",
    "dataset.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "present-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Split\n",
    "splitter = SingletaskStratifiedSplitter()\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset=dataset, frac_train=0.6, \n",
    "                                                                             frac_valid=0.2, frac_test=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "broken-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GaussianNoise, Conv1D, Flatten, Reshape\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam, RMSprop\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Hyperparameters for the network\n",
    "#DENSE = 128\n",
    "#DROPOUT = 0.5\n",
    "#C1_K  = 8 #Number of kernels/feature extractors for first layer\n",
    "#C1_S  = 32 #Width of the convolutional mini networks\n",
    "#C2_K  = 16\n",
    "#C2_S  = 32\n",
    "\n",
    "#activation='relu'\n",
    "\n",
    "input_dim = train_dataset.features.shape[1]\n",
    "\n",
    "def make_cnn_model(input_dim=input_dim,\n",
    "                   g_noise = 0.05, \n",
    "                   DENSE=128, \n",
    "                   DROPOUT=0.5, \n",
    "                   C1_K=8, \n",
    "                   C1_S=32, \n",
    "                   C2_K=16, \n",
    "                   C2_S=32,\n",
    "                   activation='relu',\n",
    "                   loss='binary_crossentropy',\n",
    "                   optimizer='adadelta', \n",
    "                   learning_rate=0.01, \n",
    "                   metrics='accuracy'):\n",
    "    model = Sequential()\n",
    "    #Adding a bit of GaussianNoise also works as regularization\n",
    "    model.add(GaussianNoise(g_noise, input_shape=(input_dim,)))\n",
    "    #First two is number of filter + kernel size\n",
    "    model.add(Reshape((input_dim, 1)))\n",
    "    model.add(Conv1D(C1_K, (C1_S), activation=activation, padding=\"same\"))\n",
    "    model.add(Conv1D(C2_K, (C2_S), padding=\"same\", activation=activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(DENSE, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    if optimizer=='adadelta':\n",
    "        opt = Adadelta(lr=learning_rate)\n",
    "    elif optimizer=='adam':\n",
    "        opt = Adam(lr=learning_rate)\n",
    "    elif optimizer=='rsmprop':\n",
    "        opt = RMSprop(lr=learning_rate)\n",
    "    else : \n",
    "        opt = optimizer\n",
    "\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "willing-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models.kerasModels import KerasModel\n",
    "\n",
    "#input_dim = train_dataset.features.shape[1]\n",
    "#print(input_dim)\n",
    "#model = KerasModel(make_cnn_model, epochs = 150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dedicated-sarah",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(train_dataset.features.shape, train_dataset.y.shape)\n",
    "\n",
    "\n",
    "#model.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "million-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics = [Metric(roc_auc_score), \n",
    "#           Metric(precision_score), \n",
    "#           Metric(accuracy_score), \n",
    "#           Metric(confusion_matrix), \n",
    "#           Metric(classification_report)]\n",
    "\n",
    "#print('training set score:', model.evaluate(train_dataset, metrics))\n",
    "#print('test set score:', model.evaluate(test_dataset, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dangerous-voluntary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 random models from a space of 243 possible models.\n",
      "Fitting model 1/15\n",
      "hyperparameters: {'optimizer': 'adam', 'DROPOUT': 0.2, 'learning_rate': 0.01, 'activation': 'relu', 'g_noise': 0.05}\n",
      "<class 'sklearn.metrics._scorer._PredictScorer'>\n",
      "METRIC:  make_scorer(f1_score)\n",
      "Fitting 15 random models from a space of 243 possible models.\n",
      "(13968, 49) 4656.0\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV] optimizer=adam, learning_rate=0.0001, g_noise=0.05, activation=selu, DROPOUT=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2223 - accuracy: 0.9244\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[CV]  optimizer=adam, learning_rate=0.0001, g_noise=0.05, activation=selu, DROPOUT=0.5, score=0.044, total=   2.8s\n",
      "[CV] optimizer=adam, learning_rate=0.0001, g_noise=0.05, activation=selu, DROPOUT=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2111 - accuracy: 0.9363\n",
      "[CV]  optimizer=adam, learning_rate=0.0001, g_noise=0.05, activation=selu, DROPOUT=0.5, score=0.041, total=   1.2s\n",
      "[CV] optimizer=adam, learning_rate=0.0001, g_noise=0.05, activation=selu, DROPOUT=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2076 - accuracy: 0.9391\n",
      "[CV]  optimizer=adam, learning_rate=0.0001, g_noise=0.05, activation=selu, DROPOUT=0.5, score=0.000, total=   1.1s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.05, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.9432\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.05, activation=relu, DROPOUT=0.4, score=0.119, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.05, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9424\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.05, activation=relu, DROPOUT=0.4, score=0.151, total=   1.2s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.05, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1951 - accuracy: 0.9418\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.05, activation=relu, DROPOUT=0.4, score=0.000, total=   1.2s\n",
      "[CV] optimizer=adam, learning_rate=0.01, g_noise=0.01, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9410\n",
      "[CV]  optimizer=adam, learning_rate=0.01, g_noise=0.01, activation=relu, DROPOUT=0.4, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.01, g_noise=0.01, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.9405\n",
      "[CV]  optimizer=adam, learning_rate=0.01, g_noise=0.01, activation=relu, DROPOUT=0.4, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.01, g_noise=0.01, activation=relu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2001 - accuracy: 0.9408\n",
      "[CV]  optimizer=adam, learning_rate=0.01, g_noise=0.01, activation=relu, DROPOUT=0.4, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.0001, g_noise=0.01, activation=relu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.9270\n",
      "[CV]  optimizer=adam, learning_rate=0.0001, g_noise=0.01, activation=relu, DROPOUT=0.2, score=0.000, total=   1.0s\n",
      "[CV] optimizer=adam, learning_rate=0.0001, g_noise=0.01, activation=relu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2427 - accuracy: 0.9355\n",
      "[CV]  optimizer=adam, learning_rate=0.0001, g_noise=0.01, activation=relu, DROPOUT=0.2, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.0001, g_noise=0.01, activation=relu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2263 - accuracy: 0.9384\n",
      "[CV]  optimizer=adam, learning_rate=0.0001, g_noise=0.01, activation=relu, DROPOUT=0.2, score=0.000, total=   1.2s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=selu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2750 - accuracy: 0.9091\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=selu, DROPOUT=0.4, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=selu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2817 - accuracy: 0.9243\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=selu, DROPOUT=0.4, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=selu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8416\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=selu, DROPOUT=0.4, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.01, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6686 - accuracy: 0.7160\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.01, activation=relu, DROPOUT=0.5, score=0.094, total=   1.2s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.01, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.8918\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.01, activation=relu, DROPOUT=0.5, score=0.000, total=   1.0s\n",
      "[CV] optimizer=adadelta, learning_rate=0.001, g_noise=0.01, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.3792\n",
      "[CV]  optimizer=adadelta, learning_rate=0.001, g_noise=0.01, activation=relu, DROPOUT=0.5, score=0.033, total=   1.0s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=selu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2025 - accuracy: 0.9366\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=selu, DROPOUT=0.5, score=0.000, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=selu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2033 - accuracy: 0.9402\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=selu, DROPOUT=0.5, score=0.161, total=   1.2s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=selu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2080 - accuracy: 0.9351\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=selu, DROPOUT=0.5, score=0.000, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1891 - accuracy: 0.9439\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5, score=0.058, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1837 - accuracy: 0.9427\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5, score=0.068, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9423\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=relu, DROPOUT=0.5, score=0.000, total=   1.4s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1867 - accuracy: 0.9418\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=elu, DROPOUT=0.2, score=0.192, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1855 - accuracy: 0.9406\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=elu, DROPOUT=0.2, score=0.130, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1958 - accuracy: 0.9391\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.001, g_noise=0.005, activation=elu, DROPOUT=0.2, score=0.094, total=   1.2s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.05, activation=elu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.9280\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.05, activation=elu, DROPOUT=0.4, score=0.000, total=   1.0s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.05, activation=elu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4192 - accuracy: 0.8609\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.05, activation=elu, DROPOUT=0.4, score=0.000, total=   1.2s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.05, activation=elu, DROPOUT=0.4 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.3929 - accuracy: 0.8667\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.05, activation=elu, DROPOUT=0.4, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9432\n",
      "[CV]  optimizer=adam, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.5, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9408\n",
      "[CV]  optimizer=adam, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.5, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adam, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.2031 - accuracy: 0.9417\n",
      "[CV]  optimizer=adam, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.5, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.9189\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=elu, DROPOUT=0.2, score=0.000, total=   1.0s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.9250\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=elu, DROPOUT=0.2, score=0.000, total=   1.1s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=elu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.9084\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=elu, DROPOUT=0.2, score=0.000, total=   1.0s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1863 - accuracy: 0.9433\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.2, score=0.043, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.9427\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.2, score=0.144, total=   1.2s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1932 - accuracy: 0.9406\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.01, g_noise=0.05, activation=relu, DROPOUT=0.2, score=0.044, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.0001, g_noise=0.05, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1894 - accuracy: 0.9434\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.0001, g_noise=0.05, activation=relu, DROPOUT=0.5, score=0.008, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.0001, g_noise=0.05, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1880 - accuracy: 0.9432\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.0001, g_noise=0.05, activation=relu, DROPOUT=0.5, score=0.035, total=   1.3s\n",
      "[CV] optimizer=rmsprop, learning_rate=0.0001, g_noise=0.05, activation=relu, DROPOUT=0.5 \n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.1932 - accuracy: 0.9432\n",
      "[CV]  optimizer=rmsprop, learning_rate=0.0001, g_noise=0.05, activation=relu, DROPOUT=0.5, score=0.000, total=   1.3s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=selu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8796\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=selu, DROPOUT=0.2, score=0.000, total=   1.0s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=selu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8933\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=selu, DROPOUT=0.2, score=0.000, total=   1.0s\n",
      "[CV] optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=selu, DROPOUT=0.2 \n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.9022\n",
      "[CV]  optimizer=adadelta, learning_rate=0.01, g_noise=0.005, activation=selu, DROPOUT=0.2, score=0.000, total=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   54.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437/437 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9416\n",
      "\n",
      " \n",
      " Best make_scorer(f1_score): 0.138994 using {'optimizer': 'rmsprop', 'learning_rate': 0.001, 'g_noise': 0.005, 'activation': 'elu', 'DROPOUT': 0.2}\n",
      "\n",
      " make_scorer(f1_score): 0.028265 (0.020036) with: {'optimizer': 'adam', 'learning_rate': 0.0001, 'g_noise': 0.05, 'activation': 'selu', 'DROPOUT': 0.5} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.089936 (0.064873) with: {'optimizer': 'rmsprop', 'learning_rate': 0.001, 'g_noise': 0.05, 'activation': 'relu', 'DROPOUT': 0.4} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.000000 (0.000000) with: {'optimizer': 'adam', 'learning_rate': 0.01, 'g_noise': 0.01, 'activation': 'relu', 'DROPOUT': 0.4} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.000000 (0.000000) with: {'optimizer': 'adam', 'learning_rate': 0.0001, 'g_noise': 0.01, 'activation': 'relu', 'DROPOUT': 0.2} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.000000 (0.000000) with: {'optimizer': 'adadelta', 'learning_rate': 0.01, 'g_noise': 0.005, 'activation': 'selu', 'DROPOUT': 0.4} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.042280 (0.038695) with: {'optimizer': 'adadelta', 'learning_rate': 0.001, 'g_noise': 0.01, 'activation': 'relu', 'DROPOUT': 0.5} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.053571 (0.075761) with: {'optimizer': 'rmsprop', 'learning_rate': 0.001, 'g_noise': 0.005, 'activation': 'selu', 'DROPOUT': 0.5} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.041987 (0.029925) with: {'optimizer': 'rmsprop', 'learning_rate': 0.001, 'g_noise': 0.005, 'activation': 'relu', 'DROPOUT': 0.5} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.138994 (0.040410) with: {'optimizer': 'rmsprop', 'learning_rate': 0.001, 'g_noise': 0.005, 'activation': 'elu', 'DROPOUT': 0.2} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.000000 (0.000000) with: {'optimizer': 'adadelta', 'learning_rate': 0.01, 'g_noise': 0.05, 'activation': 'elu', 'DROPOUT': 0.4} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.000000 (0.000000) with: {'optimizer': 'adam', 'learning_rate': 0.01, 'g_noise': 0.05, 'activation': 'relu', 'DROPOUT': 0.5} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.000000 (0.000000) with: {'optimizer': 'adadelta', 'learning_rate': 0.01, 'g_noise': 0.005, 'activation': 'elu', 'DROPOUT': 0.2} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.077053 (0.047138) with: {'optimizer': 'rmsprop', 'learning_rate': 0.01, 'g_noise': 0.05, 'activation': 'relu', 'DROPOUT': 0.2} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.014294 (0.015194) with: {'optimizer': 'rmsprop', 'learning_rate': 0.0001, 'g_noise': 0.05, 'activation': 'relu', 'DROPOUT': 0.5} \n",
      "\n",
      "\n",
      " make_scorer(f1_score): 0.000000 (0.000000) with: {'optimizer': 'adadelta', 'learning_rate': 0.01, 'g_noise': 0.005, 'activation': 'selu', 'DROPOUT': 0.2} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from parameterOptimization.HyperparameterOpt import GridHyperparamOpt\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "\n",
    "#Hyperparameter Optimization\n",
    "optimizer = GridHyperparamOpt(make_cnn_model)\n",
    "\n",
    "params_dict = {'optimizer' : ['adam', 'rmsprop', 'adadelta'],\n",
    "              'DROPOUT' : [0.2, 0.4, 0.5],\n",
    "              'learning_rate' : [0.01, 0.001, 0.0001],\n",
    "              'activation' : ['relu', 'elu', 'selu'],\n",
    "              'g_noise' : [0.01, 0.05, 0.005]}\n",
    "\n",
    "#TODO: multiple scoring not working\n",
    "#scoring = {'f1': make_scorer(f1_score), 'Accuracy': 'accuracy'}\n",
    "scoring = make_scorer(f1_score)\n",
    "\n",
    "best_model, best_hyperparams, all_results = optimizer.hyperparam_search(params_dict, train_dataset,\n",
    "                                                                        valid_dataset, scoring,\n",
    "                                                                        cv=3, n_jobs=1, verbose=3)\n",
    "\n",
    "#print('#################')\n",
    "#print(best_hyperparams)\n",
    "#print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
