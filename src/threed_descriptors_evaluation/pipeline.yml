datasets:
  classification:
    1:
      train:
        - train_1-balance.sdf
      test:
        - test_1-balance.sdf

    2:
      train:
        - train_109-balance.sdf
      test:
        - test_109-balance.sdf

  regression:
    1:
      train:
        - train_CCRF-CEM.sdf
      test:
        - test_CCRF-CEM.sdf

    2:
      train:
        - train_nci60_a549atcc_gi50.sdf
      test:
        - test_nci60_a549atcc_gi50.sdf

    3:
      train:
        - train_PC-3.sdf
      test:
        - test_PC-3.sdf

preprocessing_and_hyperparameters:
  fingerprints_and_descriptors:
    1:
      featurization:
        1:
          - All3DDescriptors
        2:
          - All3DDescriptors
          - LayeredFP
        21:
          - LayeredFP
        3:
          - All3DDescriptors
          - AtomPair
        31:
          - AtomPair
        4:
          - All3DDescriptors
          - RDKitFP
        5:
          - RDKitFP
        6:
          - All3DDescriptors
          - ECFP4
        7:
          - ECFP4
        8:
          - All3DDescriptors
          - MACCS
        9:
          - MACCS

      hyperparameters:

        hlayers_sizes:
          - '[512, 256]'
          - '[256, 128]'
          - '[128, 64]'
          - '[64, 32]'
          - '[512, 256, 128]'
          - '[256, 128, 64]'
          - '[128, 64, 32]'
          - '[512, 256, 128, 64]'
          - '[256, 128, 64, 32]'

        l2:
          - 0.0
          - 1e-4
          - 1e-3
          - 1e-2
        hidden_dropout:
          - 0.0
          - 0.25
          - 0.5
        batchnorm:
          - True
          - False

        learning_rate:
          - 1e-4
          - 1e-3
          - 1e-2
  deepchem:
    1:
      featurization:
        - GraphConv
      hyperparameters:

        graph_conv_layers:

          - [ 32, 32 ]
          - [ 64, 64 ]
          - [ 128, 128 ]
          - [ 32, 32, 32 ]
          - [ 64, 64, 64 ]
          - [ 128, 128, 128 ]
          - [ 32, 32, 32, 32 ]
          - [ 64, 64, 64, 64 ]
          - [ 128, 128, 128, 128 ]

        dense_layer_size:
          - 2048
          - 1024
          - 512
          - 256
          - 128
          - 64
          - 32

        dropout:
          - 0.0
          - 0.25
          - 0.5

        learning_rate:
          - 1e-4
          - 1e-3
          - 1e-2
    2:
      featurization:
        - TextCNN

      hyperparameters:
        n_embedding:
          - 75
          - 32
          - 64
        kernel_sizes:
          - [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]
          - [1, 2, 3, 4, 5, 7, 10, 15]
          - [3, 4, 5, 7, 10, 15]
          - [3, 4, 5, 7, 10]
          - [3, 4, 5, 7]
          - [3, 4, 5]
          - [3, 5, 7]
        num_filters:
          - [100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160]
          - [32, 32, 32, 32, 64, 64, 64, 64, 128, 128, 128, 128]
          - [128, 128, 128, 128, 64, 64, 64, 64, 32, 32, 32, 32]
        dropout:
          - 0.0
          - 0.25
          - 0.5
        learning_rate:
          - 1e-4
          - 1e-3
          - 1e-2


    3:
      featurization:
        - Weave

      hyperparameters:

        n_hidden:
          - 32
          - 64
          - 128
        n_graph_feat:
          - 128
          - 256
        n_weave:
          - 2
          - 3
          - 4
        fully_connected_layer_sizes:
          - [2048]
          - [1024]
          - [512]
          - [256]
        dropouts:
          - 0.0
          - 0.25
          - 0.5
        learning_rate:
          - 1e-4
          - 1e-3
          - 1e-2
    4:
      featurization:
        - Mol2vec
      hyperparameters:

        hlayers_sizes:
          - '[256, 128]'
          - '[128, 64]'
          - '[64, 32]'
          - '[32, 16]'
          - '[256, 128, 64]'
          - '[128, 64, 32]'
          - '[64, 32, 16]'
          - '[256, 128, 64, 32]'
          - '[128, 64, 32, 16]'

        l2:
          - 0.0
          - 1e-4
          - 1e-3
          - 1e-2

        hidden_dropout:
          - 0.0
          - 0.25
          - 0.5

        batchnorm:
          - True
          - False

        learning_rate:
          - 1e-4
          - 1e-3
          - 1e-2

    5:
      featurization:
        - MPNN

      hyperparameters:

        n_hidden:
          - 128
          - 256
          - 100

        T:
          - 3
          - 4
          - 5
          - 6
          - 7
          - 8

        M:
          - 1
          - 2
          - 3
          - 4
          - 5
          - 6
          - 7
          - 8
          - 9
          - 12

        learning_rate:
          - 1e-5
          - 1e-4
          - 1e-3

    6:
      featurization:
        - GCN

      hyperparameters:

        graph_conv_layers:
          - [32, 32]
          - [64, 64]
          - [128, 128]
          - [32, 32, 32]
          - [64, 64, 64]
          - [128, 128, 128]
          - [32, 32, 32, 32]
          - [64, 64, 64, 64]
          - [128, 128, 128, 128]

        predictor_hidden_feats:
          - 256
          - 128
          - 64

        dropout:
          - 0.0
          - 0.25
          - 0.5

        predictor_dropout:
          - 0.0
          - 0.25
          - 0.5

        learning_rate:
          - 1e-4
          - 1e-3
          - 1e-2
    7:
      featurization:
        - GAT
      hyperparameters:

        graph_attention_layers:
          - [8, 8]
          - [16, 16]
          - [32, 32]
          - [8, 8, 8]
          - [16, 16, 16]
          - [32, 32, 32]

        n_attention_heads:
          - 4
          - 8

        predictor_hidden_feats:
          - 256
          - 128
          - 64

        dropout:
          - 0.0
          - 0.25
          - 0.5

        predictor_dropout:
          - 0.0
          - 0.25
          - 0.5

        learning_rate:
          - 1e-4
          - 1e-3
          - 1e-2
    8:
      featurization:
        - AttentiveFP
      hyperparameters:
        num_layers:
          - 1
          - 2
          - 3
          - 4

        num_timesteps:
          - 2
          - 3
          - 4

        graph_feat_size:
          - 32
          - 64
          - 128
          - 256
          - 512
          - 200
        dropout:
          - 0
          - 0.25
          - 0.5
        learning_rate:
          - 1e-4
          - 1e-3
          - 1e-2
    9:
      featurization:
        - TorchMPNN
      hyperparameters:
        node_out_feats:
          - 64
          - 128

        edge_hidden_feats:
          - 128
          - 256

        num_step_message_passing:
          - 3
          - 4
          - 5
          - 6
          - 7
          - 8

        num_step_set2set:
          - 2
          - 4
          - 6
          - 8

        num_layer_set2set:
          - 2
          - 3

        learning_rate:
          - 1e-5
          - 1e-4
          - 1e-3