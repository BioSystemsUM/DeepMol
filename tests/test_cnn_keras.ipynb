{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "id": "clean-collect",
=======
   "execution_count": 8,
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "#sess = tf.compat.v1.Session(config=config)\n",
    "sess =tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "id": "automated-oriental",
=======
   "execution_count": 9,
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "from loaders.Loaders import CSVLoader\n",
    "from compoundFeaturization.rdkitFingerprints import MorganFingerprint\n",
    "from featureSelection.baseFeatureSelector import LowVarianceFS\n",
    "from splitters.splitters import SingletaskStratifiedSplitter\n",
    "from models.kerasModels import KerasModel\n",
    "from metrics.Metrics import Metric\n",
    "from metrics.metricsFunctions import f1_score, roc_auc_score, precision_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)\n",
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "pursuant-delhi",
=======
   "execution_count": 10,
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mols_shape:  23290\n",
      "Features_shape:  X not defined!\n",
      "Labels_shape:  (23290,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Load Dataset\n",
    "dataset = CSVLoader(dataset_path='preprocessed_dataset_wfoodb.csv', \n",
    "                    mols_field='Smiles', \n",
    "                    labels_fields='Class', \n",
    "                    id_field='ID')#, shard_size=4000)\n",
    "dataset = dataset.create_dataset()\n",
    "print(dataset.get_shape())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "id": "certain-ultimate",
=======
   "execution_count": 11,
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurizing datapoint 0\n",
      "Featurizing datapoint 1000\n",
      "Featurizing datapoint 2000\n",
      "Featurizing datapoint 3000\n",
      "Featurizing datapoint 4000\n",
      "Featurizing datapoint 5000\n",
      "Featurizing datapoint 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [14:32:33] Explicit valence for atom # 1 Cl, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in smile: O=[Cl]=O\n",
      "Featurizing datapoint 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [14:32:37] Explicit valence for atom # 3 B, 4, is greater than permitted\n",
      "RDKit ERROR: [14:32:37] Explicit valence for atom # 1 Cl, 9, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in smile: OB1O[B]2(O)OB(O)O[B](O)(O1)O2\n",
      "error in smile: O=[Cl-](=O)(=O)=O\n",
      "Featurizing datapoint 8000\n",
      "Featurizing datapoint 9000\n",
      "Featurizing datapoint 10000\n",
      "Featurizing datapoint 11000\n",
      "Featurizing datapoint 12000\n",
      "Featurizing datapoint 13000\n",
      "Featurizing datapoint 14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [14:32:55] Explicit valence for atom # 0 P, 11, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in smile: [P](OCC=C(C)C)(OCC=C(C)C)(=O)(OP(OCC=C(C)C)(OCC=C(C)C)=O)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)CC=C(C)C\n",
      "Featurizing datapoint 15000\n",
      "Featurizing datapoint 16000\n",
      "Featurizing datapoint 17000\n",
      "Featurizing datapoint 18000\n",
      "Featurizing datapoint 19000\n",
      "Featurizing datapoint 20000\n",
      "Featurizing datapoint 21000\n",
      "Featurizing datapoint 22000\n",
      "Featurizing datapoint 23000\n",
      "Elements with indexes:  [6257, 7708, 7709, 14244]  were removed due to the presence of NAs!\n",
      "The elements in question are:  ['O=[Cl]=O' 'OB1O[B]2(O)OB(O)O[B](O)(O1)O2' 'O=[Cl-](=O)(=O)=O'\n",
      " '[P](OCC=C(C)C)(OCC=C(C)C)(=O)(OP(OCC=C(C)C)(OCC=C(C)C)=O)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)(CC=C(C)C)CC=C(C)C']\n",
      "Mols_shape:  23286\n",
      "Features_shape:  (23286, 1024)\n",
      "Labels_shape:  (23286,)\n"
     ]
    }
   ],
   "source": [
    "#Featurization\n",
    "dataset = MorganFingerprint().featurize(dataset)\n",
    "dataset.get_shape()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "id": "fourth-intervention",
=======
   "execution_count": 12,
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mols_shape:  23286\n",
      "Features_shape:  (23286, 49)\n",
      "Labels_shape:  (23286,)\n"
     ]
    }
   ],
   "source": [
    "#Feature Selection\n",
    "dataset = LowVarianceFS(0.15).featureSelection(dataset)\n",
    "dataset.get_shape()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "id": "further-heritage",
=======
   "execution_count": 13,
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Split\n",
    "splitter = SingletaskStratifiedSplitter()\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset=dataset, frac_train=0.6, \n",
    "                                                                             frac_valid=0.2, frac_test=0.2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "id": "instructional-contributor",
=======
   "execution_count": 15,
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GaussianNoise, Conv1D, Flatten, Reshape\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam, RMSprop\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Hyperparameters for the network\n",
    "#DENSE = 128\n",
    "#DROPOUT = 0.5\n",
    "#C1_K  = 8 #Number of kernels/feature extractors for first layer\n",
    "#C1_S  = 32 #Width of the convolutional mini networks\n",
    "#C2_K  = 16\n",
    "#C2_S  = 32\n",
    "\n",
    "#activation='relu'\n",
    "\n",
    "input_dim = train_dataset.X.shape[1]\n",
    "\n",
    "def make_cnn_model(input_dim=input_dim,\n",
    "                   g_noise = 0.05, \n",
    "                   DENSE=128, \n",
    "                   DROPOUT=0.5, \n",
    "                   C1_K=8, \n",
    "                   C1_S=32, \n",
    "                   C2_K=16, \n",
    "                   C2_S=32,\n",
    "                   activation='relu',\n",
    "                   loss='binary_crossentropy',\n",
    "                   optimizer='adadelta', \n",
    "                   learning_rate=0.01, \n",
    "                   metrics='accuracy'):\n",
    "    model = Sequential()\n",
    "    #Adding a bit of GaussianNoise also works as regularization\n",
    "    model.add(GaussianNoise(g_noise, input_shape=(input_dim,)))\n",
    "    #First two is number of filter + kernel size\n",
    "    model.add(Reshape((input_dim, 1)))\n",
    "    model.add(Conv1D(C1_K, (C1_S), activation=activation, padding=\"same\"))\n",
    "    model.add(Conv1D(C2_K, (C2_S), padding=\"same\", activation=activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(DENSE, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    if optimizer=='adadelta':\n",
    "        opt = Adadelta(lr=learning_rate)\n",
    "    elif optimizer=='adam':\n",
    "        opt = Adam(lr=learning_rate)\n",
    "    elif optimizer=='rsmprop':\n",
    "        opt = RMSprop(lr=learning_rate)\n",
    "    else : \n",
    "        opt = optimizer\n",
    "\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "id": "blocked-flashing",
=======
   "execution_count": null,
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models.kerasModels import KerasModel\n",
    "\n",
    "#input_dim = train_dataset.X.shape[1]\n",
    "#print(input_dim)\n",
    "#model = KerasModel(make_cnn_model, epochs = 150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "id": "aggregate-orlando",
=======
   "execution_count": null,
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(train_dataset.X.shape, train_dataset.y.shape)\n",
    "\n",
    "\n",
    "#model.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "id": "deadly-croatia",
=======
   "execution_count": null,
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics = [Metric(roc_auc_score), \n",
    "#           Metric(precision_score), \n",
    "#           Metric(accuracy_score), \n",
    "#           Metric(confusion_matrix), \n",
    "#           Metric(classification_report)]\n",
    "\n",
    "#print('training set score:', model.evaluate(train_dataset, metrics))\n",
    "#print('test set score:', model.evaluate(test_dataset, metrics))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "id": "after-reading",
=======
   "execution_count": 16,
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODE:  classification\n",
      "Fitting 15 random models from a space of 243 possible models.\n",
      "Fitting model 1/15\n",
      "hyperparameters: {'optimizer': 'adam', 'DROPOUT': 0.2, 'learning_rate': 0.001, 'activation': 'relu', 'g_noise': 0.005}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.2154 - accuracy: 0.9390\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.10035842293906809\n",
      "Model 1/15, Metric f1_score, Validation set 1: 0.100358\n",
      "\tbest_validation_score so far: 0.100358\n",
      "Fitting model 2/15\n",
      "hyperparameters: {'optimizer': 'adam', 'DROPOUT': 0.2, 'learning_rate': 0.0001, 'activation': 'relu', 'g_noise': 0.005}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437/437 [==============================] - 1s 2ms/step - loss: 0.2877 - accuracy: 0.9409\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.0\n",
      "Model 2/15, Metric f1_score, Validation set 2: 0.000000\n",
      "\tbest_validation_score so far: 0.100358\n",
      "Fitting model 3/15\n",
      "hyperparameters: {'optimizer': 'adam', 'DROPOUT': 0.4, 'learning_rate': 0.0001, 'activation': 'selu', 'g_noise': 0.01}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.2101 - accuracy: 0.9400\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.09929078014184398\n",
      "Model 3/15, Metric f1_score, Validation set 3: 0.099291\n",
      "\tbest_validation_score so far: 0.100358\n",
      "Fitting model 4/15\n",
      "hyperparameters: {'optimizer': 'rmsprop', 'DROPOUT': 0.2, 'learning_rate': 0.001, 'activation': 'relu', 'g_noise': 0.005}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.2091 - accuracy: 0.9382\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.18604651162790697\n",
      "Model 4/15, Metric f1_score, Validation set 4: 0.186047\n",
      "\tbest_validation_score so far: 0.186047\n",
      "Fitting model 5/15\n",
      "hyperparameters: {'optimizer': 'rmsprop', 'DROPOUT': 0.4, 'learning_rate': 0.001, 'activation': 'selu', 'g_noise': 0.05}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.2223 - accuracy: 0.9307\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.0\n",
      "Model 5/15, Metric f1_score, Validation set 5: 0.000000\n",
      "\tbest_validation_score so far: 0.186047\n",
      "Fitting model 6/15\n",
      "hyperparameters: {'optimizer': 'rmsprop', 'DROPOUT': 0.4, 'learning_rate': 0.001, 'activation': 'selu', 'g_noise': 0.005}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.2143 - accuracy: 0.9347\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.13194444444444445\n",
      "Model 6/15, Metric f1_score, Validation set 6: 0.131944\n",
      "\tbest_validation_score so far: 0.186047\n",
      "Fitting model 7/15\n",
      "hyperparameters: {'optimizer': 'rmsprop', 'DROPOUT': 0.4, 'learning_rate': 0.0001, 'activation': 'selu', 'g_noise': 0.01}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.2103 - accuracy: 0.9338\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.21082621082621084\n",
      "Model 7/15, Metric f1_score, Validation set 7: 0.210826\n",
      "\tbest_validation_score so far: 0.210826\n",
      "Fitting model 8/15\n",
      "hyperparameters: {'optimizer': 'rmsprop', 'DROPOUT': 0.5, 'learning_rate': 0.01, 'activation': 'selu', 'g_noise': 0.05}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.2238 - accuracy: 0.9307\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.0\n",
      "Model 8/15, Metric f1_score, Validation set 8: 0.000000\n",
      "\tbest_validation_score so far: 0.210826\n",
      "Fitting model 9/15\n",
      "hyperparameters: {'optimizer': 'rmsprop', 'DROPOUT': 0.5, 'learning_rate': 0.0001, 'activation': 'relu', 'g_noise': 0.05}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.2063 - accuracy: 0.9334\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.08695652173913045\n",
      "Model 9/15, Metric f1_score, Validation set 9: 0.086957\n",
      "\tbest_validation_score so far: 0.210826\n",
      "Fitting model 10/15\n",
      "hyperparameters: {'optimizer': 'adadelta', 'DROPOUT': 0.2, 'learning_rate': 0.001, 'activation': 'selu', 'g_noise': 0.01}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.5519 - accuracy: 0.7212\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.02777777777777778\n",
      "Model 10/15, Metric f1_score, Validation set 10: 0.027778\n",
      "\tbest_validation_score so far: 0.210826\n",
      "Fitting model 11/15\n",
      "hyperparameters: {'optimizer': 'adadelta', 'DROPOUT': 0.4, 'learning_rate': 0.01, 'activation': 'relu', 'g_noise': 0.05}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.9044\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.0\n",
      "Model 11/15, Metric f1_score, Validation set 11: 0.000000\n",
      "\tbest_validation_score so far: 0.210826\n",
      "Fitting model 12/15\n",
      "hyperparameters: {'optimizer': 'adadelta', 'DROPOUT': 0.4, 'learning_rate': 0.01, 'activation': 'selu', 'g_noise': 0.005}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.3741 - accuracy: 0.8510\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.0\n",
      "Model 12/15, Metric f1_score, Validation set 12: 0.000000\n",
      "\tbest_validation_score so far: 0.210826\n",
      "Fitting model 13/15\n",
      "hyperparameters: {'optimizer': 'adadelta', 'DROPOUT': 0.4, 'learning_rate': 0.001, 'activation': 'elu', 'g_noise': 0.05}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.6429 - accuracy: 0.6603\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.0527859237536657\n",
      "Model 13/15, Metric f1_score, Validation set 13: 0.052786\n",
      "\tbest_validation_score so far: 0.210826\n",
      "Fitting model 14/15\n",
      "hyperparameters: {'optimizer': 'adadelta', 'DROPOUT': 0.4, 'learning_rate': 0.0001, 'activation': 'relu', 'g_noise': 0.01}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.7036 - accuracy: 0.4328\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.10129163834126442\n",
      "Model 14/15, Metric f1_score, Validation set 14: 0.101292\n",
      "\tbest_validation_score so far: 0.210826\n",
      "Fitting model 15/15\n",
      "hyperparameters: {'optimizer': 'adadelta', 'DROPOUT': 0.4, 'learning_rate': 0.0001, 'activation': 'relu', 'g_noise': 0.005}\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.7762 - accuracy: 0.1120\n",
      "expected str, bytes or os.PathLike object, not NoneType\n",
      "f1_score: \n",
      " 0.10441426146010187\n",
      "Model 15/15, Metric f1_score, Validation set 15: 0.104414\n",
      "\tbest_validation_score so far: 0.210826\n",
      "f1_score: \n",
      " 0.19553072625698326\n",
      "Best hyperparameters: ('rmsprop', 0.4, 0.0001, 'selu', 0.01)\n",
      "train_score: 0.195531\n",
      "validation_score: 0.210826\n"
     ]
    }
   ],
   "source": [
    "from parameterOptimization.HyperparameterOpt import HyperparamOpt_Valid\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "\n",
    "#Hyperparameter Optimization\n",
    "optimizer = HyperparamOpt_Valid(make_cnn_model)\n",
    "\n",
    "params_dict = {'optimizer' : ['adam', 'rmsprop', 'adadelta'],\n",
    "              'DROPOUT' : [0.2, 0.4, 0.5],\n",
    "              'learning_rate' : [0.01, 0.001, 0.0001],\n",
    "              'activation' : ['relu', 'elu', 'selu'],\n",
    "              'g_noise' : [0.01, 0.05, 0.005]}\n",
    "\n",
    "#TODO: multiple scoring not working\n",
    "#scoring = {'f1': make_scorer(f1_score), 'Accuracy': 'accuracy'}\n",
    "\n",
    "best_model, best_hyperparams, all_results = optimizer.hyperparam_search(params_dict, train_dataset,\n",
    "                                                                        valid_dataset, Metric(f1_score),\n",
    "                                                                        n_jobs=1, verbose=3)\n",
    "\n",
    "#print('#################')\n",
    "#print(best_hyperparams)\n",
    "#print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.13"
=======
   "version": "3.7.6"
>>>>>>> ca299a665ee060c3a6e88942cfe13ecae8809a72
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
